# PyTorch ä»é›¶åˆ°ç²¾é€š - å®Œæ•´å­¦ä¹ è·¯çº¿å›¾

> **å­¦ä¹ ç›®æ ‡**: ç³»ç»ŸæŒæ¡PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä»åŸºç¡€åˆ°å®æˆ˜ï¼Œå…·å¤‡ç‹¬ç«‹å¼€å‘æ·±åº¦å­¦ä¹ é¡¹ç›®çš„èƒ½åŠ›
> 
> **é¢„è®¡æ€»æ—¶é•¿**: 8-12å‘¨ï¼ˆæ¯å¤©2-3å°æ—¶ï¼‰
> 
> **å‰ç½®è¦æ±‚**: PythonåŸºç¡€ã€åŸºæœ¬çš„çº¿æ€§ä»£æ•°å’Œå¾®ç§¯åˆ†çŸ¥è¯†

---

## ğŸ“š å­¦ä¹ è·¯å¾„æ€»è§ˆ

```
é˜¶æ®µ1: åŸºç¡€å…¥é—¨ (1-2å‘¨)
    â†“
é˜¶æ®µ2: æ ¸å¿ƒæ¦‚å¿µ (2-3å‘¨)
    â†“
é˜¶æ®µ3: ç¥ç»ç½‘ç»œå®æˆ˜ (2-3å‘¨)
    â†“
é˜¶æ®µ4: é«˜çº§ç‰¹æ€§ (2-3å‘¨)
    â†“
é˜¶æ®µ5: é¡¹ç›®å®æˆ˜ (1-2å‘¨)
```

---

## ğŸ¯ é˜¶æ®µ1: PyTorchåŸºç¡€å…¥é—¨ (ç¬¬1-2å‘¨)

### 1.1 ç¯å¢ƒæ­å»ºä¸é…ç½® (ç¬¬1å¤©)

**å­¦ä¹ ç›®æ ‡**: 
- æˆåŠŸå®‰è£…PyTorchåŠç›¸å…³ä¾èµ–
- éªŒè¯GPU/CPUç¯å¢ƒé…ç½®

**å®è·µä»»åŠ¡**:
```bash
# å®‰è£…PyTorch (æ ¹æ®ä½ çš„ç³»ç»Ÿé€‰æ‹©)
pip install torch torchvision torchaudio

# éªŒè¯å®‰è£…
python -c "import torch; print(torch.__version__)"
python -c "import torch; print(torch.cuda.is_available())"
```

**éªŒè¯è„šæœ¬**:
```python
import torch
import sys

print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"Pythonç‰ˆæœ¬: {sys.version}")
print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
```

**å­¦ä¹ èµ„æº**:
- PyTorchå®˜æ–¹å®‰è£…æŒ‡å—
- GPUé©±åŠ¨å’ŒCUDAå·¥å…·åŒ…å®‰è£…æ–‡æ¡£

---

### 1.2 å¼ é‡(Tensor)åŸºç¡€æ“ä½œ (ç¬¬2-4å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£å¼ é‡çš„æ¦‚å¿µå’Œæ„ä¹‰
- æŒæ¡å¼ é‡çš„åˆ›å»ºã€ç´¢å¼•ã€åˆ‡ç‰‡
- ç†Ÿç»ƒè¿›è¡Œå¼ é‡è¿ç®—

**æ ¸å¿ƒçŸ¥è¯†ç‚¹**:

#### 1.2.1 å¼ é‡åˆ›å»º
```python
import torch

# 1. ä»æ•°æ®åˆ›å»º
data = [[1, 2], [3, 4]]
tensor = torch.tensor(data)

# 2. ä»NumPyæ•°ç»„åˆ›å»º
import numpy as np
np_array = np.array([[1, 2], [3, 4]])
tensor_from_numpy = torch.from_numpy(np_array)

# 3. ä½¿ç”¨å·¥å‚å‡½æ•°
zeros = torch.zeros(3, 4)          # å…¨0å¼ é‡
ones = torch.ones(2, 3)            # å…¨1å¼ é‡
rand = torch.rand(3, 3)            # éšæœºå¼ é‡ [0,1)
randn = torch.randn(3, 3)          # æ ‡å‡†æ­£æ€åˆ†å¸ƒ
arange = torch.arange(0, 10, 2)    # ç­‰å·®åºåˆ—
linspace = torch.linspace(0, 1, 5) # çº¿æ€§é—´éš”

# 4. åˆ›å»ºä¸å…¶ä»–å¼ é‡ç›¸åŒå½¢çŠ¶çš„å¼ é‡
x = torch.ones(2, 3)
y = torch.zeros_like(x)
z = torch.rand_like(x)
```

#### 1.2.2 å¼ é‡å±æ€§
```python
tensor = torch.rand(3, 4, 5)

print(f"å½¢çŠ¶: {tensor.shape}")        # torch.Size([3, 4, 5])
print(f"ç»´åº¦: {tensor.ndim}")         # 3
print(f"æ•°æ®ç±»å‹: {tensor.dtype}")    # torch.float32
print(f"è®¾å¤‡: {tensor.device}")       # cpu æˆ– cuda:0
print(f"å…ƒç´ æ€»æ•°: {tensor.numel()}")  # 60
```

#### 1.2.3 å¼ é‡æ“ä½œ
```python
# ç´¢å¼•å’Œåˆ‡ç‰‡
tensor = torch.arange(12).reshape(3, 4)
print(tensor[0])        # ç¬¬ä¸€è¡Œ
print(tensor[:, 1])     # ç¬¬äºŒåˆ—
print(tensor[1:, :2])   # å­çŸ©é˜µ

# æ”¹å˜å½¢çŠ¶
x = torch.arange(12)
reshaped = x.reshape(3, 4)
viewed = x.view(2, 6)
unsqueezed = x.unsqueeze(0)  # å¢åŠ ç»´åº¦
squeezed = unsqueezed.squeeze()  # å‹ç¼©ç»´åº¦

# æ‹¼æ¥
x = torch.ones(2, 3)
y = torch.zeros(2, 3)
cat_0 = torch.cat([x, y], dim=0)  # æ²¿ç¬¬0ç»´æ‹¼æ¥ -> (4, 3)
cat_1 = torch.cat([x, y], dim=1)  # æ²¿ç¬¬1ç»´æ‹¼æ¥ -> (2, 6)
stacked = torch.stack([x, y], dim=0)  # åˆ›å»ºæ–°ç»´åº¦ -> (2, 2, 3)
```

#### 1.2.4 æ•°å­¦è¿ç®—
```python
x = torch.tensor([1.0, 2.0, 3.0])
y = torch.tensor([4.0, 5.0, 6.0])

# åŸºæœ¬è¿ç®—ï¼ˆé€å…ƒç´ ï¼‰
add = x + y              # åŠ æ³•
sub = x - y              # å‡æ³•
mul = x * y              # ä¹˜æ³•
div = x / y              # é™¤æ³•
power = x ** 2           # å¹‚è¿ç®—

# çŸ©é˜µè¿ç®—
A = torch.rand(3, 4)
B = torch.rand(4, 2)
matmul = torch.matmul(A, B)  # çŸ©é˜µä¹˜æ³•
# æˆ–è€…ä½¿ç”¨ @ è¿ç®—ç¬¦
matmul = A @ B

# èšåˆæ“ä½œ
tensor = torch.rand(3, 4)
sum_all = tensor.sum()              # æ‰€æœ‰å…ƒç´ æ±‚å’Œ
sum_dim0 = tensor.sum(dim=0)        # æ²¿ç¬¬0ç»´æ±‚å’Œ
mean_val = tensor.mean()            # å¹³å‡å€¼
max_val = tensor.max()              # æœ€å¤§å€¼
min_val = tensor.min()              # æœ€å°å€¼
argmax = tensor.argmax()            # æœ€å¤§å€¼ç´¢å¼•
```

**å®è·µé¡¹ç›®**:
```python
# ç»ƒä¹ 1: å®ç°å›¾åƒçš„åŸºæœ¬å˜æ¢
def image_transform_practice():
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„å›¾åƒå¼ é‡ (æ‰¹æ¬¡, é€šé“, é«˜, å®½)
    image = torch.rand(1, 3, 224, 224)
    
    # ä»»åŠ¡1: å°†å›¾åƒå½’ä¸€åŒ–åˆ°[-1, 1]
    normalized = (image - 0.5) / 0.5
    
    # ä»»åŠ¡2: è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆç®€å•å¹³å‡ï¼‰
    grayscale = image.mean(dim=1, keepdim=True)
    
    # ä»»åŠ¡3: å›¾åƒç¿»è½¬
    flipped = torch.flip(image, dims=[3])  # æ°´å¹³ç¿»è½¬
    
    return normalized, grayscale, flipped

# ç»ƒä¹ 2: å®ç°æ‰¹é‡çŸ©é˜µè¿ç®—
def batch_matrix_operations():
    # æ‰¹é‡çº¿æ€§å˜æ¢
    batch_size = 32
    input_features = 10
    output_features = 5
    
    X = torch.randn(batch_size, input_features)
    W = torch.randn(input_features, output_features)
    b = torch.randn(output_features)
    
    # Y = XW + b
    Y = torch.matmul(X, W) + b
    
    return Y
```

**ä½œä¸š**:
1. åˆ›å»ºä¸€ä¸ª 5x5 çš„éšæœºçŸ©é˜µï¼Œè®¡ç®—å…¶è½¬ç½®ã€è¡Œåˆ—å¼ã€ç‰¹å¾å€¼
2. å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œå°†ä»»æ„å½¢çŠ¶çš„å¼ é‡æ ‡å‡†åŒ– (å‡å€¼0ï¼Œæ ‡å‡†å·®1)
3. åˆ›å»ºä¸¤ä¸ª 3D å¼ é‡å¹¶è¿›è¡Œæ‰¹é‡çŸ©é˜µä¹˜æ³•

---

### 1.3 GPUåŠ é€Ÿä¸è®¾å¤‡ç®¡ç† (ç¬¬5-6å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£CPUä¸GPUçš„åŒºåˆ«
- æŒæ¡å¼ é‡åœ¨ä¸åŒè®¾å¤‡é—´çš„è½¬ç§»
- å­¦ä¼šç¼–å†™è®¾å¤‡æ— å…³çš„ä»£ç 

**æ ¸å¿ƒçŸ¥è¯†ç‚¹**:

```python
# 1. æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# 2. åˆ›å»ºå¼ é‡æ—¶æŒ‡å®šè®¾å¤‡
x_cpu = torch.rand(3, 3)                    # é»˜è®¤åœ¨CPU
x_gpu = torch.rand(3, 3, device='cuda')     # ç›´æ¥åœ¨GPU
x_gpu = torch.rand(3, 3).to(device)         # ä½¿ç”¨.to()æ–¹æ³•

# 3. è®¾å¤‡é—´è½¬ç§»
cpu_tensor = torch.rand(3, 3)
gpu_tensor = cpu_tensor.to('cuda')          # CPU -> GPU
back_to_cpu = gpu_tensor.cpu()              # GPU -> CPU
back_to_cpu = gpu_tensor.to('cpu')          # ç­‰ä»·æ–¹æ³•

# 4. å¤šGPUç®¡ç†
if torch.cuda.device_count() > 1:
    print(f"æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPU")
    tensor_gpu0 = torch.rand(3, 3, device='cuda:0')
    tensor_gpu1 = torch.rand(3, 3, device='cuda:1')

# 5. è®¾å¤‡æ— å…³ä»£ç æ¨¡æ¿
def train_model(model, data):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    for batch in data:
        inputs = batch['input'].to(device)
        labels = batch['label'].to(device)
        # ... è®­ç»ƒé€»è¾‘
```

**æ€§èƒ½å¯¹æ¯”å®éªŒ**:
```python
import time

def benchmark_device(size=10000):
    # CPUè¿ç®—
    start = time.time()
    x_cpu = torch.rand(size, size)
    y_cpu = torch.rand(size, size)
    z_cpu = torch.matmul(x_cpu, y_cpu)
    cpu_time = time.time() - start
    
    # GPUè¿ç®—
    if torch.cuda.is_available():
        start = time.time()
        x_gpu = torch.rand(size, size, device='cuda')
        y_gpu = torch.rand(size, size, device='cuda')
        torch.cuda.synchronize()  # ç­‰å¾…GPUè®¡ç®—å®Œæˆ
        z_gpu = torch.matmul(x_gpu, y_gpu)
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        
        print(f"CPUæ—¶é—´: {cpu_time:.4f}ç§’")
        print(f"GPUæ—¶é—´: {gpu_time:.4f}ç§’")
        print(f"åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
```

---

### 1.4 å¼ é‡çš„å¹¿æ’­æœºåˆ¶ (ç¬¬7å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£å¹¿æ’­çš„åŸç†å’Œè§„åˆ™
- æŒæ¡ä¸åŒå½¢çŠ¶å¼ é‡çš„è¿ç®—

**å¹¿æ’­è§„åˆ™**:
1. å¦‚æœä¸¤ä¸ªå¼ é‡ç»´åº¦ä¸åŒï¼Œåœ¨è¾ƒå°ç»´åº¦å¼ é‡å‰é¢è¡¥1
2. ä¸¤ä¸ªå¼ é‡åœ¨æŸä¸€ç»´åº¦ä¸Šsizeç›¸åŒï¼Œæˆ–å…¶ä¸­ä¸€ä¸ªä¸º1ï¼Œåˆ™å…¼å®¹
3. å¦‚æœæ‰€æœ‰ç»´åº¦éƒ½å…¼å®¹ï¼Œåˆ™å¯ä»¥å¹¿æ’­

```python
# ç¤ºä¾‹1: æ ‡é‡ä¸å¼ é‡
x = torch.tensor([1, 2, 3])
y = 10
result = x + y  # [11, 12, 13]

# ç¤ºä¾‹2: ä¸åŒç»´åº¦çš„å¼ é‡
x = torch.rand(3, 1)      # (3, 1)
y = torch.rand(1, 4)      # (1, 4)
result = x + y            # (3, 4) è‡ªåŠ¨å¹¿æ’­

# ç¤ºä¾‹3: æ‰¹é‡å½’ä¸€åŒ–åœºæ™¯
batch_data = torch.rand(32, 3, 224, 224)  # (batch, channel, H, W)
mean = torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)
std = torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)
normalized = (batch_data - mean) / std

# ç¤ºä¾‹4: æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æ©ç 
scores = torch.rand(8, 10, 10)  # (batch, seq_len, seq_len)
mask = torch.tril(torch.ones(10, 10))  # (seq_len, seq_len)
masked_scores = scores.masked_fill(mask == 0, float('-inf'))
```

**ä½œä¸š**:
ç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œå®ç°batch normalizationçš„å¹¿æ’­è®¡ç®—

---

## ğŸ”¥ é˜¶æ®µ2: è‡ªåŠ¨å¾®åˆ†ä¸æ ¸å¿ƒæ¦‚å¿µ (ç¬¬3-5å‘¨)

### 2.1 è‡ªåŠ¨å¾®åˆ†(Autograd) (ç¬¬8-10å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æ·±å…¥ç†è§£åå‘ä¼ æ’­åŸç†
- æŒæ¡æ¢¯åº¦è®¡ç®—å’Œè®¡ç®—å›¾
- å­¦ä¼šæ¢¯åº¦ç®¡ç†æŠ€å·§

**æ ¸å¿ƒæ¦‚å¿µ**:

#### 2.1.1 åŸºç¡€æ¢¯åº¦è®¡ç®—
```python
import torch

# å¯ç”¨æ¢¯åº¦è·Ÿè¸ª
x = torch.tensor([2.0, 3.0], requires_grad=True)
y = torch.tensor([1.0, 4.0], requires_grad=True)

# å‰å‘ä¼ æ’­ï¼šæ„å»ºè®¡ç®—å›¾
z = x ** 2 + 3 * y
loss = z.sum()

# åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
loss.backward()

# è®¿é—®æ¢¯åº¦
print(f"âˆ‚loss/âˆ‚x = {x.grad}")  # [4.0, 6.0]
print(f"âˆ‚loss/âˆ‚y = {y.grad}")  # [3.0, 3.0]

# æ¢¯åº¦æ¸…é›¶ï¼ˆé‡è¦ï¼ï¼‰
x.grad.zero_()
y.grad.zero_()
```

#### 2.1.2 è®¡ç®—å›¾ä¸åŠ¨æ€å›¾
```python
# PyTorchä½¿ç”¨åŠ¨æ€è®¡ç®—å›¾
def dynamic_computation(x, condition):
    if condition:
        y = x ** 2
    else:
        y = x ** 3
    return y

x = torch.tensor(2.0, requires_grad=True)

# æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºæ–°çš„è®¡ç®—å›¾
y1 = dynamic_computation(x, True)
y1.backward()
print(f"æ¡ä»¶ä¸ºTrueæ—¶çš„æ¢¯åº¦: {x.grad}")

x.grad.zero_()
y2 = dynamic_computation(x, False)
y2.backward()
print(f"æ¡ä»¶ä¸ºFalseæ—¶çš„æ¢¯åº¦: {x.grad}")
```

#### 2.1.3 æ¢¯åº¦ç®¡ç†æŠ€å·§
```python
# 1. ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
with torch.no_grad():
    y = x ** 2  # ä¸ä¼šæ„å»ºè®¡ç®—å›¾
    
# 2. ä¸´æ—¶å¯ç”¨æ¢¯åº¦
x = torch.tensor(2.0)  # requires_grad=False
with torch.enable_grad():
    x.requires_grad_(True)
    y = x ** 2

# 3. é˜»æ–­æ¢¯åº¦ä¼ æ’­
x = torch.tensor(2.0, requires_grad=True)
y = x ** 2
z = y.detach() * 3  # zä¸ä¼šæ¥æ”¶æ¢¯åº¦

# 4. ä¿ç•™è®¡ç®—å›¾ï¼ˆå¤šæ¬¡backwardï¼‰
x = torch.tensor(2.0, requires_grad=True)
y = x ** 2
y.backward(retain_graph=True)  # ç¬¬ä¸€æ¬¡
y.backward()  # ç¬¬äºŒæ¬¡

# 5. è®¡ç®—é«˜é˜¶å¯¼æ•°
x = torch.tensor(2.0, requires_grad=True)
y = x ** 3
grad_y = torch.autograd.grad(y, x, create_graph=True)[0]
grad2_y = torch.autograd.grad(grad_y, x)[0]  # äºŒé˜¶å¯¼æ•°
```

#### 2.1.4 è‡ªå®šä¹‰autogradå‡½æ•°
```python
class MyReLU(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input):
        ctx.save_for_backward(input)
        return input.clamp(min=0)
    
    @staticmethod
    def backward(ctx, grad_output):
        input, = ctx.saved_tensors
        grad_input = grad_output.clone()
        grad_input[input < 0] = 0
        return grad_input

# ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
x = torch.randn(5, requires_grad=True)
y = MyReLU.apply(x)
loss = y.sum()
loss.backward()
```

**å®è·µé¡¹ç›®**:
```python
# é¡¹ç›®1: ä»é›¶å®ç°çº¿æ€§å›å½’
class LinearRegression:
    def __init__(self, input_dim):
        self.w = torch.randn(input_dim, 1, requires_grad=True)
        self.b = torch.zeros(1, requires_grad=True)
    
    def forward(self, x):
        return torch.matmul(x, self.w) + self.b
    
    def train(self, X, y, lr=0.01, epochs=100):
        for epoch in range(epochs):
            # å‰å‘ä¼ æ’­
            y_pred = self.forward(X)
            loss = ((y_pred - y) ** 2).mean()
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ›´æ–°å‚æ•°
            with torch.no_grad():
                self.w -= lr * self.w.grad
                self.b -= lr * self.b.grad
                
                # æ¸…é›¶æ¢¯åº¦
                self.w.grad.zero_()
                self.b.grad.zero_()
            
            if (epoch + 1) % 10 == 0:
                print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# æµ‹è¯•
X = torch.randn(100, 3)
true_w = torch.tensor([[2.0], [-3.4], [1.5]])
true_b = torch.tensor([4.2])
y = torch.matmul(X, true_w) + true_b + torch.randn(100, 1) * 0.1

model = LinearRegression(3)
model.train(X, y)
```

---

### 2.2 æ•°æ®åŠ è½½ä¸å¤„ç† (ç¬¬11-13å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡Datasetå’ŒDataLoaderçš„ä½¿ç”¨
- å­¦ä¼šæ•°æ®é¢„å¤„ç†å’Œå¢å¼º
- ç†è§£æ‰¹å¤„ç†æœºåˆ¶

#### 2.2.1 è‡ªå®šä¹‰Dataset
```python
from torch.utils.data import Dataset, DataLoader
import numpy as np

class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample, label

# ä½¿ç”¨ç¤ºä¾‹
data = torch.randn(1000, 10)
labels = torch.randint(0, 2, (1000,))
dataset = CustomDataset(data, labels)

# åˆ›å»ºDataLoader
dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,  # å¤šè¿›ç¨‹åŠ è½½
    pin_memory=True  # åŠ é€ŸGPUä¼ è¾“
)

# è¿­ä»£æ•°æ®
for batch_data, batch_labels in dataloader:
    print(f"Batch shape: {batch_data.shape}")
    break
```

#### 2.2.2 å›¾åƒæ•°æ®å¤„ç†
```python
from torchvision import datasets, transforms

# å®šä¹‰æ•°æ®å¢å¼º
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), 
                        (0.2023, 0.1994, 0.2010))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), 
                        (0.2023, 0.1994, 0.2010))
])

# åŠ è½½CIFAR-10æ•°æ®é›†
train_dataset = datasets.CIFAR10(
    root='./data',
    train=True,
    download=True,
    transform=transform_train
)

test_dataset = datasets.CIFAR10(
    root='./data',
    train=False,
    download=True,
    transform=transform_test
)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)
```

#### 2.2.3 è‡ªå®šä¹‰æ•°æ®å¢å¼º
```python
class AddGaussianNoise:
    def __init__(self, mean=0., std=0.1):
        self.mean = mean
        self.std = std
    
    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

class Cutout:
    def __init__(self, n_holes, length):
        self.n_holes = n_holes
        self.length = length
    
    def __call__(self, img):
        h, w = img.size(1), img.size(2)
        mask = torch.ones((h, w), dtype=torch.float32)
        
        for _ in range(self.n_holes):
            y = torch.randint(h, (1,)).item()
            x = torch.randint(w, (1,)).item()
            
            y1 = max(0, y - self.length // 2)
            y2 = min(h, y + self.length // 2)
            x1 = max(0, x - self.length // 2)
            x2 = min(w, x + self.length // 2)
            
            mask[y1:y2, x1:x2] = 0.
        
        mask = mask.expand_as(img)
        return img * mask

# ç»„åˆä½¿ç”¨
transform = transforms.Compose([
    transforms.ToTensor(),
    AddGaussianNoise(0., 0.1),
    Cutout(n_holes=1, length=16)
])
```

**ä½œä¸š**:
1. åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ç±»ï¼Œå®ç°è¯æ±‡è¡¨æ„å»ºå’Œåºåˆ—å¡«å……
2. å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆå¦‚Mixupï¼‰
3. ç¼–å†™ä¸€ä¸ªæ•°æ®é›†åˆ†æå·¥å…·ï¼Œç»Ÿè®¡å‡å€¼ã€æ ‡å‡†å·®ã€ç±»åˆ«åˆ†å¸ƒ

---

### 2.3 ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡è°ƒåº¦ (ç¬¬14å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡å¸¸ç”¨ä¼˜åŒ–å™¨çš„ä½¿ç”¨
- ç†è§£å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
- å­¦ä¼šè°ƒå‚æŠ€å·§

#### 2.3.1 å¸¸ç”¨ä¼˜åŒ–å™¨
```python
import torch.optim as optim

model = ... # ä½ çš„æ¨¡å‹

# 1. SGD (éšæœºæ¢¯åº¦ä¸‹é™)
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)

# 2. Adam
optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))

# 3. AdamW (å¸¦æƒé‡è¡°å‡çš„Adam)
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)

# 4. RMSprop
optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)

# 5. Adagrad
optimizer = optim.Adagrad(model.parameters(), lr=0.01)

# ä½¿ç”¨ä¼˜åŒ–å™¨
for epoch in range(num_epochs):
    for data, target in train_loader:
        optimizer.zero_grad()        # æ¸…é›¶æ¢¯åº¦
        output = model(data)         # å‰å‘ä¼ æ’­
        loss = criterion(output, target)
        loss.backward()              # åå‘ä¼ æ’­
        optimizer.step()             # æ›´æ–°å‚æ•°
```

#### 2.3.2 å­¦ä¹ ç‡è°ƒåº¦
```python
from torch.optim.lr_scheduler import *

# 1. StepLR: æ¯éš”step_sizeä¸ªepochè¡°å‡gammaå€
scheduler = StepLR(optimizer, step_size=30, gamma=0.1)

# 2. MultiStepLR: åœ¨æŒ‡å®šçš„epochè¡°å‡
scheduler = MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1)

# 3. ExponentialLR: æŒ‡æ•°è¡°å‡
scheduler = ExponentialLR(optimizer, gamma=0.95)

# 4. CosineAnnealingLR: ä½™å¼¦é€€ç«
scheduler = CosineAnnealingLR(optimizer, T_max=200)

# 5. ReduceLROnPlateau: æ ¹æ®æŒ‡æ ‡è‡ªé€‚åº”è°ƒæ•´
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)

# 6. OneCycleLR: å•å‘¨æœŸå­¦ä¹ ç‡ç­–ç•¥
scheduler = OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=10)

# ä½¿ç”¨ç¤ºä¾‹
for epoch in range(num_epochs):
    train(...)
    val_loss = validate(...)
    
    # æ ¹æ®schedulerç±»å‹è°ƒç”¨
    scheduler.step()  # StepLR, MultiStepLRç­‰
    # scheduler.step(val_loss)  # ReduceLROnPlateauéœ€è¦ä¼ å…¥æŒ‡æ ‡
```

#### 2.3.3 å­¦ä¹ ç‡é¢„çƒ­(Warmup)
```python
class WarmupScheduler:
    def __init__(self, optimizer, warmup_epochs, base_lr, target_lr):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.base_lr = base_lr
        self.target_lr = target_lr
    
    def step(self, epoch):
        if epoch < self.warmup_epochs:
            lr = self.base_lr + (self.target_lr - self.base_lr) * epoch / self.warmup_epochs
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = lr

# ä½¿ç”¨
warmup = WarmupScheduler(optimizer, warmup_epochs=5, base_lr=1e-6, target_lr=1e-3)
for epoch in range(num_epochs):
    warmup.step(epoch)
    train(...)
```

---

## ğŸ§  é˜¶æ®µ3: ç¥ç»ç½‘ç»œæ„å»ºä¸è®­ç»ƒ (ç¬¬4-6å‘¨)

### 3.1 nn.Moduleè¯¦è§£ (ç¬¬15-17å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡nn.Moduleçš„ä½¿ç”¨æ–¹æ³•
- å­¦ä¼šæ„å»ºè‡ªå®šä¹‰ç½‘ç»œå±‚
- ç†è§£æ¨¡å‹çš„ä¿å­˜ä¸åŠ è½½

#### 3.1.1 åŸºç¡€æ¨¡å‹æ„å»º
```python
import torch.nn as nn
import torch.nn.functional as F

class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleNet, self).__init__()
        # å®šä¹‰å±‚
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        # å®šä¹‰å‰å‘ä¼ æ’­
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# å®ä¾‹åŒ–æ¨¡å‹
model = SimpleNet(784, 128, 10)
print(model)

# æŸ¥çœ‹å‚æ•°
for name, param in model.named_parameters():
    print(f"{name}: {param.shape}")
```

#### 3.1.2 å¸¸ç”¨å±‚çš„ä½¿ç”¨
```python
# 1. å…¨è¿æ¥å±‚
fc = nn.Linear(in_features=100, out_features=50, bias=True)

# 2. å·ç§¯å±‚
conv2d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)
conv1d = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5)

# 3. æ± åŒ–å±‚
maxpool = nn.MaxPool2d(kernel_size=2, stride=2)
avgpool = nn.AdaptiveAvgPool2d((1, 1))

# 4. å½’ä¸€åŒ–å±‚
batchnorm1d = nn.BatchNorm1d(num_features=100)
batchnorm2d = nn.BatchNorm2d(num_features=64)
layernorm = nn.LayerNorm(normalized_shape=512)
instancenorm = nn.InstanceNorm2d(num_features=64)

# 5. Dropout
dropout = nn.Dropout(p=0.5)
dropout2d = nn.Dropout2d(p=0.2)

# 6. æ¿€æ´»å‡½æ•°
relu = nn.ReLU()
leaky_relu = nn.LeakyReLU(negative_slope=0.01)
sigmoid = nn.Sigmoid()
tanh = nn.Tanh()
gelu = nn.GELU()

# 7. å¾ªç¯å±‚
rnn = nn.RNN(input_size=100, hidden_size=256, num_layers=2, batch_first=True)
lstm = nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True)
gru = nn.GRU(input_size=100, hidden_size=256, num_layers=2, batch_first=True)

# 8. æ³¨æ„åŠ›æœºåˆ¶
multihead_attn = nn.MultiheadAttention(embed_dim=512, num_heads=8)

# 9. Transformer
transformer_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)
transformer = nn.TransformerEncoder(transformer_layer, num_layers=6)
```

#### 3.1.3 æ¨¡å‹ä¿å­˜ä¸åŠ è½½
```python
# 1. ä¿å­˜æ•´ä¸ªæ¨¡å‹
torch.save(model, 'model.pth')
model = torch.load('model.pth')

# 2. åªä¿å­˜å‚æ•°ï¼ˆæ¨èï¼‰
torch.save(model.state_dict(), 'model_weights.pth')
model = SimpleNet(784, 128, 10)
model.load_state_dict(torch.load('model_weights.pth'))

# 3. ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}
torch.save(checkpoint, 'checkpoint.pth')

# æ¢å¤è®­ç»ƒ
checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

# 4. è·¨è®¾å¤‡ä¿å­˜å’ŒåŠ è½½
# ä¿å­˜åœ¨GPUä¸Šè®­ç»ƒçš„æ¨¡å‹
torch.save(model.state_dict(), 'model.pth')

# åŠ è½½åˆ°CPU
model.load_state_dict(torch.load('model.pth', map_location='cpu'))

# åŠ è½½åˆ°æŒ‡å®šGPU
model.load_state_dict(torch.load('model.pth', map_location='cuda:1'))
```

---

### 3.2 å·ç§¯ç¥ç»ç½‘ç»œ(CNN) (ç¬¬18-21å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£å·ç§¯æ“ä½œçš„åŸç†
- æŒæ¡ç»å…¸CNNæ¶æ„
- å®ç°å›¾åƒåˆ†ç±»ä»»åŠ¡

#### 3.2.1 å·ç§¯å±‚è¯¦è§£
```python
# å·ç§¯æ“ä½œç¤ºä¾‹
import torch
import torch.nn as nn

# è¾“å…¥: (batch, channels, height, width)
input_tensor = torch.randn(1, 3, 32, 32)

# å·ç§¯å±‚å‚æ•°
conv = nn.Conv2d(
    in_channels=3,      # è¾“å…¥é€šé“æ•°
    out_channels=64,    # è¾“å‡ºé€šé“æ•°ï¼ˆå·ç§¯æ ¸æ•°é‡ï¼‰
    kernel_size=3,      # å·ç§¯æ ¸å¤§å°
    stride=1,           # æ­¥é•¿
    padding=1,          # å¡«å……
    bias=True           # æ˜¯å¦ä½¿ç”¨åç½®
)

output = conv(input_tensor)
print(f"è¾“å…¥å½¢çŠ¶: {input_tensor.shape}")
print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")  # torch.Size([1, 64, 32, 32])

# è®¡ç®—è¾“å‡ºå°ºå¯¸å…¬å¼
# output_size = (input_size - kernel_size + 2*padding) / stride + 1
```

#### 3.2.2 å®ç°LeNet-5
```python
class LeNet5(nn.Module):
    def __init__(self, num_classes=10):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 6, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(6, 16, kernel_size=5),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.classifier = nn.Sequential(
            nn.Linear(16 * 5 * 5, 120),
            nn.ReLU(),
            nn.Linear(120, 84),
            nn.ReLU(),
            nn.Linear(84, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.classifier(x)
        return x

model = LeNet5()
x = torch.randn(32, 1, 28, 28)
output = model(x)
print(output.shape)  # torch.Size([32, 10])
```

#### 3.2.3 å®ç°ResNetæ®‹å·®å—
```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, 
                         stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(residual)
        out = F.relu(out)
        return out

class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_channels = 64
        
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
    
    def _make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.avgpool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out

# ResNet-18
model = ResNet(ResidualBlock, [2, 2, 2, 2])
```

#### 3.2.4 å®Œæ•´çš„è®­ç»ƒè„šæœ¬
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

def train_epoch(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

def validate(model, test_loader, criterion, device):
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            
            test_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
    
    test_loss /= len(test_loader)
    test_acc = 100. * correct / total
    return test_loss, test_acc

# ä¸»è®­ç»ƒå¾ªç¯
def train_model(model, train_loader, test_loader, num_epochs=10):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
    
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
        test_loss, test_acc = validate(model, test_loader, criterion, device)
        
        print(f'Epoch {epoch+1}/{num_epochs}')
        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save(model.state_dict(), 'best_model.pth')
        
        scheduler.step()
    
    print(f'Best Test Accuracy: {best_acc:.2f}%')
```

**å®è·µé¡¹ç›®**:
1. åœ¨CIFAR-10æ•°æ®é›†ä¸Šè®­ç»ƒResNet-18
2. å®ç°æ•°æ®å¢å¼ºå¹¶å¯¹æ¯”æ•ˆæœ
3. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œè¿ç§»å­¦ä¹ 

---

### 3.3 å¾ªç¯ç¥ç»ç½‘ç»œ(RNN/LSTM/GRU) (ç¬¬22-24å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£åºåˆ—å»ºæ¨¡çš„åŸç†
- æŒæ¡RNNã€LSTMã€GRUçš„ä½¿ç”¨
- å®ç°æ–‡æœ¬åˆ†ç±»å’Œåºåˆ—é¢„æµ‹

#### 3.3.1 åŸºç¡€RNNå®ç°
```python
class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        # x: (batch, seq_len, input_size)
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        # out: (batch, seq_len, hidden_size)
        out = self.fc(out[:, -1, :])  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        return out
```

#### 3.3.2 LSTMå®ç°
```python
class LSTMModel(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classes, dropout=0.5):
        super(LSTMModel, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, 
                           batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, num_classes)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        # x: (batch, seq_len)
        embedded = self.dropout(self.embedding(x))
        # embedded: (batch, seq_len, embedding_dim)
        
        lstm_out, (hidden, cell) = self.lstm(embedded)
        # lstm_out: (batch, seq_len, hidden_size)
        # hidden: (num_layers, batch, hidden_size)
        
        # ä½¿ç”¨æœ€åä¸€å±‚çš„éšè—çŠ¶æ€
        output = self.fc(hidden[-1])
        return output

# åŒå‘LSTM
class BiLSTM(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classes):
        super(BiLSTM, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.bilstm = nn.LSTM(embedding_dim, hidden_size, num_layers,
                             batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 å› ä¸ºæ˜¯åŒå‘
    
    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out, (hidden, cell) = self.bilstm(embedded)
        # æ‹¼æ¥å‰å‘å’Œåå‘çš„æœ€åéšè—çŠ¶æ€
        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)
        output = self.fc(hidden)
        return output
```

#### 3.3.3 åºåˆ—åˆ°åºåˆ—(Seq2Seq)æ¨¡å‹
```python
class Seq2Seq(nn.Module):
    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):
        super(Seq2Seq, self).__init__()
        
        # ç¼–ç å™¨
        self.encoder_embedding = nn.Embedding(input_dim, embedding_dim)
        self.encoder_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        
        # è§£ç å™¨
        self.decoder_embedding = nn.Embedding(output_dim, embedding_dim)
        self.decoder_lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, src, trg):
        # ç¼–ç 
        embedded_src = self.encoder_embedding(src)
        _, (hidden, cell) = self.encoder_lstm(embedded_src)
        
        # è§£ç 
        embedded_trg = self.decoder_embedding(trg)
        decoder_output, _ = self.decoder_lstm(embedded_trg, (hidden, cell))
        output = self.fc(decoder_output)
        
        return output
```

**å®è·µé¡¹ç›®**:
1. å®ç°æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹ï¼ˆIMDBæ•°æ®é›†ï¼‰
2. å®ç°åºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰
3. å®ç°ç®€å•çš„æœºå™¨ç¿»è¯‘æ¨¡å‹

---

## ğŸš€ é˜¶æ®µ4: é«˜çº§æŠ€æœ¯ä¸ç‰¹æ€§ (ç¬¬7-9å‘¨)

### 4.1 è¿ç§»å­¦ä¹ ä¸é¢„è®­ç»ƒæ¨¡å‹ (ç¬¬25-27å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡è¿ç§»å­¦ä¹ çš„åŸç†å’Œæ–¹æ³•
- å­¦ä¼šä½¿ç”¨torchvisioné¢„è®­ç»ƒæ¨¡å‹
- å®ç°Fine-tuningæŠ€å·§

#### 4.1.1 ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
```python
import torchvision.models as models

# 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
resnet50 = models.resnet50(pretrained=True)
vgg16 = models.vgg16(pretrained=True)
efficientnet = models.efficientnet_b0(pretrained=True)

# 2. ç‰¹å¾æå–æ¨¡å¼ï¼ˆå†»ç»“å‚æ•°ï¼‰
model = models.resnet50(pretrained=True)
for param in model.parameters():
    param.requires_grad = False

# ä¿®æ”¹æœ€åä¸€å±‚
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 10)  # 10ä¸ªç±»åˆ«

# 3. Fine-tuningæ¨¡å¼ï¼ˆéƒ¨åˆ†è§£å†»ï¼‰
# å†»ç»“å‰é¢çš„å±‚
for name, param in model.named_parameters():
    if 'layer4' not in name and 'fc' not in name:
        param.requires_grad = False

# 4. ä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡
params_to_update = []
params_to_update_fc = []

for name, param in model.named_parameters():
    if param.requires_grad:
        if 'fc' in name:
            params_to_update_fc.append(param)
        else:
            params_to_update.append(param)

optimizer = optim.SGD([
    {'params': params_to_update, 'lr': 0.001},
    {'params': params_to_update_fc, 'lr': 0.01}
], momentum=0.9)
```

#### 4.1.2 è‡ªå®šä¹‰é¢„è®­ç»ƒæ¨¡å‹çš„ä½¿ç”¨
```python
class TransferLearningModel(nn.Module):
    def __init__(self, num_classes, freeze_backbone=True):
        super(TransferLearningModel, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒçš„ResNet
        backbone = models.resnet50(pretrained=True)
        
        if freeze_backbone:
            for param in backbone.parameters():
                param.requires_grad = False
        
        # æå–ç‰¹å¾æå–éƒ¨åˆ†
        self.features = nn.Sequential(*list(backbone.children())[:-1])
        
        # è‡ªå®šä¹‰åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

# æ¸è¿›å¼è§£å†»è®­ç»ƒ
def progressive_unfreezing(model, optimizer, train_loader, epochs_per_stage=5):
    stages = [
        ['layer4', 'classifier'],
        ['layer3', 'layer4', 'classifier'],
        ['layer2', 'layer3', 'layer4', 'classifier'],
    ]
    
    for stage, layers_to_train in enumerate(stages):
        print(f"Stage {stage + 1}: Training {layers_to_train}")
        
        # å†»ç»“æ‰€æœ‰å‚æ•°
        for param in model.parameters():
            param.requires_grad = False
        
        # è§£å†»æŒ‡å®šå±‚
        for name, param in model.named_parameters():
            if any(layer in name for layer in layers_to_train):
                param.requires_grad = True
        
        # è®­ç»ƒè¯¥é˜¶æ®µ
        for epoch in range(epochs_per_stage):
            train_epoch(model, train_loader, criterion, optimizer, device)
```

---

### 4.2 æ¨¡å‹éƒ¨ç½²ä¸ä¼˜åŒ– (ç¬¬28-30å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡æ¨¡å‹é‡åŒ–å’Œå‰ªææŠ€æœ¯
- å­¦ä¹ TorchScriptå’ŒONNXå¯¼å‡º
- äº†è§£æ¨¡å‹åŠ é€ŸæŠ€å·§

#### 4.2.1 æ¨¡å‹é‡åŒ–
```python
import torch.quantization as quantization

# 1. åŠ¨æ€é‡åŒ–ï¼ˆæœ€ç®€å•ï¼‰
model_fp32 = MyModel()
model_int8 = torch.quantization.quantize_dynamic(
    model_fp32, 
    {nn.Linear}, 
    dtype=torch.qint8
)

# 2. é™æ€é‡åŒ–
model_fp32.eval()
model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')
model_fp32_prepared = torch.quantization.prepare(model_fp32)

# æ ¡å‡†
with torch.no_grad():
    for data, _ in calibration_loader:
        model_fp32_prepared(data)

model_int8 = torch.quantization.convert(model_fp32_prepared)

# 3. é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(QAT)
model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')
model_fp32_qat = torch.quantization.prepare_qat(model_fp32)

# è®­ç»ƒ
for epoch in range(num_epochs):
    train(model_fp32_qat, train_loader, optimizer)

model_int8 = torch.quantization.convert(model_fp32_qat)
```

#### 4.2.2 TorchScriptå¯¼å‡º
```python
# 1. ä½¿ç”¨torch.jit.trace
model = MyModel()
model.eval()

example_input = torch.rand(1, 3, 224, 224)
traced_script_module = torch.jit.trace(model, example_input)

# ä¿å­˜
traced_script_module.save("model_traced.pt")

# åŠ è½½
loaded_model = torch.jit.load("model_traced.pt")

# 2. ä½¿ç”¨torch.jit.script
@torch.jit.script
def my_function(x):
    if x.sum() > 0:
        return x * 2
    else:
        return x / 2

class MyScriptModule(torch.nn.Module):
    def __init__(self):
        super(MyScriptModule, self).__init__()
        self.conv = nn.Conv2d(3, 64, 3)
    
    def forward(self, x):
        return F.relu(self.conv(x))

scripted_module = torch.jit.script(MyScriptModule())
scripted_module.save("model_scripted.pt")
```

#### 4.2.3 ONNXå¯¼å‡º
```python
import torch.onnx

model = MyModel()
model.eval()

dummy_input = torch.randn(1, 3, 224, 224)

# å¯¼å‡ºONNX
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)

# éªŒè¯ONNXæ¨¡å‹
import onnx
onnx_model = onnx.load("model.onnx")
onnx.checker.check_model(onnx_model)

# ä½¿ç”¨ONNX Runtimeæ¨ç†
import onnxruntime as ort
ort_session = ort.InferenceSession("model.onnx")
outputs = ort_session.run(
    None,
    {"input": dummy_input.numpy()}
)
```

---

### 4.3 é«˜çº§è®­ç»ƒæŠ€å·§ (ç¬¬31-33å¤©)

**å­¦ä¹ ç›®æ ‡**:
- æŒæ¡æ··åˆç²¾åº¦è®­ç»ƒ
- å­¦ä¹ æ¢¯åº¦è£å‰ªå’Œæ¢¯åº¦ç´¯ç§¯
- äº†è§£å¯¹æŠ—è®­ç»ƒå’Œæ­£åˆ™åŒ–

#### 4.3.1 æ··åˆç²¾åº¦è®­ç»ƒ
```python
from torch.cuda.amp import autocast, GradScaler

# åˆ›å»ºGradScaler
scaler = GradScaler()

for epoch in range(num_epochs):
    for data, target in train_loader:
        data, target = data.cuda(), target.cuda()
        
        optimizer.zero_grad()
        
        # è‡ªåŠ¨æ··åˆç²¾åº¦
        with autocast():
            output = model(data)
            loss = criterion(output, target)
        
        # ç¼©æ”¾æŸå¤±å¹¶åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        
        # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼‰
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        # æ›´æ–°æƒé‡
        scaler.step(optimizer)
        scaler.update()
```

#### 4.3.2 æ¢¯åº¦ç´¯ç§¯
```python
accumulation_steps = 4

optimizer.zero_grad()
for i, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)
    
    output = model(data)
    loss = criterion(output, target)
    
    # å½’ä¸€åŒ–æŸå¤±
    loss = loss / accumulation_steps
    loss.backward()
    
    # æ¯accumulation_stepsæ­¥æ›´æ–°ä¸€æ¬¡
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

#### 4.3.3 æ—©åœå’Œæ¨¡å‹æ£€æŸ¥ç‚¹
```python
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0, path='checkpoint.pth'):
        self.patience = patience
        self.min_delta = min_delta
        self.path = path
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
    
    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.save_checkpoint(model)
            self.counter = 0
    
    def save_checkpoint(self, model):
        torch.save(model.state_dict(), self.path)

# ä½¿ç”¨
early_stopping = EarlyStopping(patience=10)

for epoch in range(num_epochs):
    train_loss = train_epoch(model, train_loader, optimizer, criterion)
    val_loss = validate(model, val_loader, criterion)
    
    early_stopping(val_loss, model)
    
    if early_stopping.early_stop:
        print("Early stopping triggered")
        break
```

---

### 4.4 Transformerä¸æ³¨æ„åŠ›æœºåˆ¶ (ç¬¬34-36å¤©)

**å­¦ä¹ ç›®æ ‡**:
- ç†è§£æ³¨æ„åŠ›æœºåˆ¶åŸç†
- å®ç°Transformeræ¨¡å‹
- æŒæ¡ä½ç½®ç¼–ç 

#### 4.4.1 è‡ªæ³¨æ„åŠ›æœºåˆ¶
```python
class SelfAttention(nn.Module):
    def __init__(self, embed_size, heads):
        super(SelfAttention, self).__init__()
        self.embed_size = embed_size
        self.heads = heads
        self.head_dim = embed_size // heads
        
        assert (self.head_dim * heads == embed_size), "Embed size needs to be divisible by heads"
        
        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)
        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)
    
    def forward(self, values, keys, query, mask=None):
        N = query.shape[0]
        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]
        
        # åˆ†å‰²æˆå¤šå¤´
        values = values.reshape(N, value_len, self.heads, self.head_dim)
        keys = keys.reshape(N, key_len, self.heads, self.head_dim)
        queries = query.reshape(N, query_len, self.heads, self.head_dim)
        
        values = self.values(values)
        keys = self.keys(keys)
        queries = self.queries(queries)
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        energy = torch.einsum("nqhd,nkhd->nhqk", [queries, keys])
        
        if mask is not None:
            energy = energy.masked_fill(mask == 0, float("-1e20"))
        
        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)
        
        out = torch.einsum("nhql,nlhd->nqhd", [attention, values]).reshape(
            N, query_len, self.heads * self.head_dim
        )
        
        out = self.fc_out(out)
        return out
```

#### 4.4.2 ä½ç½®ç¼–ç 
```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        x = x + self.pe[:, :x.size(1), :]
        return x
```

#### 4.4.3 å®Œæ•´Transformerç¼–ç å™¨
```python
import math

class TransformerBlock(nn.Module):
    def __init__(self, embed_size, heads, dropout, forward_expansion):
        super(TransformerBlock, self).__init__()
        self.attention = SelfAttention(embed_size, heads)
        self.norm1 = nn.LayerNorm(embed_size)
        self.norm2 = nn.LayerNorm(embed_size)
        
        self.feed_forward = nn.Sequential(
            nn.Linear(embed_size, forward_expansion * embed_size),
            nn.ReLU(),
            nn.Linear(forward_expansion * embed_size, embed_size)
        )
        
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, value, key, query, mask):
        attention = self.attention(value, key, query, mask)
        x = self.dropout(self.norm1(attention + query))
        forward = self.feed_forward(x)
        out = self.dropout(self.norm2(forward + x))
        return out

class TransformerEncoder(nn.Module):
    def __init__(self, vocab_size, embed_size, num_layers, heads, 
                 forward_expansion, dropout, max_length):
        super(TransformerEncoder, self).__init__()
        self.embed_size = embed_size
        self.word_embedding = nn.Embedding(vocab_size, embed_size)
        self.position_embedding = nn.Embedding(max_length, embed_size)
        
        self.layers = nn.ModuleList([
            TransformerBlock(embed_size, heads, dropout, forward_expansion)
            for _ in range(num_layers)
        ])
        
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x, mask):
        N, seq_length = x.shape
        positions = torch.arange(0, seq_length).expand(N, seq_length).to(x.device)
        
        out = self.dropout(
            self.word_embedding(x) + self.position_embedding(positions)
        )
        
        for layer in self.layers:
            out = layer(out, out, out, mask)
        
        return out
```

---

## ğŸ’¼ é˜¶æ®µ5: ç»¼åˆé¡¹ç›®å®æˆ˜ (ç¬¬10-12å‘¨)

### 5.1 è®¡ç®—æœºè§†è§‰é¡¹ç›® (ç¬¬37-39å¤©)

**é¡¹ç›®1: å›¾åƒåˆ†ç±»ç³»ç»Ÿ**
- æ•°æ®é›†ï¼šè‡ªå®šä¹‰æ•°æ®é›†æˆ–Kaggleç«èµ›æ•°æ®
- ä»»åŠ¡ï¼šå®ç°ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹
- æŠ€æœ¯ç‚¹ï¼šæ•°æ®å¢å¼ºã€è¿ç§»å­¦ä¹ ã€æ¨¡å‹é›†æˆ

**é¡¹ç›®2: ç›®æ ‡æ£€æµ‹**
- ä½¿ç”¨torchvisionå®ç°Faster R-CNNæˆ–YOLO
- åœ¨COCOæˆ–VOCæ•°æ®é›†ä¸Šè®­ç»ƒ
- å®ç°å®æ—¶æ£€æµ‹ç³»ç»Ÿ

**é¡¹ç›®3: å›¾åƒåˆ†å‰²**
- å®ç°U-Netæˆ–DeepLab
- è¯­ä¹‰åˆ†å‰²æˆ–å®ä¾‹åˆ†å‰²ä»»åŠ¡
- åŒ»å­¦å›¾åƒæˆ–å«æ˜Ÿå›¾åƒåˆ†å‰²

---

### 5.2 è‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›® (ç¬¬40-42å¤©)

**é¡¹ç›®1: æ–‡æœ¬åˆ†ç±»**
- æƒ…æ„Ÿåˆ†ææˆ–ä¸»é¢˜åˆ†ç±»
- ä½¿ç”¨LSTM/GRUæˆ–Transformer
- éƒ¨ç½²ä¸ºREST API

**é¡¹ç›®2: å‘½åå®ä½“è¯†åˆ«**
- ä½¿ç”¨BiLSTM-CRFæ¨¡å‹
- ä¸­æ–‡æˆ–è‹±æ–‡NERä»»åŠ¡
- å®ç°å®æ—¶æ ‡æ³¨ç³»ç»Ÿ

**é¡¹ç›®3: æ–‡æœ¬ç”Ÿæˆ**
- å®ç°ç®€å•çš„GPTé£æ ¼æ¨¡å‹
- è¯—æ­Œç”Ÿæˆæˆ–å¯¹è¯ç”Ÿæˆ
- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹Fine-tuning

---

### 5.3 æ¨èç³»ç»Ÿé¡¹ç›® (ç¬¬43-44å¤©)

**é¡¹ç›®: ååŒè¿‡æ»¤æ¨èç³»ç»Ÿ**
- å®ç°çŸ©é˜µåˆ†è§£æˆ–ç¥ç»ååŒè¿‡æ»¤
- åœ¨MovieLensæ•°æ®é›†ä¸Šè®­ç»ƒ
- å®ç°TopNæ¨è

---

### 5.4 ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)é¡¹ç›® (ç¬¬45-46å¤©)

**é¡¹ç›®: å›¾åƒç”Ÿæˆ**
```python
# DCGANç¤ºä¾‹
class Generator(nn.Module):
    def __init__(self, nz, ngf, nc):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
        )
    
    def forward(self, input):
        return self.main(input)

class Discriminator(nn.Module):
    def __init__(self, nc, ndf):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, input):
        return self.main(input)
```

---

## ğŸ“– å­¦ä¹ èµ„æºæ¨è

### å®˜æ–¹æ–‡æ¡£
- **PyTorchå®˜æ–¹æ–‡æ¡£**: https://pytorch.org/docs/
- **PyTorch Tutorials**: https://pytorch.org/tutorials/
- **torchvisionæ–‡æ¡£**: https://pytorch.org/vision/

### åœ¨çº¿è¯¾ç¨‹
- **Fast.ai**: Practical Deep Learning for Coders
- **Coursera**: Deep Learning Specialization (Andrew Ng)
- **Udacity**: Deep Learning Nanodegree

### ä¹¦ç±æ¨è
- ã€ŠDeep Learning with PyTorchã€‹
- ã€ŠProgramming PyTorch for Deep Learningã€‹
- ã€ŠPyTorchæ·±åº¦å­¦ä¹ å®æˆ˜ã€‹

### ç¤¾åŒºèµ„æº
- **PyTorchè®ºå›**: https://discuss.pytorch.org/
- **GitHub**: pytorch/pytorch, pytorch/examples
- **Papers with Code**: æœ€æ–°è®ºæ–‡å’Œå®ç°

---

## âœ… å­¦ä¹ æ£€æŸ¥æ¸…å•

### åŸºç¡€éƒ¨åˆ†
- [ ] ç†Ÿç»ƒåˆ›å»ºå’Œæ“ä½œå¼ é‡
- [ ] ç†è§£GPUåŠ é€ŸåŸç†
- [ ] æŒæ¡è‡ªåŠ¨å¾®åˆ†æœºåˆ¶
- [ ] ä¼šä½¿ç”¨DataLoaderåŠ è½½æ•°æ®

### æ¨¡å‹æ„å»º
- [ ] èƒ½å¤Ÿä½¿ç”¨nn.Moduleæ„å»ºæ¨¡å‹
- [ ] ç†è§£å¸¸ç”¨å±‚çš„ä½œç”¨
- [ ] æŒæ¡æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
- [ ] ä¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹

### è®­ç»ƒæŠ€å·§
- [ ] æŒæ¡å¸¸ç”¨ä¼˜åŒ–å™¨
- [ ] ä¼šä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
- [ ] ç†è§£æ­£åˆ™åŒ–æ–¹æ³•
- [ ] èƒ½å¤Ÿè°ƒè¯•è®­ç»ƒè¿‡ç¨‹

### é«˜çº§ç‰¹æ€§
- [ ] æŒæ¡æ··åˆç²¾åº¦è®­ç»ƒ
- [ ] äº†è§£æ¨¡å‹é‡åŒ–
- [ ] ä¼šå¯¼å‡ºONNXæ¨¡å‹
- [ ] ç†è§£åˆ†å¸ƒå¼è®­ç»ƒ

### é¡¹ç›®å®æˆ˜
- [ ] å®Œæˆè‡³å°‘3ä¸ªå®Œæ•´é¡¹ç›®
- [ ] èƒ½å¤Ÿéƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§
- [ ] æŒæ¡æ¨¡å‹ä¼˜åŒ–æŠ€å·§
- [ ] æœ‰é˜…è¯»è®ºæ–‡å®ç°çš„èƒ½åŠ›

---

## ğŸ¯ æ¯æ—¥å­¦ä¹ å»ºè®®

### æ—¶é—´å®‰æ’
- **ç†è®ºå­¦ä¹ **: 30-45åˆ†é’Ÿ
- **ä»£ç å®è·µ**: 60-90åˆ†é’Ÿ
- **é¡¹ç›®ç»ƒä¹ **: 30-45åˆ†é’Ÿ
- **æ€»ç»“å¤ä¹ **: 15-30åˆ†é’Ÿ

### å­¦ä¹ æ–¹æ³•
1. **ä¸»åŠ¨å®è·µ**: æ¯ä¸ªçŸ¥è¯†ç‚¹éƒ½è¦äº²æ‰‹ç¼–å†™ä»£ç 
2. **è®°å½•ç¬”è®°**: æ•´ç†é‡ç‚¹å’Œè¸©è¿‡çš„å‘
3. **æŸ¥é˜…æ–‡æ¡£**: å…»æˆæŸ¥çœ‹å®˜æ–¹æ–‡æ¡£çš„ä¹ æƒ¯
4. **ç¤¾åŒºäº¤æµ**: å‚ä¸è®ºå›è®¨è®ºï¼Œå­¦ä¹ ä»–äººç»éªŒ
5. **é¡¹ç›®é©±åŠ¨**: ä»¥é¡¹ç›®ä¸ºå¯¼å‘ï¼Œå­¦ä»¥è‡´ç”¨

### å¸¸è§é—®é¢˜è§£å†³
- **CUDA out of memory**: å‡å°batch sizeï¼Œä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- **æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±**: ä½¿ç”¨æ¢¯åº¦è£å‰ªï¼Œè°ƒæ•´å­¦ä¹ ç‡
- **è¿‡æ‹Ÿåˆ**: å¢åŠ æ•°æ®å¢å¼ºï¼Œä½¿ç”¨Dropoutï¼Œæ­£åˆ™åŒ–
- **è®­ç»ƒå¤ªæ…¢**: æ£€æŸ¥æ•°æ®åŠ è½½ï¼Œä½¿ç”¨å¤šè¿›ç¨‹ï¼ŒGPUåŠ é€Ÿ

---

## ğŸ† è¿›é˜¶æ–¹å‘

å®ŒæˆåŸºç¡€å­¦ä¹ åï¼Œå¯ä»¥æ ¹æ®å…´è¶£é€‰æ‹©ä»¥ä¸‹æ–¹å‘æ·±å…¥ï¼š

1. **è®¡ç®—æœºè§†è§‰**: ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€3Dè§†è§‰
2. **è‡ªç„¶è¯­è¨€å¤„ç†**: å¤§è¯­è¨€æ¨¡å‹ã€æœºå™¨ç¿»è¯‘ã€é—®ç­”ç³»ç»Ÿ
3. **å¼ºåŒ–å­¦ä¹ **: DQNã€PPOã€AlphaGoç®—æ³•
4. **å›¾ç¥ç»ç½‘ç»œ**: GCNã€GATã€å›¾åˆ†ç±»ä»»åŠ¡
5. **æ¨¡å‹å‹ç¼©**: é‡åŒ–ã€å‰ªæã€çŸ¥è¯†è’¸é¦
6. **åˆ†å¸ƒå¼è®­ç»ƒ**: DDPã€FSDPã€å¤§è§„æ¨¡è®­ç»ƒ

---

## ğŸ“ æ€»ç»“

è¿™ä»½å­¦ä¹ è®¡åˆ’æ¶µç›–äº†ä»PyTorchåŸºç¡€åˆ°é«˜çº§åº”ç”¨çš„å®Œæ•´è·¯å¾„ã€‚å»ºè®®ï¼š

1. **å¾ªåºæ¸è¿›**: ä¸è¦è·³è·ƒå¼å­¦ä¹ ï¼Œæ‰“ç‰¢åŸºç¡€å¾ˆé‡è¦
2. **æŒä¹‹ä»¥æ’**: æ¯å¤©ä¿æŒ2-3å°æ—¶çš„é«˜è´¨é‡å­¦ä¹ æ—¶é—´
3. **å¤šåŠ¨æ‰‹ç»ƒ**: ç†è®ºç»“åˆå®è·µï¼Œä»£ç æ˜¯æœ€å¥½çš„è€å¸ˆ
4. **åŠæ—¶æ€»ç»“**: å®šæœŸå›é¡¾æ‰€å­¦å†…å®¹ï¼Œå»ºç«‹çŸ¥è¯†ä½“ç³»
5. **å‚ä¸ç¤¾åŒº**: ä¸ä»–äººäº¤æµï¼Œå…±åŒè¿›æ­¥

ç¥æ‚¨å­¦ä¹ é¡ºåˆ©ï¼Œæ—©æ—¥æˆä¸ºPyTorché«˜æ‰‹ï¼ğŸš€
