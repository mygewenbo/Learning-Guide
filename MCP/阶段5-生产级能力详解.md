# é˜¶æ®µ 5ï¼šç”Ÿäº§çº§èƒ½åŠ›è¯¦è§£

> **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡å°† MCP Server ä» Demo è½¬å˜ä¸ºå¯é•¿æœŸè¿è¡Œçš„ç”Ÿäº§çº§æœåŠ¡çš„å…³é”®æŠ€æœ¯
> 
> **å‰ç½®è¦æ±‚**ï¼šå·²å®Œæˆé˜¶æ®µ 3ï¼ˆServer å¼€å‘ï¼‰å’Œé˜¶æ®µ 4ï¼ˆClient/Host é›†æˆï¼‰
> 
> **é¢„è®¡æ—¶é—´**ï¼š3-5 å¤©

---

## ğŸ“– æœ¬é˜¶æ®µå¯¼è¯»

åœ¨å‰é¢çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº† MCP çš„åŸºæœ¬æ¦‚å¿µå’Œå¼€å‘æŠ€èƒ½ã€‚ä½†æ˜¯ï¼Œè¦å°†ä¸€ä¸ªç®€å•çš„ Demo åº”ç”¨è½¬å˜ä¸ºå¯åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šè¿è¡Œçš„æœåŠ¡ï¼Œè¿˜éœ€è¦è€ƒè™‘è®¸å¤šå…³é”®é—®é¢˜ï¼š

### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦ç”Ÿäº§çº§èƒ½åŠ›ï¼Ÿ

å½“ä½ çš„ MCP Server ä»å¼€å‘é˜¶æ®µè¿›å…¥ç”Ÿäº§ç¯å¢ƒæ—¶ï¼Œä¼šé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

1. **é•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§**
   - Demo å¯èƒ½åªè¿è¡Œå‡ åˆ†é’Ÿç”¨äºæ¼”ç¤º
   - ç”Ÿäº§ç¯å¢ƒéœ€è¦ 7Ã—24 å°æ—¶ä¸é—´æ–­è¿è¡Œ
   - éœ€è¦ä¼˜é›…åœ°å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ

2. **èµ„æºç®¡ç†é—®é¢˜**
   - æ•°æ®åº“è¿æ¥ä¼šä¸ä¼šæ³„æ¼ï¼Ÿ
   - å†…å­˜ä½¿ç”¨æ˜¯å¦å¯æ§ï¼Ÿ
   - å¤–éƒ¨ API è°ƒç”¨æ˜¯å¦æœ‰åˆç†çš„é™åˆ¶ï¼Ÿ

3. **æ€§èƒ½ä¸æ•ˆç‡**
   - é‡å¤çš„è¯·æ±‚æ˜¯å¦å¯ä»¥ç¼“å­˜ï¼Ÿ
   - æ…¢æŸ¥è¯¢å¦‚ä½•ä¼˜åŒ–ï¼Ÿ
   - å¹¶å‘è¯·æ±‚å¦‚ä½•å¤„ç†ï¼Ÿ

4. **å¯è§‚æµ‹æ€§**
   - å‡ºç°é—®é¢˜æ—¶å¦‚ä½•å¿«é€Ÿå®šä½ï¼Ÿ
   - ç³»ç»Ÿè¿è¡ŒçŠ¶å†µå¦‚ä½•ç›‘æ§ï¼Ÿ
   - ç”¨æˆ·è¡Œä¸ºå¦‚ä½•è¿½è¸ªï¼Ÿ

5. **å®‰å…¨æ€§**
   - æ•æ„Ÿæ•°æ®å¦‚ä½•ä¿æŠ¤ï¼Ÿ
   - æƒé™å¦‚ä½•æ§åˆ¶ï¼Ÿ
   - æ¶æ„è¯·æ±‚å¦‚ä½•é˜²èŒƒï¼Ÿ

6. **å¯ç»´æŠ¤æ€§**
   - ä»£ç å¦‚ä½•æµ‹è¯•ï¼Ÿ
   - æ–°åŠŸèƒ½å¦‚ä½•éªŒè¯ï¼Ÿ
   - é—®é¢˜å¦‚ä½•è°ƒè¯•ï¼Ÿ

### ğŸ“š æœ¬é˜¶æ®µå†…å®¹æ¦‚è§ˆ

æœ¬é˜¶æ®µå°†ç³»ç»Ÿè®²è§£è¿™äº›ç”Ÿäº§çº§èƒ½åŠ›çš„å®ç°æ–¹æ³•ï¼š

```
é˜¶æ®µ5ï¼šç”Ÿäº§çº§èƒ½åŠ›è¯¦è§£
â”‚
â”œâ”€â”€ 1. ç”Ÿå‘½å‘¨æœŸä¸ä¸Šä¸‹æ–‡ç®¡ç†
â”‚   â”œâ”€â”€ ç†è§£ MCP Server ç”Ÿå‘½å‘¨æœŸ
â”‚   â”œâ”€â”€ ä½¿ç”¨ lifespan ç®¡ç†èµ„æº
â”‚   â”œâ”€â”€ ä¸Šä¸‹æ–‡å¯¹è±¡çš„è®¾è®¡ä¸ä½¿ç”¨
â”‚   â””â”€â”€ ä¼˜é›…å…³é—­ä¸æ¸…ç†
â”‚
â”œâ”€â”€ 2. çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ ä¼šè¯çº§çŠ¶æ€
â”‚   â”œâ”€â”€ åº”ç”¨çº§çŠ¶æ€
â”‚   â”œâ”€â”€ æŒä¹…åŒ–çŠ¶æ€
â”‚   â””â”€â”€ çŠ¶æ€åŒæ­¥ä¸ä¸€è‡´æ€§
â”‚
â”œâ”€â”€ 3. ç¼“å­˜ä¸æ€§èƒ½ä¼˜åŒ–
â”‚   â”œâ”€â”€ ç¼“å­˜ç­–ç•¥è®¾è®¡
â”‚   â”œâ”€â”€ å¤šçº§ç¼“å­˜æ¶æ„
â”‚   â”œâ”€â”€ ç¼“å­˜å¤±æ•ˆä¸æ›´æ–°
â”‚   â””â”€â”€ æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜
â”‚
â”œâ”€â”€ 4. æ—¥å¿—ä¸ç›‘æ§
â”‚   â”œâ”€â”€ ç»“æ„åŒ–æ—¥å¿—
â”‚   â”œâ”€â”€ æ—¥å¿—çº§åˆ«ä¸åˆ†ç±»
â”‚   â”œâ”€â”€ ç›‘æ§æŒ‡æ ‡æ”¶é›†
â”‚   â””â”€â”€ å‘Šè­¦ä¸é€šçŸ¥
â”‚
â”œâ”€â”€ 5. å®‰å…¨æ€§ä¸æƒé™æ§åˆ¶
â”‚   â”œâ”€â”€ è®¤è¯ä¸æˆæƒ
â”‚   â”œâ”€â”€ æ•°æ®åŠ å¯†ä¸è„±æ•
â”‚   â”œâ”€â”€ è¾“å…¥éªŒè¯ä¸é˜²æŠ¤
â”‚   â””â”€â”€ å®‰å…¨å®¡è®¡
â”‚
â”œâ”€â”€ 6. æµ‹è¯•ä¸è°ƒè¯•
â”‚   â”œâ”€â”€ å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ å‹åŠ›æµ‹è¯•
â”‚   â””â”€â”€ è°ƒè¯•æŠ€å·§
â”‚
â””â”€â”€ 7. æœ€ä½³å®è·µä¸éƒ¨ç½²
    â”œâ”€â”€ ä»£ç ç»„ç»‡
    â”œâ”€â”€ é…ç½®ç®¡ç†
    â”œâ”€â”€ éƒ¨ç½²ç­–ç•¥
    â””â”€â”€ è¿ç»´å»ºè®®
```

### ğŸ“ å­¦ä¹ æ–¹æ³•å»ºè®®

1. **å¾ªåºæ¸è¿›**ï¼šå…ˆç†è§£æ¦‚å¿µï¼Œå†çœ‹ä»£ç ï¼Œæœ€åå®è·µ
2. **å¯¹æ¯”æ€è€ƒ**ï¼šæ¯”è¾ƒ Demo ç‰ˆæœ¬å’Œç”Ÿäº§ç‰ˆæœ¬çš„å·®å¼‚
3. **åŠ¨æ‰‹å®è·µ**ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½å°è¯•å†™ä»£ç å®ç°
4. **æŸ¥é˜…æ–‡æ¡£**ï¼šé‡åˆ°ä¸æ¸…æ¥šçš„åœ°æ–¹åŠæ—¶æŸ¥é˜…å®˜æ–¹æ–‡æ¡£
5. **æ€»ç»“å½’çº³**ï¼šæ¯å®Œæˆä¸€ä¸ªéƒ¨åˆ†ï¼Œæ€»ç»“å…³é”®è¦ç‚¹

---

## 1. ç”Ÿå‘½å‘¨æœŸä¸ä¸Šä¸‹æ–‡ç®¡ç†

### 1.1 ç†è§£ MCP Server ç”Ÿå‘½å‘¨æœŸ

MCP Server çš„ç”Ÿå‘½å‘¨æœŸæ˜¯æŒ‡ä»æœåŠ¡å¯åŠ¨åˆ°å…³é—­çš„æ•´ä¸ªè¿‡ç¨‹ã€‚ç†è§£ç”Ÿå‘½å‘¨æœŸå¯¹äºç®¡ç†èµ„æºã€ç»´æŠ¤çŠ¶æ€è‡³å…³é‡è¦ã€‚

#### å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MCP Server ç”Ÿå‘½å‘¨æœŸ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. å¯åŠ¨å‰å‡†å¤‡ï¼ˆStartupï¼‰
   â†“
   - åŠ è½½é…ç½®æ–‡ä»¶
   - åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
   - å‡†å¤‡èµ„æºï¼ˆæ•°æ®åº“è¿æ¥æ± ã€ç¼“å­˜ç­‰ï¼‰
   
2. æœåŠ¡åˆå§‹åŒ–ï¼ˆInitializeï¼‰
   â†“
   - æ¥æ”¶ Client çš„ initialize è¯·æ±‚
   - äº¤æ¢èƒ½åŠ›åå•†
   - å‘é€ initialized é€šçŸ¥
   
3. è¿è¡Œé˜¶æ®µï¼ˆRunningï¼‰
   â†“
   - å¤„ç†å·¥å…·è°ƒç”¨
   - è¯»å–èµ„æº
   - è·å–æç¤º
   - å‘é€é€šçŸ¥
   
4. å…³é—­å‰æ¸…ç†ï¼ˆShutdownï¼‰
   â†“
   - å®Œæˆå½“å‰è¯·æ±‚
   - ä¿å­˜çŠ¶æ€
   - é‡Šæ”¾èµ„æº
   - è®°å½•ç»Ÿè®¡ä¿¡æ¯
   
5. æœåŠ¡ç»ˆæ­¢ï¼ˆTerminatedï¼‰
   â†“
   - è¿›ç¨‹é€€å‡º
```

#### ä¸ºä»€ä¹ˆéœ€è¦ç®¡ç†ç”Ÿå‘½å‘¨æœŸï¼Ÿ

**é—®é¢˜åœºæ™¯ 1ï¼šèµ„æºæ³„æ¼**

```python
# âŒ ä¸å¥½çš„åšæ³•ï¼šæ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°è¿æ¥
@app.tool()
async def query_database(query: str):
    # æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„æ•°æ®åº“è¿æ¥
    db = create_database_connection()
    result = db.execute(query)
    # å¿˜è®°å…³é—­è¿æ¥ï¼
    return result
```

**åæœ**ï¼š
- éšç€è°ƒç”¨æ¬¡æ•°å¢åŠ ï¼Œæ•°æ®åº“è¿æ¥æ•°ä¸æ–­å¢é•¿
- æœ€ç»ˆè€—å°½è¿æ¥æ± ï¼Œå¯¼è‡´æœåŠ¡å´©æºƒ
- æ•°æ®åº“æœåŠ¡å™¨å‹åŠ›è¿‡å¤§

**é—®é¢˜åœºæ™¯ 2ï¼šåˆå§‹åŒ–å¼€é”€**

```python
# âŒ ä¸å¥½çš„åšæ³•ï¼šæ¯æ¬¡éƒ½é‡æ–°åŠ è½½æ¨¡å‹
@app.tool()
async def analyze_text(text: str):
    # æ¯æ¬¡éƒ½åŠ è½½ AI æ¨¡å‹ï¼ˆè€—æ—¶ 10 ç§’ï¼‰
    model = load_large_ai_model()
    result = model.analyze(text)
    return result
```

**åæœ**ï¼š
- æ¯æ¬¡è°ƒç”¨éƒ½éœ€è¦ç­‰å¾… 10 ç§’åŠ è½½æ¨¡å‹
- é‡å¤åŠ è½½æµªè´¹å†…å­˜å’Œ CPU
- ç”¨æˆ·ä½“éªŒæå·®

**âœ… æ­£ç¡®çš„åšæ³•ï¼šä½¿ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†**

```python
# åœ¨å¯åŠ¨æ—¶åˆå§‹åŒ–ï¼Œåœ¨å…³é—­æ—¶æ¸…ç†
@app.lifespan()
async def lifespan(ctx):
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    print("ğŸš€ Server æ­£åœ¨å¯åŠ¨...")
    
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
    db_pool = await create_connection_pool()
    
    # åŠ è½½ AI æ¨¡å‹ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
    ai_model = await load_large_ai_model()
    
    # ä¿å­˜åˆ°ä¸Šä¸‹æ–‡ä¸­
    ctx.db_pool = db_pool
    ctx.ai_model = ai_model
    
    print("âœ… Server å¯åŠ¨å®Œæˆï¼")
    
    # yield ä¹‹åæ˜¯å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
    yield
    
    # å…³é—­æ—¶æ¸…ç†èµ„æº
    print("ğŸ›‘ Server æ­£åœ¨å…³é—­...")
    await db_pool.close()
    await ai_model.unload()
    print("âœ… èµ„æºæ¸…ç†å®Œæˆï¼")
```

### 1.2 ä½¿ç”¨ lifespan ç®¡ç†èµ„æº

`lifespan` æ˜¯ MCP Server æä¾›çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æœºåˆ¶ï¼Œè®©ä½ å¯ä»¥åœ¨æœåŠ¡å¯åŠ¨å’Œå…³é—­æ—¶æ‰§è¡Œç‰¹å®šçš„é€»è¾‘ã€‚

#### åŸºæœ¬ç”¨æ³•

```python
from mcp.server import Server
from contextlib import asynccontextmanager

app = Server("my-production-server")

@app.lifespan()
async def lifespan(ctx):
    """
    ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
    - yield ä¹‹å‰ï¼šå¯åŠ¨æ—¶æ‰§è¡Œ
    - yield ä¹‹åï¼šå…³é—­æ—¶æ‰§è¡Œ
    """
    # === å¯åŠ¨é˜¶æ®µ ===
    print("=" * 50)
    print("ğŸš€ æœåŠ¡å¯åŠ¨ä¸­...")
    
    # ä½ çš„åˆå§‹åŒ–ä»£ç 
    # ...
    
    print("âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼")
    print("=" * 50)
    
    # yield åˆ†éš”å¯åŠ¨å’Œå…³é—­
    yield
    
    # === å…³é—­é˜¶æ®µ ===
    print("=" * 50)
    print("ğŸ›‘ æœåŠ¡å…³é—­ä¸­...")
    
    # ä½ çš„æ¸…ç†ä»£ç 
    # ...
    
    print("âœ… æ¸…ç†å®Œæˆï¼")
    print("=" * 50)
```

#### å®æˆ˜ç¤ºä¾‹ï¼šç®¡ç†æ•°æ®åº“è¿æ¥æ± 

```python
import asyncpg
from typing import Optional

app = Server("database-server")

# å…¨å±€å˜é‡ï¼ˆä¸æ¨èï¼Œè¿™é‡Œä»…ä½œç¤ºä¾‹ï¼‰
db_pool: Optional[asyncpg.Pool] = None

@app.lifespan()
async def lifespan(ctx):
    """ç®¡ç†æ•°æ®åº“è¿æ¥æ± çš„ç”Ÿå‘½å‘¨æœŸ"""
    global db_pool
    
    # === å¯åŠ¨ï¼šåˆ›å»ºè¿æ¥æ±  ===
    print("ğŸ“¦ åˆ›å»ºæ•°æ®åº“è¿æ¥æ± ...")
    
    db_pool = await asyncpg.create_pool(
        host="localhost",
        port=5432,
        user="myuser",
        password="mypassword",
        database="mydb",
        min_size=5,      # æœ€å°è¿æ¥æ•°
        max_size=20,     # æœ€å¤§è¿æ¥æ•°
        command_timeout=60.0  # æŸ¥è¯¢è¶…æ—¶æ—¶é—´
    )
    
    print(f"âœ… è¿æ¥æ± åˆ›å»ºå®Œæˆï¼š{db_pool.get_size()} ä¸ªè¿æ¥")
    
    yield  # æœåŠ¡è¿è¡Œä¸­
    
    # === å…³é—­ï¼šé‡Šæ”¾è¿æ¥æ±  ===
    print("ğŸ”Œ å…³é—­æ•°æ®åº“è¿æ¥æ± ...")
    
    if db_pool:
        await db_pool.close()
        print("âœ… è¿æ¥æ± å·²å…³é—­")

# åœ¨å·¥å…·ä¸­ä½¿ç”¨è¿æ¥æ± 
@app.tool()
async def query_users(name: str):
    """æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯"""
    if not db_pool:
        return {"error": "æ•°æ®åº“æœªåˆå§‹åŒ–"}
    
    async with db_pool.acquire() as conn:
        result = await conn.fetchrow(
            "SELECT * FROM users WHERE name = $1",
            name
        )
        return dict(result) if result else None
```

#### å®æˆ˜ç¤ºä¾‹ï¼šç®¡ç†ç¼“å­˜ç³»ç»Ÿ

```python
import aioredis
from typing import Optional

app = Server("cache-server")

# ä½¿ç”¨ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆæ¨èæ–¹å¼ï¼‰
@app.lifespan()
async def lifespan(ctx):
    """ç®¡ç† Redis ç¼“å­˜çš„ç”Ÿå‘½å‘¨æœŸ"""
    
    # === å¯åŠ¨ï¼šè¿æ¥ Redis ===
    print("ğŸ”— è¿æ¥åˆ° Redis...")
    
    redis_client = await aioredis.create_redis_pool(
        "redis://localhost:6379",
        minsize=5,
        maxsize=10,
        encoding="utf-8"
    )
    
    # ä¿å­˜åˆ°ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆæ¨èï¼‰
    ctx.redis = redis_client
    
    print("âœ… Redis è¿æ¥æˆåŠŸ")
    
    # æµ‹è¯•è¿æ¥
    await redis_client.set("server:status", "running")
    status = await redis_client.get("server:status")
    print(f"ğŸ“ Redis æµ‹è¯•ï¼š{status}")
    
    yield  # æœåŠ¡è¿è¡Œ
    
    # === å…³é—­ï¼šæ–­å¼€ Redis ===
    print("ğŸ“¤ å…³é—­ Redis è¿æ¥...")
    
    # ä¿å­˜æœ€åçŠ¶æ€
    await redis_client.set("server:status", "stopped")
    
    # å…³é—­è¿æ¥
    redis_client.close()
    await redis_client.wait_closed()
    
    print("âœ… Redis è¿æ¥å·²å…³é—­")

# åœ¨å·¥å…·ä¸­è®¿é—® Redis
@app.tool()
async def get_cached_data(key: str, ctx):
    """ä»ç¼“å­˜è·å–æ•°æ®"""
    redis = ctx.request_context.lifespan_context.redis
    
    value = await redis.get(f"cache:{key}")
    
    if value:
        print(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­ï¼š{key}")
        return {"cached": True, "value": value}
    else:
        print(f"âŒ ç¼“å­˜æœªå‘½ä¸­ï¼š{key}")
        return {"cached": False}

@app.tool()
async def set_cached_data(key: str, value: str, ctx, ttl: int = 3600):
    """è®¾ç½®ç¼“å­˜æ•°æ®"""
    redis = ctx.request_context.lifespan_context.redis
    
    await redis.setex(f"cache:{key}", ttl, value)
    print(f"ğŸ’¾ ç¼“å­˜å·²ä¿å­˜ï¼š{key}ï¼ˆTTL: {ttl}ç§’ï¼‰")
    
    return {"success": True, "key": key}
```

### 1.3 ä¸Šä¸‹æ–‡å¯¹è±¡çš„è®¾è®¡ä¸ä½¿ç”¨

ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆContextï¼‰æ˜¯åœ¨æ•´ä¸ª Server ç”Ÿå‘½å‘¨æœŸä¸­å…±äº«æ•°æ®çš„å…³é”®æœºåˆ¶ã€‚

#### ä¸Šä¸‹æ–‡çš„å±‚æ¬¡ç»“æ„

```python
"""
MCP ä¸Šä¸‹æ–‡å±‚æ¬¡ç»“æ„ï¼š

Context (ctx)
â”‚
â”œâ”€â”€ request_context           # å•ä¸ªè¯·æ±‚çš„ä¸Šä¸‹æ–‡
â”‚   â”œâ”€â”€ session              # ä¼šè¯ä¿¡æ¯
â”‚   â”œâ”€â”€ request_id           # è¯·æ±‚ ID
â”‚   â””â”€â”€ lifespan_context     # ç”Ÿå‘½å‘¨æœŸä¸Šä¸‹æ–‡ï¼ˆå…±äº«èµ„æºï¼‰
â”‚       â”œâ”€â”€ db_pool          # æ•°æ®åº“è¿æ¥æ± 
â”‚       â”œâ”€â”€ redis            # Redis å®¢æˆ·ç«¯
â”‚       â”œâ”€â”€ http_client      # HTTP å®¢æˆ·ç«¯
â”‚       â””â”€â”€ config           # é…ç½®ä¿¡æ¯
â”‚
â””â”€â”€ app_context              # åº”ç”¨çº§ä¸Šä¸‹æ–‡
    â”œâ”€â”€ statistics           # ç»Ÿè®¡ä¿¡æ¯
    â””â”€â”€ shared_state         # å…±äº«çŠ¶æ€
"""
```

#### è®¾è®¡è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ç±»

```python
from dataclasses import dataclass, field
from typing import Dict, Any, Optional
import asyncpg
import aioredis
import httpx

@dataclass
class AppContext:
    """åº”ç”¨çº§ä¸Šä¸‹æ–‡"""
    
    # å…±äº«èµ„æº
    db_pool: Optional[asyncpg.Pool] = None
    redis_client: Optional[aioredis.Redis] = None
    http_client: Optional[httpx.AsyncClient] = None
    
    # é…ç½®ä¿¡æ¯
    config: Dict[str, Any] = field(default_factory=dict)
    
    # ç»Ÿè®¡ä¿¡æ¯
    request_count: int = 0
    error_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    
    # è¿è¡Œæ—¶ä¿¡æ¯
    start_time: Optional[float] = None
    
    def increment_request(self):
        """å¢åŠ è¯·æ±‚è®¡æ•°"""
        self.request_count += 1
    
    def increment_error(self):
        """å¢åŠ é”™è¯¯è®¡æ•°"""
        self.error_count += 1
    
    def record_cache_hit(self):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.cache_hits += 1
    
    def record_cache_miss(self):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.cache_misses += 1
    
    def get_cache_hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.cache_hits + self.cache_misses
        if total == 0:
            return 0.0
        return self.cache_hits / total * 100
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        import time
        uptime = time.time() - self.start_time if self.start_time else 0
        
        return {
            "uptime_seconds": uptime,
            "request_count": self.request_count,
            "error_count": self.error_count,
            "cache_hit_rate": f"{self.get_cache_hit_rate():.2f}%",
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses
        }
```

#### åœ¨ lifespan ä¸­ä½¿ç”¨è‡ªå®šä¹‰ä¸Šä¸‹æ–‡

```python
import time
from pathlib import Path
import json

app = Server("production-server")

@app.lifespan()
async def lifespan(ctx):
    """å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ç¤ºä¾‹"""
    
    print("=" * 60)
    print("ğŸš€ ç”Ÿäº§çº§æœåŠ¡å¯åŠ¨ä¸­...")
    print("=" * 60)
    
    # === 1. åˆ›å»ºåº”ç”¨ä¸Šä¸‹æ–‡ ===
    app_ctx = AppContext()
    app_ctx.start_time = time.time()
    
    # === 2. åŠ è½½é…ç½® ===
    print("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
    config_path = Path("config.json")
    if config_path.exists():
        with open(config_path) as f:
            app_ctx.config = json.load(f)
        print(f"âœ… é…ç½®åŠ è½½å®Œæˆï¼š{len(app_ctx.config)} é¡¹")
    else:
        print("âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        app_ctx.config = {
            "db_host": "localhost",
            "db_port": 5432,
            "redis_url": "redis://localhost:6379",
            "cache_ttl": 3600
        }
    
    # === 3. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ±  ===
    print("ğŸ“¦ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± ...")
    try:
        app_ctx.db_pool = await asyncpg.create_pool(
            host=app_ctx.config["db_host"],
            port=app_ctx.config["db_port"],
            user=app_ctx.config.get("db_user", "postgres"),
            password=app_ctx.config.get("db_password", ""),
            database=app_ctx.config.get("db_name", "mydb"),
            min_size=5,
            max_size=20
        )
        print(f"âœ… æ•°æ®åº“è¿æ¥æ± å°±ç»ªï¼š{app_ctx.db_pool.get_size()} ä¸ªè¿æ¥")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
        app_ctx.db_pool = None
    
    # === 4. è¿æ¥ Redis ===
    print("ğŸ”— è¿æ¥ Redis...")
    try:
        app_ctx.redis_client = await aioredis.create_redis_pool(
            app_ctx.config["redis_url"],
            minsize=5,
            maxsize=10
        )
        print("âœ… Redis è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Redis è¿æ¥å¤±è´¥ï¼š{e}")
        app_ctx.redis_client = None
    
    # === 5. åˆ›å»º HTTP å®¢æˆ·ç«¯ ===
    print("ğŸŒ åˆ›å»º HTTP å®¢æˆ·ç«¯...")
    app_ctx.http_client = httpx.AsyncClient(
        timeout=30.0,
        limits=httpx.Limits(max_connections=100)
    )
    print("âœ… HTTP å®¢æˆ·ç«¯å°±ç»ª")
    
    # === 6. ä¿å­˜ä¸Šä¸‹æ–‡ ===
    ctx.app_context = app_ctx
    
    print("=" * 60)
    print("âœ… æœåŠ¡å¯åŠ¨å®Œæˆï¼")
    print(f"ğŸ“Š å¯åŠ¨æ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # æœåŠ¡è¿è¡Œä¸­...
    yield
    
    # === å…³é—­é˜¶æ®µ ===
    print("\n" + "=" * 60)
    print("ğŸ›‘ æœåŠ¡å…³é—­ä¸­...")
    print("=" * 60)
    
    # === 1. æ‰“å°ç»Ÿè®¡ä¿¡æ¯ ===
    stats = app_ctx.get_statistics()
    print("\nğŸ“Š è¿è¡Œç»Ÿè®¡ï¼š")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # === 2. å…³é—­ HTTP å®¢æˆ·ç«¯ ===
    if app_ctx.http_client:
        print("\nğŸŒ å…³é—­ HTTP å®¢æˆ·ç«¯...")
        await app_ctx.http_client.aclose()
        print("âœ… HTTP å®¢æˆ·ç«¯å·²å…³é—­")
    
    # === 3. æ–­å¼€ Redis ===
    if app_ctx.redis_client:
        print("ğŸ“¤ æ–­å¼€ Redis...")
        app_ctx.redis_client.close()
        await app_ctx.redis_client.wait_closed()
        print("âœ… Redis å·²æ–­å¼€")
    
    # === 4. å…³é—­æ•°æ®åº“è¿æ¥æ±  ===
    if app_ctx.db_pool:
        print("ğŸ”Œ å…³é—­æ•°æ®åº“è¿æ¥æ± ...")
        await app_ctx.db_pool.close()
        print("âœ… æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")
    
    print("\n" + "=" * 60)
    print("âœ… æœåŠ¡å·²å®‰å…¨å…³é—­")
    print("=" * 60)
```



---

## 2. çŠ¶æ€ç®¡ç†è¯¦è§£

### 2.1 ç†è§£çŠ¶æ€çš„ä¸åŒå±‚æ¬¡

åœ¨ MCP Server ä¸­ï¼ŒçŠ¶æ€ç®¡ç†éœ€è¦è€ƒè™‘ä¸åŒçš„å±‚æ¬¡å’Œç”Ÿå‘½å‘¨æœŸã€‚ç†è§£è¿™äº›å±‚æ¬¡å¯¹äºè®¾è®¡å¯é çš„ç³»ç»Ÿè‡³å…³é‡è¦ã€‚

#### çŠ¶æ€çš„ä¸‰ä¸ªå±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          çŠ¶æ€ç®¡ç†å±‚æ¬¡å›¾                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. è¯·æ±‚çº§çŠ¶æ€ï¼ˆRequest Stateï¼‰
   - ç”Ÿå‘½å‘¨æœŸï¼šå•æ¬¡è¯·æ±‚å¤„ç†æœŸé—´
   - ç”¨é€”ï¼šè¯·æ±‚å‚æ•°ã€ä¸­é—´ç»“æœã€ä¸´æ—¶å˜é‡
   - ç‰¹ç‚¹ï¼šè¯·æ±‚ç»“æŸåç«‹å³é‡Šæ”¾
   
   ç¤ºä¾‹ï¼š
   - å½“å‰å¤„ç†çš„æŸ¥è¯¢å‚æ•°
   - API è°ƒç”¨çš„ä¸´æ—¶ç»“æœ
   - è®¡ç®—çš„ä¸­é—´å€¼

2. ä¼šè¯çº§çŠ¶æ€ï¼ˆSession Stateï¼‰
   - ç”Ÿå‘½å‘¨æœŸï¼šClient è¿æ¥æœŸé—´
   - ç”¨é€”ï¼šç”¨æˆ·åå¥½ã€ä¼šè¯å†å²ã€ä¸´æ—¶ç¼“å­˜
   - ç‰¹ç‚¹ï¼šè¿æ¥æ–­å¼€åé‡Šæ”¾
   
   ç¤ºä¾‹ï¼š
   - ç”¨æˆ·çš„æŸ¥è¯¢å†å²
   - ä¼šè¯é…ç½®ï¼ˆè¯­è¨€ã€åå¥½ç­‰ï¼‰
   - ä¸´æ—¶ç¼“å­˜çš„ç»“æœ

3. åº”ç”¨çº§çŠ¶æ€ï¼ˆApplication Stateï¼‰
   - ç”Ÿå‘½å‘¨æœŸï¼šServer è¿è¡ŒæœŸé—´
   - ç”¨é€”ï¼šå…¨å±€é…ç½®ã€ç»Ÿè®¡ä¿¡æ¯ã€å…±äº«èµ„æº
   - ç‰¹ç‚¹ï¼šServer å…³é—­åé‡Šæ”¾ï¼ˆé™¤éæŒä¹…åŒ–ï¼‰
   
   ç¤ºä¾‹ï¼š
   - è¯·æ±‚è®¡æ•°ç»Ÿè®¡
   - å…¨å±€ç¼“å­˜
   - é…ç½®ä¿¡æ¯
```

#### ä¸ºä»€ä¹ˆè¦åŒºåˆ†çŠ¶æ€å±‚æ¬¡ï¼Ÿ

**åœºæ™¯è¯´æ˜**ï¼š
å‡è®¾æˆ‘ä»¬è¦å¼€å‘ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ MCP Serverï¼Œå®ƒéœ€è¦ï¼š
1. è®°ä½ç”¨æˆ·åœ¨å½“å‰å¯¹è¯ä¸­çš„é—®é¢˜ï¼ˆä¼šè¯çº§ï¼‰
2. ç»Ÿè®¡æ€»å…±å¤„ç†äº†å¤šå°‘è¯·æ±‚ï¼ˆåº”ç”¨çº§ï¼‰
3. å¤„ç†å½“å‰è¯·æ±‚çš„ä¸´æ—¶æ•°æ®ï¼ˆè¯·æ±‚çº§ï¼‰

å¦‚æœä¸åŒºåˆ†å±‚æ¬¡ï¼Œå¯èƒ½ä¼šé‡åˆ°ï¼š
- å†…å­˜æ³„æ¼ï¼šä¼šè¯ç»“æŸäº†ï¼Œä½†æ•°æ®è¿˜å ç€å†…å­˜
- æ•°æ®æ··ä¹±ï¼šä¸åŒç”¨æˆ·çš„æ•°æ®äº’ç›¸å¹²æ‰°
- æ€§èƒ½é—®é¢˜ï¼šä¸éœ€è¦æŒä¹…åŒ–çš„æ•°æ®å´è¢«ä¿å­˜åˆ°ç£ç›˜

### 2.2 è¯·æ±‚çº§çŠ¶æ€ç®¡ç†

è¯·æ±‚çº§çŠ¶æ€æ˜¯æœ€ç®€å•çš„ï¼Œé€šå¸¸ä½œä¸ºå‡½æ•°å‚æ•°æˆ–å±€éƒ¨å˜é‡å­˜åœ¨ã€‚

#### åŸºæœ¬ç¤ºä¾‹

```python
@app.tool()
async def process_text(text: str, mode: str = "summary"):
    """å¤„ç†æ–‡æœ¬çš„å·¥å…·"""
    
    # === è¯·æ±‚çº§çŠ¶æ€ ===
    # è¿™äº›å˜é‡åªåœ¨è¿™ä¸ªè¯·æ±‚å¤„ç†æœŸé—´å­˜åœ¨
    
    input_length = len(text)
    words = text.split()
    word_count = len(words)
    
    # æ ¹æ®æ¨¡å¼å¤„ç†
    if mode == "summary":
        result = generate_summary(text)
    elif mode == "translate":
        result = translate_text(text)
    else:
        result = text
    
    # è¿”å›ç»“æœï¼ˆè¯·æ±‚ç»“æŸï¼Œæ‰€æœ‰å±€éƒ¨å˜é‡è‡ªåŠ¨é‡Šæ”¾ï¼‰
    return {
        "result": result,
        "input_length": input_length,
        "word_count": word_count
    }
```

#### è¯·æ±‚ä¸Šä¸‹æ–‡ä¼ é€’

æœ‰æ—¶éœ€è¦åœ¨å¤šä¸ªå‡½æ•°ä¹‹é—´ä¼ é€’è¯·æ±‚ç›¸å…³çš„ä¿¡æ¯ï¼š

```python
from dataclasses import dataclass
from typing import Optional
import time
import uuid

@dataclass
class RequestContext:
    """è¯·æ±‚ä¸Šä¸‹æ–‡"""
    request_id: str
    start_time: float
    user_id: Optional[str] = None
    metadata: dict = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    def get_elapsed_time(self) -> float:
        """è·å–è¯·æ±‚å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰"""
        return time.time() - self.start_time
    
    def log_info(self, message: str):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        elapsed = self.get_elapsed_time()
        print(f"[{self.request_id}] [{elapsed:.3f}s] {message}")


@app.tool()
async def complex_operation(data: str, ctx):
    """å¤æ‚æ“ä½œç¤ºä¾‹"""
    
    # åˆ›å»ºè¯·æ±‚ä¸Šä¸‹æ–‡
    req_ctx = RequestContext(
        request_id=str(uuid.uuid4()),
        start_time=time.time(),
        user_id=ctx.request_context.session.get("user_id")
    )
    
    req_ctx.log_info("å¼€å§‹å¤„ç†è¯·æ±‚")
    
    # æ­¥éª¤ 1ï¼šéªŒè¯æ•°æ®
    req_ctx.log_info("éªŒè¯æ•°æ®...")
    is_valid = await validate_data(data, req_ctx)
    if not is_valid:
        return {"error": "æ•°æ®éªŒè¯å¤±è´¥"}
    
    # æ­¥éª¤ 2ï¼šå¤„ç†æ•°æ®
    req_ctx.log_info("å¤„ç†æ•°æ®...")
    result = await process_data(data, req_ctx)
    
    # æ­¥éª¤ 3ï¼šä¿å­˜ç»“æœ
    req_ctx.log_info("ä¿å­˜ç»“æœ...")
    await save_result(result, req_ctx)
    
    req_ctx.log_info(f"è¯·æ±‚å®Œæˆï¼Œæ€»è€—æ—¶ï¼š{req_ctx.get_elapsed_time():.3f}ç§’")
    
    return result


async def validate_data(data: str, req_ctx: RequestContext) -> bool:
    """éªŒè¯æ•°æ®ï¼ˆå¯ä»¥è®¿é—®è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰"""
    req_ctx.log_info(f"éªŒè¯æ•°æ®é•¿åº¦ï¼š{len(data)}")
    return len(data) > 0


async def process_data(data: str, req_ctx: RequestContext):
    """å¤„ç†æ•°æ®"""
    req_ctx.log_info("æ‰§è¡Œæ•°æ®å¤„ç†é€»è¾‘...")
    # å¤„ç†é€»è¾‘...
    return {"processed": data.upper()}


async def save_result(result, req_ctx: RequestContext):
    """ä¿å­˜ç»“æœ"""
    req_ctx.log_info(f"ä¿å­˜ç»“æœï¼š{result}")
    # ä¿å­˜é€»è¾‘...
```

### 2.3 ä¼šè¯çº§çŠ¶æ€ç®¡ç†

ä¼šè¯çº§çŠ¶æ€ç”¨äºå­˜å‚¨ä¸ç‰¹å®š Client è¿æ¥ç›¸å…³çš„æ•°æ®ã€‚

#### ä¼šè¯çŠ¶æ€è®¾è®¡

```python
from dataclasses import dataclass, field
from typing import List, Dict, Any
from datetime import datetime

@dataclass
class SessionState:
    """ä¼šè¯çŠ¶æ€"""
    
    # ä¼šè¯æ ‡è¯†
    session_id: str
    created_at: datetime = field(default_factory=datetime.now)
    
    # ç”¨æˆ·ä¿¡æ¯
    user_id: Optional[str] = None
    user_name: Optional[str] = None
    
    # ä¼šè¯å†å²
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    query_history: List[str] = field(default_factory=list)
    
    # ä¼šè¯åå¥½
    preferences: Dict[str, Any] = field(default_factory=dict)
    
    # ç»Ÿè®¡ä¿¡æ¯
    request_count: int = 0
    error_count: int = 0
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ å¯¹è¯æ¶ˆæ¯"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > 100:
            self.conversation_history = self.conversation_history[-100:]
    
    def add_query(self, query: str):
        """æ·»åŠ æŸ¥è¯¢å†å²"""
        self.query_history.append(query)
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.query_history) > 50:
            self.query_history = self.query_history[-50:]
    
    def get_recent_queries(self, n: int = 10) -> List[str]:
        """è·å–æœ€è¿‘çš„æŸ¥è¯¢"""
        return self.query_history[-n:]
    
    def set_preference(self, key: str, value: Any):
        """è®¾ç½®åå¥½"""
        self.preferences[key] = value
    
    def get_preference(self, key: str, default=None):
        """è·å–åå¥½"""
        return self.preferences.get(key, default)
```

#### ä¼šè¯çŠ¶æ€ç®¡ç†å™¨

```python
from typing import Dict
import uuid

class SessionManager:
    """ä¼šè¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.sessions: Dict[str, SessionState] = {}
    
    def create_session(self, user_id: Optional[str] = None) -> SessionState:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_id = str(uuid.uuid4())
        session = SessionState(
            session_id=session_id,
            user_id=user_id
        )
        self.sessions[session_id] = session
        
        print(f"âœ… åˆ›å»ºä¼šè¯ï¼š{session_id}")
        return session
    
    def get_session(self, session_id: str) -> Optional[SessionState]:
        """è·å–ä¼šè¯"""
        return self.sessions.get(session_id)
    
    def delete_session(self, session_id: str):
        """åˆ é™¤ä¼šè¯"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            print(f"ğŸ—‘ï¸  åˆ é™¤ä¼šè¯ï¼š{session_id}")
    
    def get_active_session_count(self) -> int:
        """è·å–æ´»è·ƒä¼šè¯æ•°"""
        return len(self.sessions)
    
    def cleanup_old_sessions(self, max_age_hours: int = 24):
        """æ¸…ç†æ—§ä¼šè¯"""
        from datetime import datetime, timedelta
        
        now = datetime.now()
        expired_sessions = []
        
        for session_id, session in self.sessions.items():
            age = now - session.created_at
            if age > timedelta(hours=max_age_hours):
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            self.delete_session(session_id)
        
        if expired_sessions:
            print(f"ğŸ§¹ æ¸…ç†äº† {len(expired_sessions)} ä¸ªè¿‡æœŸä¼šè¯")


# åœ¨ lifespan ä¸­åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
@app.lifespan()
async def lifespan(ctx):
    # å¯åŠ¨æ—¶åˆ›å»ºä¼šè¯ç®¡ç†å™¨
    session_manager = SessionManager()
    ctx.session_manager = session_manager
    
    print("âœ… ä¼šè¯ç®¡ç†å™¨å·²åˆå§‹åŒ–")
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†æ‰€æœ‰ä¼šè¯
    session_count = session_manager.get_active_session_count()
    print(f"ğŸ“Š å½“å‰æ´»è·ƒä¼šè¯æ•°ï¼š{session_count}")
```

#### åœ¨å·¥å…·ä¸­ä½¿ç”¨ä¼šè¯çŠ¶æ€

```python
@app.tool()
async def chat(message: str, ctx, session_id: Optional[str] = None):
    """èŠå¤©å·¥å…·ï¼ˆå¸¦ä¼šè¯çŠ¶æ€ï¼‰"""
    
    # è·å–ä¼šè¯ç®¡ç†å™¨
    session_manager = ctx.request_context.lifespan_context.session_manager
    
    # è·å–æˆ–åˆ›å»ºä¼šè¯
    if session_id:
        session = session_manager.get_session(session_id)
        if not session:
            return {"error": f"ä¼šè¯ä¸å­˜åœ¨ï¼š{session_id}"}
    else:
        # åˆ›å»ºæ–°ä¼šè¯
        session = session_manager.create_session()
        session_id = session.session_id
    
    # å¢åŠ è¯·æ±‚è®¡æ•°
    session.request_count += 1
    
    # è®°å½•ç”¨æˆ·æ¶ˆæ¯
    session.add_message("user", message)
    session.add_query(message)
    
    # ç”Ÿæˆå›å¤ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
    response = f"æ”¶åˆ°æ¶ˆæ¯ï¼š{message}"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å†å²ä¸Šä¸‹æ–‡
    recent_queries = session.get_recent_queries(3)
    if len(recent_queries) > 1:
        response += f"\n\nä½ æœ€è¿‘è¿˜é—®è¿‡ï¼š{', '.join(recent_queries[:-1])}"
    
    # è®°å½•åŠ©æ‰‹å›å¤
    session.add_message("assistant", response)
    
    return {
        "session_id": session_id,
        "response": response,
        "conversation_length": len(session.conversation_history),
        "total_requests": session.request_count
    }


@app.tool()
async def get_session_info(session_id: str, ctx):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    session_manager = ctx.request_context.lifespan_context.session_manager
    session = session_manager.get_session(session_id)
    
    if not session:
        return {"error": "ä¼šè¯ä¸å­˜åœ¨"}
    
    return {
        "session_id": session.session_id,
        "created_at": session.created_at.isoformat(),
        "request_count": session.request_count,
        "conversation_length": len(session.conversation_history),
        "recent_queries": session.get_recent_queries(5)
    }


@app.tool()
async def set_preference(session_id: str, key: str, value: str, ctx):
    """è®¾ç½®ä¼šè¯åå¥½"""
    session_manager = ctx.request_context.lifespan_context.session_manager
    session = session_manager.get_session(session_id)
    
    if not session:
        return {"error": "ä¼šè¯ä¸å­˜åœ¨"}
    
    session.set_preference(key, value)
    
    return {
        "success": True,
        "session_id": session_id,
        "preference": {key: value}
    }
```

### 2.4 åº”ç”¨çº§çŠ¶æ€ç®¡ç†

åº”ç”¨çº§çŠ¶æ€æ˜¯å…¨å±€å…±äº«çš„ï¼Œåœ¨æ•´ä¸ª Server ç”Ÿå‘½å‘¨æœŸä¸­å­˜åœ¨ã€‚

#### åº”ç”¨çŠ¶æ€è®¾è®¡

```python
from dataclasses import dataclass, field
from typing import Dict, Any, Set
from datetime import datetime
import threading

@dataclass
class ApplicationState:
    """åº”ç”¨çº§çŠ¶æ€"""
    
    # å¯åŠ¨ä¿¡æ¯
    start_time: datetime = field(default_factory=datetime.now)
    version: str = "1.0.0"
    
    # å…¨å±€ç»Ÿè®¡
    total_requests: int = 0
    total_errors: int = 0
    total_tool_calls: Dict[str, int] = field(default_factory=dict)
    
    # å…¨å±€ç¼“å­˜
    global_cache: Dict[str, Any] = field(default_factory=dict)
    
    # æ´»è·ƒè¿æ¥
    active_connections: Set[str] = field(default_factory=set)
    
    # çº¿ç¨‹é”ï¼ˆç”¨äºå¹¶å‘æ§åˆ¶ï¼‰
    _lock: threading.Lock = field(default_factory=threading.Lock)
    
    def increment_request(self):
        """å¢åŠ è¯·æ±‚è®¡æ•°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._lock:
            self.total_requests += 1
    
    def increment_error(self):
        """å¢åŠ é”™è¯¯è®¡æ•°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._lock:
            self.total_errors += 1
    
    def record_tool_call(self, tool_name: str):
        """è®°å½•å·¥å…·è°ƒç”¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._lock:
            if tool_name not in self.total_tool_calls:
                self.total_tool_calls[tool_name] = 0
            self.total_tool_calls[tool_name] += 1
    
    def add_connection(self, connection_id: str):
        """æ·»åŠ è¿æ¥"""
        with self._lock:
            self.active_connections.add(connection_id)
    
    def remove_connection(self, connection_id: str):
        """ç§»é™¤è¿æ¥"""
        with self._lock:
            self.active_connections.discard(connection_id)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        uptime = datetime.now() - self.start_time
        
        with self._lock:
            return {
                "version": self.version,
                "uptime_seconds": uptime.total_seconds(),
                "uptime_formatted": str(uptime),
                "total_requests": self.total_requests,
                "total_errors": self.total_errors,
                "error_rate": f"{(self.total_errors / max(self.total_requests, 1)) * 100:.2f}%",
                "active_connections": len(self.active_connections),
                "tool_calls": dict(self.total_tool_calls),
                "cache_size": len(self.global_cache)
            }
    
    def get_cache(self, key: str, default=None):
        """è·å–ç¼“å­˜"""
        with self._lock:
            return self.global_cache.get(key, default)
    
    def set_cache(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜"""
        with self._lock:
            self.global_cache[key] = value
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self.global_cache.clear()
```

#### åœ¨ lifespan ä¸­åˆå§‹åŒ–åº”ç”¨çŠ¶æ€

```python
@app.lifespan()
async def lifespan(ctx):
    """åˆå§‹åŒ–åº”ç”¨çŠ¶æ€"""
    
    print("=" * 60)
    print("ğŸš€ åˆå§‹åŒ–åº”ç”¨çŠ¶æ€...")
    
    # åˆ›å»ºåº”ç”¨çŠ¶æ€
    app_state = ApplicationState(version="1.0.0")
    ctx.app_state = app_state
    
    print(f"âœ… åº”ç”¨çŠ¶æ€å·²åˆå§‹åŒ–")
    print(f"ğŸ“… å¯åŠ¨æ—¶é—´ï¼š{app_state.start_time}")
    print(f"ğŸ·ï¸  ç‰ˆæœ¬ï¼š{app_state.version}")
    print("=" * 60)
    
    yield
    
    # å…³é—­æ—¶æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯ï¼š")
    stats = app_state.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    print("=" * 60)
```

#### åœ¨å·¥å…·ä¸­ä½¿ç”¨åº”ç”¨çŠ¶æ€

```python
@app.tool()
async def search(query: str, ctx):
    """æœç´¢å·¥å…·ï¼ˆä½¿ç”¨åº”ç”¨çº§ç¼“å­˜ï¼‰"""
    
    # è·å–åº”ç”¨çŠ¶æ€
    app_state = ctx.request_context.lifespan_context.app_state
    
    # è®°å½•è¯·æ±‚
    app_state.increment_request()
    app_state.record_tool_call("search")
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"search:{query}"
    cached_result = app_state.get_cache(cache_key)
    
    if cached_result:
        print(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­ï¼š{query}")
        return {
            "cached": True,
            "result": cached_result
        }
    
    # æ‰§è¡Œæœç´¢
    print(f"ğŸ” æ‰§è¡Œæœç´¢ï¼š{query}")
    result = f"æœç´¢ç»“æœï¼š{query}"
    
    # ä¿å­˜åˆ°ç¼“å­˜
    app_state.set_cache(cache_key, result)
    
    return {
        "cached": False,
        "result": result
    }


@app.tool()
async def get_stats(ctx):
    """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    app_state = ctx.request_context.lifespan_context.app_state
    return app_state.get_statistics()


@app.tool()
async def clear_cache(ctx):
    """æ¸…ç©ºå…¨å±€ç¼“å­˜"""
    app_state = ctx.request_context.lifespan_context.app_state
    app_state.clear_cache()
    return {"success": True, "message": "ç¼“å­˜å·²æ¸…ç©º"}
```

### 2.5 æŒä¹…åŒ–çŠ¶æ€ç®¡ç†

å¯¹äºéœ€è¦åœ¨ Server é‡å¯åä¿ç•™çš„çŠ¶æ€ï¼Œéœ€è¦æŒä¹…åŒ–åˆ°ç£ç›˜æˆ–æ•°æ®åº“ã€‚

#### ç®€å•çš„æ–‡ä»¶æŒä¹…åŒ–

```python
import json
import pickle
from pathlib import Path

class PersistentState:
    """æŒä¹…åŒ–çŠ¶æ€ç®¡ç†"""
    
    def __init__(self, storage_path: str = "server_state.json"):
        self.storage_path = Path(storage_path)
        self.data = {}
        self.load()
    
    def load(self):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€"""
        if self.storage_path.exists():
            try:
                with open(self.storage_path, 'r') as f:
                    self.data = json.load(f)
                print(f"âœ… åŠ è½½æŒä¹…åŒ–çŠ¶æ€ï¼š{len(self.data)} é¡¹")
            except Exception as e:
                print(f"âš ï¸  åŠ è½½çŠ¶æ€å¤±è´¥ï¼š{e}")
                self.data = {}
        else:
            print("ğŸ“ åˆ›å»ºæ–°çš„çŠ¶æ€æ–‡ä»¶")
            self.data = {}
    
    def save(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶"""
        try:
            with open(self.storage_path, 'w') as f:
                json.dump(self.data, f, indent=2)
            print(f"ğŸ’¾ ä¿å­˜æŒä¹…åŒ–çŠ¶æ€ï¼š{len(self.data)} é¡¹")
        except Exception as e:
            print(f"âŒ ä¿å­˜çŠ¶æ€å¤±è´¥ï¼š{e}")
    
    def get(self, key: str, default=None):
        """è·å–å€¼"""
        return self.data.get(key, default)
    
    def set(self, key: str, value: Any):
        """è®¾ç½®å€¼"""
        self.data[key] = value
    
    def delete(self, key: str):
        """åˆ é™¤å€¼"""
        if key in self.data:
            del self.data[key]
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        self.data = {}


# åœ¨ lifespan ä¸­ä½¿ç”¨
@app.lifespan()
async def lifespan(ctx):
    # å¯åŠ¨æ—¶åŠ è½½æŒä¹…åŒ–çŠ¶æ€
    persistent_state = PersistentState("server_state.json")
    ctx.persistent_state = persistent_state
    
    # æ¢å¤ä¸Šæ¬¡çš„ç»Ÿè®¡ä¿¡æ¯
    total_lifetime_requests = persistent_state.get("total_lifetime_requests", 0)
    print(f"ğŸ“Š å†å²æ€»è¯·æ±‚æ•°ï¼š{total_lifetime_requests}")
    
    yield
    
    # å…³é—­æ—¶ä¿å­˜çŠ¶æ€
    app_state = ctx.app_state
    persistent_state.set("total_lifetime_requests", 
                         total_lifetime_requests + app_state.total_requests)
    persistent_state.set("last_shutdown", datetime.now().isoformat())
    persistent_state.save()
```

---



## 3. ç¼“å­˜ä¸æ€§èƒ½ä¼˜åŒ–

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜ï¼Ÿ

ç¼“å­˜æ˜¯æå‡ç³»ç»Ÿæ€§èƒ½çš„å…³é”®æŠ€æœ¯ã€‚åœ¨ MCP Server ä¸­ï¼Œåˆç†ä½¿ç”¨ç¼“å­˜å¯ä»¥ï¼š

#### ç¼“å­˜çš„ä»·å€¼

```
åœºæ™¯å¯¹æ¯”ï¼šWeb æœç´¢å·¥å…·

âŒ æ²¡æœ‰ç¼“å­˜ï¼š
ç”¨æˆ·æŸ¥è¯¢ "Python æ•™ç¨‹"
  â†’ è°ƒç”¨å¤–éƒ¨ APIï¼ˆè€—æ—¶ 2 ç§’ï¼‰
  â†’ è¿”å›ç»“æœ
  
å†æ¬¡æŸ¥è¯¢ "Python æ•™ç¨‹"
  â†’ åˆè°ƒç”¨å¤–éƒ¨ APIï¼ˆè€—æ—¶ 2 ç§’ï¼‰
  â†’ è¿”å›ç›¸åŒç»“æœ
  
é—®é¢˜ï¼š
- æµªè´¹æ—¶é—´ï¼šç”¨æˆ·ç­‰å¾… 4 ç§’
- æµªè´¹èµ„æºï¼šAPI é…é¢æ¶ˆè€—
- ç”¨æˆ·ä½“éªŒå·®ï¼šæ¯æ¬¡éƒ½è¦ç­‰å¾…

âœ… ä½¿ç”¨ç¼“å­˜ï¼š
ç”¨æˆ·æŸ¥è¯¢ "Python æ•™ç¨‹"
  â†’ è°ƒç”¨å¤–éƒ¨ APIï¼ˆè€—æ—¶ 2 ç§’ï¼‰
  â†’ ä¿å­˜åˆ°ç¼“å­˜
  â†’ è¿”å›ç»“æœ
  
å†æ¬¡æŸ¥è¯¢ "Python æ•™ç¨‹"
  â†’ ä»ç¼“å­˜è¯»å–ï¼ˆè€—æ—¶ 0.01 ç§’ï¼‰
  â†’ è¿”å›ç»“æœ
  
ä¼˜åŠ¿ï¼š
- å“åº”å¿« 200 å€
- èŠ‚çœ API è°ƒç”¨
- ç”¨æˆ·ä½“éªŒå¥½
```

#### é€‚åˆç¼“å­˜çš„åœºæ™¯

1. **è®¡ç®—å¯†é›†å‹æ“ä½œ**
   - æ–‡æœ¬åˆ†æã€å›¾åƒå¤„ç†
   - æ•°æ®ç»Ÿè®¡ã€æŠ¥è¡¨ç”Ÿæˆ

2. **å¤–éƒ¨ API è°ƒç”¨**
   - Web æœç´¢ã€ç¿»è¯‘æœåŠ¡
   - å¤©æ°”æŸ¥è¯¢ã€æ–°é—»è·å–

3. **æ•°æ®åº“æŸ¥è¯¢**
   - çƒ­ç‚¹æ•°æ®æŸ¥è¯¢
   - é…ç½®ä¿¡æ¯è¯»å–

4. **é™æ€æˆ–åŠé™æ€å†…å®¹**
   - ç”¨æˆ·èµ„æ–™ã€äº§å“ä¿¡æ¯
   - ç³»ç»Ÿé…ç½®ã€è§„åˆ™æ•°æ®

#### ä¸é€‚åˆç¼“å­˜çš„åœºæ™¯

1. **å®æ—¶æ€§è¦æ±‚é«˜çš„æ•°æ®**
   - è‚¡ç¥¨ä»·æ ¼ã€å®æ—¶å¤©æ°”
   - åœ¨çº¿ç”¨æˆ·çŠ¶æ€

2. **ä¸ªæ€§åŒ–ç¨‹åº¦é«˜çš„æ•°æ®**
   - ç”¨æˆ·ç§å¯†ä¿¡æ¯
   - åŠ¨æ€ç”Ÿæˆçš„å†…å®¹

3. **ä½é¢‘è®¿é—®çš„æ•°æ®**
   - ä¸€æ¬¡æ€§æŸ¥è¯¢
   - é•¿å°¾è¯·æ±‚

### 3.2 ç¼“å­˜ç­–ç•¥è®¾è®¡

#### å¸¸è§ç¼“å­˜ç­–ç•¥

```python
from enum import Enum
from typing import Optional, Any
from datetime import datetime, timedelta
import hashlib

class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥"""
    TTL = "ttl"              # åŸºäºæ—¶é—´è¿‡æœŸ
    LRU = "lru"              # æœ€è¿‘æœ€å°‘ä½¿ç”¨
    LFU = "lfu"              # æœ€ä¸ç»å¸¸ä½¿ç”¨
    FIFO = "fifo"            # å…ˆè¿›å…ˆå‡º

class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    
    def __init__(self, key: str, value: Any, ttl: Optional[int] = None):
        self.key = key
        self.value = value
        self.created_at = datetime.now()
        self.accessed_at = datetime.now()
        self.access_count = 0
        self.ttl = ttl  # ç§’
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        if self.ttl is None:
            return False
        
        age = (datetime.now() - self.created_at).total_seconds()
        return age > self.ttl
    
    def access(self):
        """è®°å½•è®¿é—®"""
        self.accessed_at = datetime.now()
        self.access_count += 1
```

#### TTLï¼ˆTime To Liveï¼‰ç¼“å­˜

æœ€å¸¸ç”¨çš„ç¼“å­˜ç­–ç•¥ï¼Œè®¾ç½®å›ºå®šçš„è¿‡æœŸæ—¶é—´ã€‚

```python
from typing import Dict, Optional, Any
from datetime import datetime, timedelta

class TTLCache:
    """åŸºäº TTL çš„ç¼“å­˜"""
    
    def __init__(self, default_ttl: int = 300):
        self.cache: Dict[str, CacheEntry] = {}
        self.default_ttl = default_ttl
        self.hits = 0
        self.misses = 0
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if key not in self.cache:
            self.misses += 1
            return None
        
        entry = self.cache[key]
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if entry.is_expired():
            del self.cache[key]
            self.misses += 1
            return None
        
        # è®°å½•è®¿é—®
        entry.access()
        self.hits += 1
        return entry.value
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜"""
        if ttl is None:
            ttl = self.default_ttl
        
        self.cache[key] = CacheEntry(key, value, ttl)
    
    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        if key in self.cache:
            del self.cache[key]
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.hits = 0
        self.misses = 0
    
    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        expired_keys = [
            key for key, entry in self.cache.items()
            if entry.is_expired()
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        return len(expired_keys)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0
        
        return {
            "size": len(self.cache),
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": f"{hit_rate:.2f}%",
            "total_requests": total
        }


# ä½¿ç”¨ç¤ºä¾‹
@app.tool()
async def cached_search(query: str, ctx):
    """å¸¦ç¼“å­˜çš„æœç´¢å·¥å…·"""
    
    # è·å–ç¼“å­˜
    cache = ctx.request_context.lifespan_context.cache
    
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = f"search:{query}"
    
    # å°è¯•ä»ç¼“å­˜è·å–
    cached_result = cache.get(cache_key)
    if cached_result:
        print(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­ï¼š{query}")
        return {
            "cached": True,
            "result": cached_result
        }
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæœç´¢
    print(f"ğŸ” æ‰§è¡Œæœç´¢ï¼š{query}")
    result = await perform_search(query)  # å®é™…æœç´¢é€»è¾‘
    
    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
    cache.set(cache_key, result, ttl=300)
    
    return {
        "cached": False,
        "result": result
    }
```

#### LRUï¼ˆLeast Recently Usedï¼‰ç¼“å­˜

å½“ç¼“å­˜æ»¡æ—¶ï¼Œåˆ é™¤æœ€è¿‘æœ€å°‘ä½¿ç”¨çš„é¡¹ã€‚

```python
from collections import OrderedDict

class LRUCache:
    """LRU ç¼“å­˜"""
    
    def __init__(self, capacity: int = 100):
        self.capacity = capacity
        self.cache: OrderedDict[str, Any] = OrderedDict()
        self.hits = 0
        self.misses = 0
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if key not in self.cache:
            self.misses += 1
            return None
        
        # ç§»åˆ°æœ«å°¾ï¼ˆè¡¨ç¤ºæœ€è¿‘ä½¿ç”¨ï¼‰
        self.cache.move_to_end(key)
        self.hits += 1
        return self.cache[key]
    
    def set(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜"""
        if key in self.cache:
            # æ›´æ–°å¹¶ç§»åˆ°æœ«å°¾
            self.cache.move_to_end(key)
        else:
            # æ£€æŸ¥å®¹é‡
            if len(self.cache) >= self.capacity:
                # åˆ é™¤æœ€æ—§çš„é¡¹ï¼ˆç¬¬ä¸€ä¸ªï¼‰
                self.cache.popitem(last=False)
        
        self.cache[key] = value
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        self.hits = 0
        self.misses = 0
```

### 3.3 å¤šçº§ç¼“å­˜æ¶æ„

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œé€šå¸¸ä½¿ç”¨å¤šçº§ç¼“å­˜æ¥å¹³è¡¡æ€§èƒ½å’Œèµ„æºå ç”¨ã€‚

#### å¤šçº§ç¼“å­˜è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å¤šçº§ç¼“å­˜æ¶æ„                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¯·æ±‚ â†’ L1 ç¼“å­˜ï¼ˆå†…å­˜ï¼‰
          â†“ æœªå‘½ä¸­
       L2 ç¼“å­˜ï¼ˆRedisï¼‰
          â†“ æœªå‘½ä¸­
       æ•°æ®æºï¼ˆæ•°æ®åº“/APIï¼‰

ç‰¹ç‚¹ï¼š
- L1ï¼šé€Ÿåº¦å¿«ï¼ˆ0.01msï¼‰ï¼Œå®¹é‡å°ï¼ˆ100MBï¼‰
- L2ï¼šé€Ÿåº¦ä¸­ç­‰ï¼ˆ1-10msï¼‰ï¼Œå®¹é‡å¤§ï¼ˆ1GB+ï¼‰
- æºï¼šé€Ÿåº¦æ…¢ï¼ˆ100ms+ï¼‰ï¼Œå®¹é‡æœ€å¤§
```

#### å®ç°å¤šçº§ç¼“å­˜

```python
from typing import Optional, Any
import aioredis

class MultiLevelCache:
    """å¤šçº§ç¼“å­˜"""
    
    def __init__(
        self,
        l1_cache: TTLCache,
        redis_client: Optional[aioredis.Redis] = None
    ):
        self.l1 = l1_cache  # å†…å­˜ç¼“å­˜ï¼ˆL1ï¼‰
        self.l2 = redis_client  # Redis ç¼“å­˜ï¼ˆL2ï¼‰
        
        # ç»Ÿè®¡
        self.l1_hits = 0
        self.l2_hits = 0
        self.misses = 0
    
    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜ï¼ˆå¤šçº§ï¼‰"""
        
        # 1. å°è¯• L1 ç¼“å­˜
        value = self.l1.get(key)
        if value is not None:
            self.l1_hits += 1
            print(f"ğŸ’¾ L1 å‘½ä¸­ï¼š{key}")
            return value
        
        # 2. å°è¯• L2 ç¼“å­˜ï¼ˆRedisï¼‰
        if self.l2:
            try:
                value = await self.l2.get(f"cache:{key}")
                if value:
                    self.l2_hits += 1
                    print(f"ğŸ’¾ L2 å‘½ä¸­ï¼š{key}")
                    
                    # å›å¡«åˆ° L1
                    self.l1.set(key, value)
                    
                    return value
            except Exception as e:
                print(f"âš ï¸  L2 è¯»å–å¤±è´¥ï¼š{e}")
        
        # 3. éƒ½æœªå‘½ä¸­
        self.misses += 1
        return None
    
    async def set(
        self,
        key: str,
        value: Any,
        l1_ttl: int = 60,
        l2_ttl: int = 3600
    ):
        """è®¾ç½®ç¼“å­˜ï¼ˆå¤šçº§ï¼‰"""
        
        # ä¿å­˜åˆ° L1
        self.l1.set(key, value, ttl=l1_ttl)
        
        # ä¿å­˜åˆ° L2ï¼ˆRedisï¼‰
        if self.l2:
            try:
                await self.l2.setex(
                    f"cache:{key}",
                    l2_ttl,
                    value
                )
            except Exception as e:
                print(f"âš ï¸  L2 å†™å…¥å¤±è´¥ï¼š{e}")
    
    async def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜ï¼ˆå¤šçº§ï¼‰"""
        
        # ä» L1 åˆ é™¤
        self.l1.delete(key)
        
        # ä» L2 åˆ é™¤
        if self.l2:
            try:
                await self.l2.delete(f"cache:{key}")
            except Exception as e:
                print(f"âš ï¸  L2 åˆ é™¤å¤±è´¥ï¼š{e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.l1_hits + self.l2_hits + self.misses
        
        return {
            "l1_hits": self.l1_hits,
            "l2_hits": self.l2_hits,
            "misses": self.misses,
            "total_requests": total,
            "l1_hit_rate": f"{(self.l1_hits / total * 100) if total > 0 else 0:.2f}%",
            "l2_hit_rate": f"{(self.l2_hits / total * 100) if total > 0 else 0:.2f}%",
            "overall_hit_rate": f"{((self.l1_hits + self.l2_hits) / total * 100) if total > 0 else 0:.2f}%"
        }


# åœ¨ lifespan ä¸­åˆå§‹åŒ–
@app.lifespan()
async def lifespan(ctx):
    # åˆ›å»º L1 ç¼“å­˜ï¼ˆå†…å­˜ï¼‰
    l1_cache = TTLCache(default_ttl=60)
    
    # è¿æ¥ Redisï¼ˆL2ï¼‰
    redis_client = await aioredis.create_redis_pool(
        "redis://localhost:6379"
    )
    
    # åˆ›å»ºå¤šçº§ç¼“å­˜
    multi_cache = MultiLevelCache(l1_cache, redis_client)
    ctx.cache = multi_cache
    
    print("âœ… å¤šçº§ç¼“å­˜å·²åˆå§‹åŒ–")
    
    yield
    
    # å…³é—­æ—¶æ‰“å°ç»Ÿè®¡
    stats = multi_cache.get_stats()
    print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡ï¼š{stats}")
    
    redis_client.close()
    await redis_client.wait_closed()


# ä½¿ç”¨å¤šçº§ç¼“å­˜
@app.tool()
async def get_user_profile(user_id: str, ctx):
    """è·å–ç”¨æˆ·èµ„æ–™ï¼ˆä½¿ç”¨å¤šçº§ç¼“å­˜ï¼‰"""
    
    cache = ctx.request_context.lifespan_context.cache
    cache_key = f"user:{user_id}"
    
    # å°è¯•ä»ç¼“å­˜è·å–
    profile = await cache.get(cache_key)
    if profile:
        return {"cached": True, "profile": profile}
    
    # ä»æ•°æ®åº“æŸ¥è¯¢
    print(f"ğŸ—„ï¸  ä»æ•°æ®åº“æŸ¥è¯¢ï¼š{user_id}")
    profile = await query_database(user_id)
    
    # ä¿å­˜åˆ°å¤šçº§ç¼“å­˜
    await cache.set(
        cache_key,
        profile,
        l1_ttl=60,    # L1 ç¼“å­˜ 1 åˆ†é’Ÿ
        l2_ttl=3600   # L2 ç¼“å­˜ 1 å°æ—¶
    )
    
    return {"cached": False, "profile": profile}
```

### 3.4 æ™ºèƒ½ç¼“å­˜å¤±æ•ˆ

ç¼“å­˜å¤±æ•ˆç­–ç•¥å†³å®šäº†ä½•æ—¶æ›´æ–°æˆ–åˆ é™¤ç¼“å­˜ã€‚

#### ä¸»åŠ¨å¤±æ•ˆç­–ç•¥

```python
class CacheInvalidationManager:
    """ç¼“å­˜å¤±æ•ˆç®¡ç†å™¨"""
    
    def __init__(self, cache: MultiLevelCache):
        self.cache = cache
        self.invalidation_patterns = {}
    
    def register_pattern(self, event_type: str, pattern: str):
        """æ³¨å†Œå¤±æ•ˆæ¨¡å¼"""
        if event_type not in self.invalidation_patterns:
            self.invalidation_patterns[event_type] = []
        self.invalidation_patterns[event_type].append(pattern)
    
    async def invalidate_by_event(self, event_type: str, entity_id: str):
        """æ ¹æ®äº‹ä»¶å¤±æ•ˆç¼“å­˜"""
        
        patterns = self.invalidation_patterns.get(event_type, [])
        
        for pattern in patterns:
            # ç”Ÿæˆéœ€è¦å¤±æ•ˆçš„ç¼“å­˜é”®
            cache_key = pattern.format(id=entity_id)
            
            print(f"ğŸ—‘ï¸  å¤±æ•ˆç¼“å­˜ï¼š{cache_key}")
            await self.cache.delete(cache_key)
    
    async def invalidate_by_prefix(self, prefix: str):
        """æ ¹æ®å‰ç¼€å¤±æ•ˆç¼“å­˜"""
        # è¿™é‡Œéœ€è¦éå†æ‰€æœ‰ç¼“å­˜é”®ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ Redis SCANï¼‰
        print(f"ğŸ—‘ï¸  å¤±æ•ˆå‰ç¼€ï¼š{prefix}*")


# ä½¿ç”¨ç¤ºä¾‹
@app.tool()
async def update_user_profile(user_id: str, new_data: dict, ctx):
    """æ›´æ–°ç”¨æˆ·èµ„æ–™"""
    
    # æ›´æ–°æ•°æ®åº“
    await update_database(user_id, new_data)
    
    # å¤±æ•ˆç›¸å…³ç¼“å­˜
    cache = ctx.request_context.lifespan_context.cache
    await cache.delete(f"user:{user_id}")
    await cache.delete(f"user_list")  # ç”¨æˆ·åˆ—è¡¨ä¹Ÿå¤±æ•ˆ
    
    print(f"âœ… å·²æ›´æ–°ç”¨æˆ· {user_id} å¹¶å¤±æ•ˆç¼“å­˜")
    
    return {"success": True}
```

### 3.5 æ€§èƒ½ç›‘æ§

#### æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```python
from dataclasses import dataclass, field
from typing import List
import time

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    
    # å“åº”æ—¶é—´ç»Ÿè®¡
    response_times: List[float] = field(default_factory=list)
    
    # ååé‡ç»Ÿè®¡
    requests_per_second: float = 0.0
    
    # èµ„æºä½¿ç”¨
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    
    def add_response_time(self, duration: float):
        """æ·»åŠ å“åº”æ—¶é—´"""
        self.response_times.append(duration)
        
        # åªä¿ç•™æœ€è¿‘ 1000 ä¸ª
        if len(self.response_times) > 1000:
            self.response_times = self.response_times[-1000:]
    
    def get_avg_response_time(self) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        if not self.response_times:
            return 0.0
        return sum(self.response_times) / len(self.response_times)
    
    def get_p95_response_time(self) -> float:
        """è·å– P95 å“åº”æ—¶é—´"""
        if not self.response_times:
            return 0.0
        
        sorted_times = sorted(self.response_times)
        index = int(len(sorted_times) * 0.95)
        return sorted_times[index]
    
    def get_p99_response_time(self) -> float:
        """è·å– P99 å“åº”æ—¶é—´"""
        if not self.response_times:
            return 0.0
        
        sorted_times = sorted(self.response_times)
        index = int(len(sorted_times) * 0.99)
        return sorted_times[index]


# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    
    async def wrapper(*args, **kwargs):
        # è·å–ä¸Šä¸‹æ–‡
        ctx = kwargs.get('ctx')
        if ctx:
            metrics = ctx.request_context.lifespan_context.metrics
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            try:
                # æ‰§è¡Œå‡½æ•°
                result = await func(*args, **kwargs)
                return result
            finally:
                # è®°å½•å“åº”æ—¶é—´
                duration = time.time() - start_time
                metrics.add_response_time(duration)
                
                print(f"â±ï¸  {func.__name__} è€—æ—¶ï¼š{duration:.3f}ç§’")
        else:
            return await func(*args, **kwargs)
    
    return wrapper


# ä½¿ç”¨ç›‘æ§è£…é¥°å™¨
@app.tool()
@monitor_performance
async def expensive_operation(data: str, ctx):
    """è€—æ—¶æ“ä½œ"""
    await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
    return {"result": f"å¤„ç†å®Œæˆï¼š{data}"}


@app.tool()
async def get_performance_metrics(ctx):
    """è·å–æ€§èƒ½æŒ‡æ ‡"""
    metrics = ctx.request_context.lifespan_context.metrics
    
    return {
        "avg_response_time": f"{metrics.get_avg_response_time():.3f}s",
        "p95_response_time": f"{metrics.get_p95_response_time():.3f}s",
        "p99_response_time": f"{metrics.get_p99_response_time():.3f}s",
        "total_requests": len(metrics.response_times)
    }
```

### 3.6 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1. æ‰¹é‡æ“ä½œ

```python
@app.tool()
async def batch_query_users(user_ids: List[str], ctx):
    """æ‰¹é‡æŸ¥è¯¢ç”¨æˆ·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    
    cache = ctx.request_context.lifespan_context.cache
    
    # æ‰¹é‡æ£€æŸ¥ç¼“å­˜
    cached_users = {}
    uncached_ids = []
    
    for user_id in user_ids:
        cached = await cache.get(f"user:{user_id}")
        if cached:
            cached_users[user_id] = cached
        else:
            uncached_ids.append(user_id)
    
    # æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ï¼ˆä¸€æ¬¡æŸ¥è¯¢æ‰€æœ‰æœªç¼“å­˜çš„ï¼‰
    if uncached_ids:
        db_users = await batch_query_database(uncached_ids)
        
        # æ‰¹é‡ä¿å­˜åˆ°ç¼“å­˜
        for user_id, user_data in db_users.items():
            await cache.set(f"user:{user_id}", user_data)
            cached_users[user_id] = user_data
    
    return cached_users
```

#### 2. å¼‚æ­¥å¹¶å‘

```python
import asyncio

@app.tool()
async def aggregate_data(ctx):
    """èšåˆå¤šä¸ªæ•°æ®æºï¼ˆå¹¶å‘ï¼‰"""
    
    # å¹¶å‘æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
    results = await asyncio.gather(
        fetch_user_data(),
        fetch_order_data(),
        fetch_product_data(),
        return_exceptions=True  # æ•è·å¼‚å¸¸
    )
    
    user_data, order_data, product_data = results
    
    return {
        "user": user_data if not isinstance(user_data, Exception) else None,
        "orders": order_data if not isinstance(order_data, Exception) else None,
        "products": product_data if not isinstance(product_data, Exception) else None
    }
```

#### 3. è¿æ¥æ± å¤ç”¨

```python
# åœ¨ lifespan ä¸­åˆ›å»ºè¿æ¥æ± 
@app.lifespan()
async def lifespan(ctx):
    # HTTP è¿æ¥æ± 
    http_client = httpx.AsyncClient(
        limits=httpx.Limits(
            max_connections=100,
            max_keepalive_connections=20
        ),
        timeout=30.0
    )
    ctx.http_client = http_client
    
    yield
    
    await http_client.aclose()


# å¤ç”¨è¿æ¥æ± 
@app.tool()
async def fetch_external_api(url: str, ctx):
    """è°ƒç”¨å¤–éƒ¨ APIï¼ˆå¤ç”¨è¿æ¥ï¼‰"""
    http_client = ctx.request_context.lifespan_context.http_client
    
    response = await http_client.get(url)
    return response.json()
```

---



## 4. æ—¥å¿—ä¸ç›‘æ§

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦æ—¥å¿—ï¼Ÿ

æ—¥å¿—æ˜¯ç”Ÿäº§ç¯å¢ƒä¸­æœ€é‡è¦çš„è°ƒè¯•å’Œç›‘æ§æ‰‹æ®µã€‚æ²¡æœ‰æ—¥å¿—ï¼Œç³»ç»Ÿå°±åƒä¸€ä¸ªé»‘ç›’ï¼Œä½ å°†æ— æ³•ï¼š

#### æ—¥å¿—çš„ä»·å€¼

```
é—®é¢˜åœºæ™¯ï¼šç”Ÿäº§ç¯å¢ƒå‡ºç°bug

âŒ æ²¡æœ‰æ—¥å¿—çš„æƒ…å†µï¼š
ç”¨æˆ·ï¼šç³»ç»Ÿå´©æºƒäº†ï¼
å¼€å‘ï¼šä»€ä¹ˆæ—¶å€™ï¼Ÿåšäº†ä»€ä¹ˆæ“ä½œï¼Ÿ
ç”¨æˆ·ï¼šå¿˜äº†...
å¼€å‘ï¼š...ï¼ˆå®Œå…¨æ— ä»ä¸‹æ‰‹ï¼‰

âœ… æœ‰å®Œå–„æ—¥å¿—çš„æƒ…å†µï¼š
ç”¨æˆ·ï¼šç³»ç»Ÿå´©æºƒäº†ï¼
å¼€å‘ï¼š
  1. æŸ¥çœ‹æ—¥å¿—ï¼Œå‘ç°é”™è¯¯æ—¶é—´ï¼š2025-11-20 20:30:15
  2. çœ‹åˆ°ç”¨æˆ·æ“ä½œï¼šè°ƒç”¨äº† process_data å·¥å…·
  3. çœ‹åˆ°é”™è¯¯åŸå› ï¼šæ•°æ®åº“è¿æ¥è¶…æ—¶
  4. çœ‹åˆ°å †æ ˆä¿¡æ¯ï¼šåœ¨ line 45 å‡ºé”™
  5. 5åˆ†é’Ÿå†…å®šä½å¹¶ä¿®å¤é—®é¢˜ï¼
```

#### æ—¥å¿—çš„ä½œç”¨

1. **æ•…éšœæ’æŸ¥**
   - å¿«é€Ÿå®šä½é—®é¢˜æ ¹æº
   - è¿˜åŸé”™è¯¯å‘ç”Ÿæ—¶çš„ç°åœº
   - è¿½è¸ªè°ƒç”¨é“¾è·¯

2. **æ€§èƒ½åˆ†æ**
   - è¯†åˆ«æ…¢æŸ¥è¯¢
   - å‘ç°æ€§èƒ½ç“¶é¢ˆ
   - ç›‘æ§èµ„æºä½¿ç”¨

3. **å®‰å…¨å®¡è®¡**
   - è®°å½•æ•æ„Ÿæ“ä½œ
   - è¿½è¸ªå¼‚å¸¸è®¿é—®
   - åˆè§„æ€§è¦æ±‚

4. **ä¸šåŠ¡åˆ†æ**
   - ç”¨æˆ·è¡Œä¸ºåˆ†æ
   - åŠŸèƒ½ä½¿ç”¨ç»Ÿè®¡
   - æ•°æ®è¶‹åŠ¿æ´å¯Ÿ

#### æ—¥å¿—çº§åˆ«è¯¦è§£

```python
import logging

"""
æ—¥å¿—çº§åˆ«ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š

CRITICAL (50) - ä¸¥é‡é”™è¯¯ï¼Œç³»ç»Ÿå¯èƒ½æ— æ³•ç»§ç»­è¿è¡Œ
  ç¤ºä¾‹ï¼šæ•°æ®åº“å®Œå…¨ä¸å¯ç”¨ã€æ ¸å¿ƒæœåŠ¡å´©æºƒ
  
ERROR (40) - é”™è¯¯ï¼ŒåŠŸèƒ½æ— æ³•æ­£å¸¸æ‰§è¡Œ
  ç¤ºä¾‹ï¼šAPI è°ƒç”¨å¤±è´¥ã€æ–‡ä»¶è¯»å–é”™è¯¯
  
WARNING (30) - è­¦å‘Šï¼Œå¯èƒ½å¯¼è‡´é—®é¢˜
  ç¤ºä¾‹ï¼šç£ç›˜ç©ºé—´ä¸è¶³ã€ç¼“å­˜å¤±æ•ˆ
  
INFO (20) - é‡è¦ä¿¡æ¯ï¼Œæ­£å¸¸ä¸šåŠ¡æµç¨‹
  ç¤ºä¾‹ï¼šæœåŠ¡å¯åŠ¨ã€ç”¨æˆ·ç™»å½•ã€è®¢å•åˆ›å»º
  
DEBUG (10) - è°ƒè¯•ä¿¡æ¯ï¼Œå¼€å‘é˜¶æ®µä½¿ç”¨
  ç¤ºä¾‹ï¼šå˜é‡å€¼ã€å‡½æ•°è°ƒç”¨ã€ä¸­é—´ç»“æœ
"""

# çº§åˆ«ä½¿ç”¨åŸåˆ™
logger.critical("æ•°æ®åº“è¿æ¥æ± è€—å°½ï¼")        # éœ€è¦ç«‹å³å¤„ç†
logger.error("æ— æ³•è¿æ¥åˆ°æ”¯ä»˜ç½‘å…³")            # åŠŸèƒ½å¤±è´¥
logger.warning("ç¼“å­˜å‘½ä¸­ç‡ä½äº50%")           # éœ€è¦å…³æ³¨
logger.info("ç”¨æˆ· user123 ç™»å½•æˆåŠŸ")         # æ­£å¸¸è®°å½•
logger.debug("æŸ¥è¯¢å‚æ•°: query='Python'")     # è°ƒè¯•ä¿¡æ¯
```

### 4.2 ç»“æ„åŒ–æ—¥å¿—è®¾è®¡

ç»“æ„åŒ–æ—¥å¿—ä½¿ç”¨ JSON æ ¼å¼ï¼Œä¾¿äºæœºå™¨è§£æã€æŸ¥è¯¢å’Œåˆ†æã€‚

#### ç»“æ„åŒ–æ—¥å¿—çš„ä¼˜åŠ¿

```
å¯¹æ¯”ç¤ºä¾‹ï¼š

âŒ ä¼ ç»Ÿæ—¥å¿—ï¼ˆéš¾ä»¥è§£æï¼‰ï¼š
2025-11-20 20:30:15 User alice called search with query Python and got 10 results in 0.5s

âœ… ç»“æ„åŒ–æ—¥å¿—ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{
  "timestamp": "2025-11-20T20:30:15.123Z",
  "level": "INFO",
  "user": "alice",
  "tool": "search",
  "query": "Python",
  "result_count": 10,
  "duration_ms": 500,
  "request_id": "abc-123"
}

ä¼˜åŠ¿ï¼š
- å¯ä»¥æŒ‰å­—æ®µæŸ¥è¯¢ï¼šæ‰¾å‡ºæ‰€æœ‰è€—æ—¶è¶…è¿‡1ç§’çš„è¯·æ±‚
- å¯ä»¥ç»Ÿè®¡åˆ†æï¼šè®¡ç®—å¹³å‡å“åº”æ—¶é—´
- å¯ä»¥å…³è”è¿½è¸ªï¼šé€šè¿‡ request_id è¿½è¸ªæ•´ä¸ªè¯·æ±‚é“¾
```

#### å®ç°ç»“æ„åŒ–æ—¥å¿—å™¨

```python
import logging
import json
from datetime import datetime
from typing import Any, Dict, Optional
import traceback

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—å™¨"""
    
    def __init__(self, name: str, level: int = logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # åˆ›å»ºå¤„ç†å™¨
        handler = logging.StreamHandler()
        handler.setLevel(level)
        
        # è®¾ç½®æ ¼å¼å™¨
        formatter = StructuredFormatter()
        handler.setFormatter(formatter)
        
        self.logger.addHandler(handler)
    
    def _log(
        self,
        level: str,
        message: str,
        extra: Optional[Dict[str, Any]] = None,
        exc_info: Optional[Exception] = None
    ):
        """å†…éƒ¨æ—¥å¿—æ–¹æ³•"""
        log_data = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": level,
            "message": message
        }
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        if extra:
            log_data.update(extra)
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if exc_info:
            log_data["exception"] = {
                "type": type(exc_info).__name__,
                "message": str(exc_info),
                "traceback": traceback.format_exc()
            }
        
        # è¾“å‡º JSON
        print(json.dumps(log_data, ensure_ascii=False))
    
    def debug(self, message: str, **kwargs):
        """è°ƒè¯•æ—¥å¿—"""
        self._log("DEBUG", message, kwargs)
    
    def info(self, message: str, **kwargs):
        """ä¿¡æ¯æ—¥å¿—"""
        self._log("INFO", message, kwargs)
    
    def warning(self, message: str, **kwargs):
        """è­¦å‘Šæ—¥å¿—"""
        self._log("WARNING", message, kwargs)
    
    def error(self, message: str, exc_info: Optional[Exception] = None, **kwargs):
        """é”™è¯¯æ—¥å¿—"""
        self._log("ERROR", message, kwargs, exc_info)
    
    def critical(self, message: str, exc_info: Optional[Exception] = None, **kwargs):
        """ä¸¥é‡é”™è¯¯æ—¥å¿—"""
        self._log("CRITICAL", message, kwargs, exc_info)


class StructuredFormatter(logging.Formatter):
    """ç»“æ„åŒ–æ ¼å¼å™¨"""
    
    def format(self, record: logging.LogRecord) -> str:
        """æ ¼å¼åŒ–æ—¥å¿—è®°å½•"""
        log_data = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        if hasattr(record, "extra_fields"):
            log_data.update(record.extra_fields)
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__,
                "message": str(record.exc_info[1]),
                "traceback": self.formatException(record.exc_info)
            }
        
        return json.dumps(log_data, ensure_ascii=False)


# ä½¿ç”¨ç¤ºä¾‹
logger = StructuredLogger("mcp_server")

# è®°å½•ä¸åŒçº§åˆ«çš„æ—¥å¿—
logger.info("æœåŠ¡å¯åŠ¨", version="1.0.0", port=8080)
logger.debug("å¤„ç†è¯·æ±‚", request_id="abc-123", user="alice")
logger.warning("ç¼“å­˜å‘½ä¸­ç‡ä½", hit_rate=0.45, threshold=0.5)

# è®°å½•é”™è¯¯ï¼ˆå¸¦å¼‚å¸¸ä¿¡æ¯ï¼‰
try:
    1 / 0
except Exception as e:
    logger.error("è®¡ç®—é”™è¯¯", exc_info=e, operation="divide")
```

### 4.3 ç”Ÿäº§çº§æ—¥å¿—å®è·µ

#### å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿè®¾è®¡

```python
import logging
import logging.handlers
from pathlib import Path
from datetime import datetime
from typing import Optional
import gzip
import shutil

class ProductionLogger:
    """ç”Ÿäº§çº§æ—¥å¿—ç³»ç»Ÿ"""
    
    def __init__(
        self,
        name: str,
        log_dir: str = "logs",
        level: int = logging.INFO,
        max_bytes: int = 10 * 1024 * 1024,  # 10MB
        backup_count: int = 5
    ):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # 1. æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå½©è‰²è¾“å‡ºï¼‰
        self._add_console_handler()
        
        # 2. æ–‡ä»¶å¤„ç†å™¨ï¼ˆæ‰€æœ‰æ—¥å¿—ï¼‰
        self._add_file_handler("all", logging.DEBUG, max_bytes, backup_count)
        
        # 3. é”™è¯¯æ–‡ä»¶å¤„ç†å™¨ï¼ˆåªè®°å½•é”™è¯¯ï¼‰
        self._add_file_handler("error", logging.ERROR, max_bytes, backup_count)
        
        # 4. JSON æ–‡ä»¶å¤„ç†å™¨ï¼ˆç»“æ„åŒ–æ—¥å¿—ï¼‰
        self._add_json_handler(max_bytes, backup_count)
    
    def _add_console_handler(self):
        """æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨"""
        handler = logging.StreamHandler()
        
        # å½©è‰²æ ¼å¼
        formatter = ColoredFormatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        
        self.logger.addHandler(handler)
    
    def _add_file_handler(
        self,
        name: str,
        level: int,
        max_bytes: int,
        backup_count: int
    ):
        """æ·»åŠ æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰"""
        log_file = self.log_dir / f"{name}.log"
        
        handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
        handler.setLevel(level)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        handler.setFormatter(formatter)
        
        self.logger.addHandler(handler)
    
    def _add_json_handler(self, max_bytes: int, backup_count: int):
        """æ·»åŠ  JSON æ–‡ä»¶å¤„ç†å™¨"""
        log_file = self.log_dir / "structured.log"
        
        handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding='utf-8'
        )
        
        handler.setFormatter(StructuredFormatter())
        
        self.logger.addHandler(handler)
    
    def get_logger(self) -> logging.Logger:
        """è·å–æ—¥å¿—å™¨"""
        return self.logger


class ColoredFormatter(logging.Formatter):
    """å½©è‰²æ—¥å¿—æ ¼å¼å™¨"""
    
    COLORS = {
        'DEBUG': '\033[36m',     # é’è‰²
        'INFO': '\033[32m',      # ç»¿è‰²
        'WARNING': '\033[33m',   # é»„è‰²
        'ERROR': '\033[31m',     # çº¢è‰²
        'CRITICAL': '\033[35m',  # ç´«è‰²
        'RESET': '\033[0m'       # é‡ç½®
    }
    
    def format(self, record):
        """æ ¼å¼åŒ–æ—¥å¿—"""
        color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        record.levelname = f"{color}{record.levelname}{self.COLORS['RESET']}"
        return super().format(record)


# åœ¨ lifespan ä¸­åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
@app.lifespan()
async def lifespan(ctx):
    # åˆ›å»ºç”Ÿäº§çº§æ—¥å¿—å™¨
    prod_logger = ProductionLogger(
        name="mcp_server",
        log_dir="logs",
        level=logging.INFO
    )
    
    logger = prod_logger.get_logger()
    ctx.logger = logger
    
    logger.info("=" * 60)
    logger.info("ğŸš€ MCP Server å¯åŠ¨")
    logger.info(f"ğŸ“… æ—¶é—´: {datetime.now()}")
    logger.info(f"ğŸ·ï¸  ç‰ˆæœ¬: 1.0.0")
    logger.info("=" * 60)
    
    yield
    
    logger.info("=" * 60)
    logger.info("ğŸ›‘ MCP Server å…³é—­")
    logger.info(f"ğŸ“… æ—¶é—´: {datetime.now()}")
    logger.info("=" * 60)
```

#### åœ¨å·¥å…·ä¸­ä½¿ç”¨æ—¥å¿—

```python
@app.tool()
async def search_with_logging(query: str, ctx):
    """å¸¦å®Œæ•´æ—¥å¿—çš„æœç´¢å·¥å…·"""
    
    logger = ctx.request_context.lifespan_context.logger
    request_id = str(uuid.uuid4())
    
    # 1. è®°å½•è¯·æ±‚å¼€å§‹
    logger.info(
        "æœç´¢è¯·æ±‚å¼€å§‹",
        extra={
            "request_id": request_id,
            "tool": "search",
            "query": query,
            "user": "alice"
        }
    )
    
    start_time = time.time()
    
    try:
        # 2. æ‰§è¡Œæœç´¢
        logger.debug(
            "è°ƒç”¨æœç´¢ API",
            extra={"request_id": request_id, "query": query}
        )
        
        result = await perform_search(query)
        
        # 3. è®°å½•æˆåŠŸ
        duration = time.time() - start_time
        logger.info(
            "æœç´¢å®Œæˆ",
            extra={
                "request_id": request_id,
                "query": query,
                "result_count": len(result),
                "duration_ms": int(duration * 1000),
                "status": "success"
            }
        )
        
        return {
            "success": True,
            "result": result,
            "request_id": request_id
        }
        
    except Exception as e:
        # 4. è®°å½•é”™è¯¯
        duration = time.time() - start_time
        logger.error(
            "æœç´¢å¤±è´¥",
            exc_info=e,
            extra={
                "request_id": request_id,
                "query": query,
                "duration_ms": int(duration * 1000),
                "status": "error"
            }
        )
        
        return {
            "success": False,
            "error": str(e),
            "request_id": request_id
        }
```

### 4.4 ç›‘æ§æŒ‡æ ‡æ”¶é›†

é™¤äº†æ—¥å¿—ï¼Œè¿˜éœ€è¦æ”¶é›†å„ç§ç›‘æ§æŒ‡æ ‡ã€‚

#### æŒ‡æ ‡ç±»å‹

```python
from dataclasses import dataclass, field
from typing import Dict, List
from collections import defaultdict
import time

@dataclass
class Metrics:
    """ç›‘æ§æŒ‡æ ‡"""
    
    # è®¡æ•°å™¨ï¼ˆCounterï¼‰- åªå¢ä¸å‡
    request_total: int = 0
    error_total: int = 0
    tool_calls: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    
    # ç›´æ–¹å›¾ï¼ˆHistogramï¼‰- åˆ†å¸ƒç»Ÿè®¡
    response_times: List[float] = field(default_factory=list)
    
    # ä»ªè¡¨ç›˜ï¼ˆGaugeï¼‰- å½“å‰å€¼
    active_connections: int = 0
    memory_usage_mb: float = 0.0
    cache_size: int = 0
    
    def record_request(self, tool_name: str, duration: float, success: bool):
        """è®°å½•è¯·æ±‚"""
        self.request_total += 1
        self.tool_calls[tool_name] += 1
        self.response_times.append(duration)
        
        if not success:
            self.error_total += 1
    
    def get_error_rate(self) -> float:
        """è·å–é”™è¯¯ç‡"""
        if self.request_total == 0:
            return 0.0
        return self.error_total / self.request_total
    
    def get_avg_response_time(self) -> float:
        """è·å–å¹³å‡å“åº”æ—¶é—´"""
        if not self.response_times:
            return 0.0
        return sum(self.response_times) / len(self.response_times)
    
    def get_percentile(self, p: float) -> float:
        """è·å–ç™¾åˆ†ä½æ•°"""
        if not self.response_times:
            return 0.0
        
        sorted_times = sorted(self.response_times)
        index = int(len(sorted_times) * p)
        return sorted_times[min(index, len(sorted_times) - 1)]
    
    def get_summary(self) -> Dict:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        return {
            "requests_total": self.request_total,
            "errors_total": self.error_total,
            "error_rate": f"{self.get_error_rate() * 100:.2f}%",
            "avg_response_time": f"{self.get_avg_response_time():.3f}s",
            "p50_response_time": f"{self.get_percentile(0.50):.3f}s",
            "p95_response_time": f"{self.get_percentile(0.95):.3f}s",
            "p99_response_time": f"{self.get_percentile(0.99):.3f}s",
            "active_connections": self.active_connections,
            "top_tools": dict(
                sorted(
                    self.tool_calls.items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:10]
            )
        }


# åœ¨ lifespan ä¸­åˆå§‹åŒ–æŒ‡æ ‡
@app.lifespan()
async def lifespan(ctx):
    metrics = Metrics()
    ctx.metrics = metrics
    
    # å®šæœŸè¾“å‡ºæŒ‡æ ‡
    async def metrics_reporter():
        while True:
            await asyncio.sleep(60)  # æ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡
            summary = metrics.get_summary()
            logger.info("ğŸ“Š æŒ‡æ ‡æŠ¥å‘Š", extra=summary)
    
    # å¯åŠ¨æŒ‡æ ‡æŠ¥å‘Šä»»åŠ¡
    task = asyncio.create_task(metrics_reporter())
    
    yield
    
    task.cancel()
```

### 4.5 å‘Šè­¦ç³»ç»Ÿ

å½“æŒ‡æ ‡è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œéœ€è¦åŠæ—¶å‘Šè­¦ã€‚

```python
from enum import Enum
from typing import Callable, List
import smtplib
from email.mime.text import MIMEText

class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    
    def __init__(
        self,
        name: str,
        condition: Callable[[Metrics], bool],
        level: AlertLevel,
        message_template: str
    ):
        self.name = name
        self.condition = condition
        self.level = level
        self.message_template = message_template
        self.last_triggered = None
        self.cooldown = 300  # å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
    
    def check(self, metrics: Metrics) -> bool:
        """æ£€æŸ¥æ˜¯å¦è§¦å‘"""
        # æ£€æŸ¥å†·å´æ—¶é—´
        if self.last_triggered:
            if time.time() - self.last_triggered < self.cooldown:
                return False
        
        # æ£€æŸ¥æ¡ä»¶
        if self.condition(metrics):
            self.last_triggered = time.time()
            return True
        
        return False
    
    def get_message(self, metrics: Metrics) -> str:
        """è·å–å‘Šè­¦æ¶ˆæ¯"""
        return self.message_template.format(
            error_rate=metrics.get_error_rate() * 100,
            avg_response_time=metrics.get_avg_response_time(),
            active_connections=metrics.active_connections
        )


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.rules: List[AlertRule] = []
    
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ è§„åˆ™"""
        self.rules.append(rule)
    
    async def check_all(self, metrics: Metrics):
        """æ£€æŸ¥æ‰€æœ‰è§„åˆ™"""
        for rule in self.rules:
            if rule.check(metrics):
                await self.trigger_alert(rule, metrics)
    
    async def trigger_alert(self, rule: AlertRule, metrics: Metrics):
        """è§¦å‘å‘Šè­¦"""
        message = rule.get_message(metrics)
        
        # è®°å½•æ—¥å¿—
        if rule.level == AlertLevel.CRITICAL:
            self.logger.critical(f"ğŸš¨ {rule.name}: {message}")
        elif rule.level == AlertLevel.ERROR:
            self.logger.error(f"âŒ {rule.name}: {message}")
        elif rule.level == AlertLevel.WARNING:
            self.logger.warning(f"âš ï¸  {rule.name}: {message}")
        else:
            self.logger.info(f"â„¹ï¸  {rule.name}: {message}")
        
        # å‘é€é€šçŸ¥ï¼ˆé‚®ä»¶ã€Slackã€é’‰é’‰ç­‰ï¼‰
        await self.send_notification(rule, message)
    
    async def send_notification(self, rule: AlertRule, message: str):
        """å‘é€é€šçŸ¥"""
        # è¿™é‡Œå¯ä»¥é›†æˆå„ç§é€šçŸ¥æ¸ é“
        # ç¤ºä¾‹ï¼šå‘é€é‚®ä»¶
        try:
            # await send_email(rule.name, message)
            pass
        except Exception as e:
            self.logger.error(f"å‘é€å‘Šè­¦é€šçŸ¥å¤±è´¥: {e}")


# é…ç½®å‘Šè­¦è§„åˆ™
@app.lifespan()
async def lifespan(ctx):
    logger = ctx.logger
    metrics = ctx.metrics
    
    # åˆ›å»ºå‘Šè­¦ç®¡ç†å™¨
    alert_manager = AlertManager(logger)
    
    # æ·»åŠ è§„åˆ™
    alert_manager.add_rule(AlertRule(
        name="é«˜é”™è¯¯ç‡å‘Šè­¦",
        condition=lambda m: m.get_error_rate() > 0.1,  # é”™è¯¯ç‡è¶…è¿‡10%
        level=AlertLevel.ERROR,
        message_template="é”™è¯¯ç‡è¿‡é«˜ï¼š{error_rate:.2f}%"
    ))
    
    alert_manager.add_rule(AlertRule(
        name="æ…¢å“åº”å‘Šè­¦",
        condition=lambda m: m.get_avg_response_time() > 2.0,  # å¹³å‡å“åº”æ—¶é—´è¶…è¿‡2ç§’
        level=AlertLevel.WARNING,
        message_template="å¹³å‡å“åº”æ—¶é—´è¿‡é•¿ï¼š{avg_response_time:.2f}s"
    ))
    
    alert_manager.add_rule(AlertRule(
        name="è¿æ¥æ•°å‘Šè­¦",
        condition=lambda m: m.active_connections > 100,  # æ´»è·ƒè¿æ¥è¶…è¿‡100
        level=AlertLevel.WARNING,
        message_template="æ´»è·ƒè¿æ¥æ•°è¿‡å¤šï¼š{active_connections}"
    ))
    
    ctx.alert_manager = alert_manager
    
    # å®šæœŸæ£€æŸ¥å‘Šè­¦
    async def alert_checker():
        while True:
            await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            await alert_manager.check_all(metrics)
    
    alert_task = asyncio.create_task(alert_checker())
    
    yield
    
    alert_task.cancel()
```

---



## 5. å®‰å…¨æ€§ä¸æƒé™æ§åˆ¶

### 5.1 å®‰å…¨å¨èƒä¸é˜²æŠ¤åŸåˆ™

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå®‰å…¨æ˜¯ç¬¬ä¸€è¦åŠ¡ã€‚MCP Server å¯èƒ½é¢ä¸´å„ç§å®‰å…¨å¨èƒã€‚

#### å¸¸è§å®‰å…¨å¨èƒ

```
MCP Server é¢ä¸´çš„å®‰å…¨å¨èƒï¼š

1. æœªæˆæƒè®¿é—®
   å¨èƒï¼šä»»ä½•äººéƒ½èƒ½è°ƒç”¨æ•æ„Ÿå·¥å…·
   åæœï¼šæ•°æ®æ³„éœ²ã€ç³»ç»Ÿç ´å
   ç¤ºä¾‹ï¼šæ”»å‡»è€…è°ƒç”¨ delete_all_data å·¥å…·

2. æ•°æ®æ³„éœ²
   å¨èƒï¼šæ•æ„Ÿä¿¡æ¯è¢«è®°å½•æˆ–è¿”å›
   åæœï¼šéšç§æ³„éœ²ã€åˆè§„é—®é¢˜
   ç¤ºä¾‹ï¼šæ—¥å¿—ä¸­åŒ…å«ç”¨æˆ·å¯†ç ã€ä¿¡ç”¨å¡å·

3. æ³¨å…¥æ”»å‡»
   å¨èƒï¼šæ¶æ„è¾“å…¥å¯¼è‡´å‘½ä»¤æ‰§è¡Œ
   åæœï¼šç³»ç»Ÿè¢«æ§åˆ¶ã€æ•°æ®æŸå
   ç¤ºä¾‹ï¼šSQL æ³¨å…¥ã€å‘½ä»¤æ³¨å…¥

4. æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰
   å¨èƒï¼šå¤§é‡è¯·æ±‚è€—å°½èµ„æº
   åæœï¼šæœåŠ¡ä¸å¯ç”¨
   ç¤ºä¾‹ï¼šæ¶æ„å¾ªç¯è°ƒç”¨è€—æ—¶å·¥å…·

5. æƒé™æå‡
   å¨èƒï¼šæ™®é€šç”¨æˆ·è·å¾—ç®¡ç†å‘˜æƒé™
   åæœï¼šç³»ç»Ÿè¢«æ§åˆ¶
   ç¤ºä¾‹ï¼šç»•è¿‡æƒé™æ£€æŸ¥æ‰§è¡Œç®¡ç†æ“ä½œ
```

#### å®‰å…¨é˜²æŠ¤åŸåˆ™

```
OWASP å®‰å…¨åŸåˆ™ï¼š

1. æœ€å°æƒé™åŸåˆ™ï¼ˆPrinciple of Least Privilegeï¼‰
   - åªæˆäºˆå®Œæˆä»»åŠ¡æ‰€éœ€çš„æœ€å°æƒé™
   - é»˜è®¤æ‹’ç»ï¼Œæ˜¾å¼æˆæƒ
   
2. çºµæ·±é˜²å¾¡ï¼ˆDefense in Depthï¼‰
   - å¤šå±‚å®‰å…¨æªæ–½
   - ä¸€å±‚å¤±è´¥ï¼Œå…¶ä»–å±‚ä»å¯ä¿æŠ¤
   
3. å¤±è´¥å®‰å…¨ï¼ˆFail Securelyï¼‰
   - é”™è¯¯æ—¶åº”ä¿æŒå®‰å…¨çŠ¶æ€
   - ä¸æ³„éœ²æ•æ„Ÿä¿¡æ¯
   
4. ä¸ä¿¡ä»»è¾“å…¥ï¼ˆNever Trust Inputï¼‰
   - éªŒè¯æ‰€æœ‰å¤–éƒ¨è¾“å…¥
   - å¯¹è¾“å…¥è¿›è¡Œæ¸…ç†å’Œè½¬ä¹‰
   
5. å®‰å…¨é»˜è®¤ï¼ˆSecure by Defaultï¼‰
   - é»˜è®¤é…ç½®åº”è¯¥æ˜¯å®‰å…¨çš„
   - éœ€è¦ä¸»åŠ¨é€‰æ‹©é™ä½å®‰å…¨æ€§
```

### 5.2 è®¤è¯ä¸æˆæƒ

è®¤è¯ï¼ˆAuthenticationï¼‰ç¡®è®¤"ä½ æ˜¯è°"ï¼Œæˆæƒï¼ˆAuthorizationï¼‰ç¡®å®š"ä½ èƒ½åšä»€ä¹ˆ"ã€‚

#### åŸºäº Token çš„è®¤è¯

```python
import hashlib
import secrets
from datetime import datetime, timedelta
from typing import Optional, Dict
import jwt

class TokenAuth:
    """åŸºäº Token çš„è®¤è¯ç³»ç»Ÿ"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.tokens: Dict[str, Dict] = {}  # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ Redis
    
    def generate_token(
        self,
        user_id: str,
        roles: list[str],
        expires_in: int = 3600
    ) -> str:
        """ç”Ÿæˆè®¿é—®ä»¤ç‰Œ"""
        
        # ä½¿ç”¨ JWT
        payload = {
            "user_id": user_id,
            "roles": roles,
            "exp": datetime.utcnow() + timedelta(seconds=expires_in),
            "iat": datetime.utcnow()
        }
        
        token = jwt.encode(payload, self.secret_key, algorithm="HS256")
        
        # ä¿å­˜åˆ°å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
        self.tokens[token] = {
            "user_id": user_id,
            "roles": roles,
            "created_at": datetime.utcnow(),
            "expires_at": datetime.utcnow() + timedelta(seconds=expires_in)
        }
        
        return token
    
    def verify_token(self, token: str) -> Optional[Dict]:
        """éªŒè¯ä»¤ç‰Œ"""
        try:
            # è§£ç  JWT
            payload = jwt.decode(
                token,
                self.secret_key,
                algorithms=["HS256"]
            )
            
            return {
                "user_id": payload["user_id"],
                "roles": payload["roles"]
            }
            
        except jwt.ExpiredSignatureError:
            print("ä»¤ç‰Œå·²è¿‡æœŸ")
            return None
        except jwt.InvalidTokenError:
            print("æ— æ•ˆçš„ä»¤ç‰Œ")
            return None
    
    def revoke_token(self, token: str):
        """æ’¤é”€ä»¤ç‰Œ"""
        if token in self.tokens:
            del self.tokens[token]


# åœ¨ lifespan ä¸­åˆå§‹åŒ–
@app.lifespan()
async def lifespan(ctx):
    # ä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥ï¼ˆå®‰å…¨åšæ³•ï¼‰
    import os
    secret_key = os.getenv("JWT_SECRET_KEY", secrets.token_hex(32))
    
    token_auth = TokenAuth(secret_key)
    ctx.token_auth = token_auth
    
    print("âœ… è®¤è¯ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    yield
```

#### æƒé™æ§åˆ¶è£…é¥°å™¨

```python
from functools import wraps
from typing import List

def require_auth(roles: Optional[List[str]] = None):
    """æƒé™æ§åˆ¶è£…é¥°å™¨"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # è·å–ä¸Šä¸‹æ–‡
            ctx = kwargs.get('ctx')
            if not ctx:
                return {"error": "ç¼ºå°‘ä¸Šä¸‹æ–‡"}
            
            # è·å–è®¤è¯ä¿¡æ¯ï¼ˆä»è¯·æ±‚å¤´æˆ–å‚æ•°ä¸­ï¼‰
            token = kwargs.get('token') or ctx.request_context.get('token')
            
            if not token:
                return {
                    "error": "æœªæˆæƒ",
                    "message": "ç¼ºå°‘è®¤è¯ä»¤ç‰Œ"
                }
            
            # éªŒè¯ä»¤ç‰Œ
            token_auth = ctx.request_context.lifespan_context.token_auth
            user_info = token_auth.verify_token(token)
            
            if not user_info:
                return {
                    "error": "æœªæˆæƒ",
                    "message": "ä»¤ç‰Œæ— æ•ˆæˆ–å·²è¿‡æœŸ"
                }
            
            # æ£€æŸ¥è§’è‰²æƒé™
            if roles:
                user_roles = user_info.get("roles", [])
                if not any(role in user_roles for role in roles):
                    return {
                        "error": "æƒé™ä¸è¶³",
                        "message": f"éœ€è¦ä»¥ä¸‹è§’è‰²ä¹‹ä¸€: {', '.join(roles)}"
                    }
            
            # å°†ç”¨æˆ·ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            kwargs['user_info'] = user_info
            
            # æ‰§è¡Œå‡½æ•°
            return await func(*args, **kwargs)
        
        return wrapper
    return decorator


# ä½¿ç”¨æƒé™æ§åˆ¶
@app.tool()
@require_auth()  # éœ€è¦è®¤è¯
async def get_profile(ctx, token: str, user_info: dict):
    """è·å–ç”¨æˆ·èµ„æ–™ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    user_id = user_info["user_id"]
    
    # æŸ¥è¯¢ç”¨æˆ·èµ„æ–™
    profile = await query_user_profile(user_id)
    
    return {
        "user_id": user_id,
        "profile": profile
    }


@app.tool()
@require_auth(roles=["admin"])  # éœ€è¦ç®¡ç†å‘˜è§’è‰²
async def delete_user(user_id: str, ctx, token: str, user_info: dict):
    """åˆ é™¤ç”¨æˆ·ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    admin_id = user_info["user_id"]
    
    # è®°å½•æ•æ„Ÿæ“ä½œ
    logger.warning(
        "ç®¡ç†å‘˜åˆ é™¤ç”¨æˆ·",
        extra={
            "admin_id": admin_id,
            "target_user_id": user_id,
            "action": "delete_user"
        }
    )
    
    # æ‰§è¡Œåˆ é™¤
    await delete_user_from_db(user_id)
    
    return {
        "success": True,
        "message": f"ç”¨æˆ· {user_id} å·²åˆ é™¤"
    }
```

### 5.3 æ•°æ®åŠ å¯†ä¸è„±æ•

ä¿æŠ¤æ•æ„Ÿæ•°æ®ä¸è¢«æ³„éœ²ã€‚

#### æ•æ„Ÿæ•°æ®åŠ å¯†

```python
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2
import base64

class DataEncryption:
    """æ•°æ®åŠ å¯†å·¥å…·"""
    
    def __init__(self, password: str):
        # ä»å¯†ç æ´¾ç”Ÿå¯†é’¥
        kdf = PBKDF2(
            algorithm=hashes.SHA256(),
            length=32,
            salt=b'mcp_server_salt',  # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨éšæœºç›
            iterations=100000,
        )
        key = base64.urlsafe_b64encode(kdf.derive(password.encode()))
        self.cipher = Fernet(key)
    
    def encrypt(self, data: str) -> str:
        """åŠ å¯†æ•°æ®"""
        encrypted = self.cipher.encrypt(data.encode())
        return base64.urlsafe_b64encode(encrypted).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†æ•°æ®"""
        encrypted = base64.urlsafe_b64decode(encrypted_data.encode())
        decrypted = self.cipher.decrypt(encrypted)
        return decrypted.decode()


# ä½¿ç”¨ç¤ºä¾‹
@app.tool()
async def store_sensitive_data(data: str, ctx):
    """å­˜å‚¨æ•æ„Ÿæ•°æ®ï¼ˆåŠ å¯†ï¼‰"""
    encryption = ctx.request_context.lifespan_context.encryption
    
    # åŠ å¯†æ•°æ®
    encrypted = encryption.encrypt(data)
    
    # å­˜å‚¨åŠ å¯†åçš„æ•°æ®
    await save_to_database(encrypted)
    
    return {"success": True, "message": "æ•°æ®å·²åŠ å¯†å­˜å‚¨"}


@app.tool()
async def retrieve_sensitive_data(data_id: str, ctx):
    """è·å–æ•æ„Ÿæ•°æ®ï¼ˆè§£å¯†ï¼‰"""
    encryption = ctx.request_context.lifespan_context.encryption
    
    # ä»æ•°æ®åº“è·å–åŠ å¯†æ•°æ®
    encrypted = await load_from_database(data_id)
    
    # è§£å¯†
    decrypted = encryption.decrypt(encrypted)
    
    return {"success": True, "data": decrypted}
```

#### æ•°æ®è„±æ•

```python
import re

class DataMasking:
    """æ•°æ®è„±æ•å·¥å…·"""
    
    @staticmethod
    def mask_email(email: str) -> str:
        """è„±æ•é‚®ç®±åœ°å€"""
        if '@' not in email:
            return email
        
        username, domain = email.split('@')
        
        if len(username) <= 2:
            masked_username = '*' * len(username)
        else:
            masked_username = username[0] + '*' * (len(username) - 2) + username[-1]
        
        return f"{masked_username}@{domain}"
    
    @staticmethod
    def mask_phone(phone: str) -> str:
        """è„±æ•æ‰‹æœºå·"""
        if len(phone) < 11:
            return phone
        
        return phone[:3] + '*' * 4 + phone[-4:]
    
    @staticmethod
    def mask_id_card(id_card: str) -> str:
        """è„±æ•èº«ä»½è¯å·"""
        if len(id_card) < 18:
            return id_card
        
        return id_card[:6] + '*' * 8 + id_card[-4:]
    
    @staticmethod
    def mask_credit_card(card_number: str) -> str:
        """è„±æ•ä¿¡ç”¨å¡å·"""
        if len(card_number) < 16:
            return card_number
        
        return '*' * 12 + card_number[-4:]
    
    @staticmethod
    def mask_password(password: str) -> str:
        """è„±æ•å¯†ç ï¼ˆå®Œå…¨éšè—ï¼‰"""
        return '*' * len(password)


# åœ¨æ—¥å¿—ä¸­ä½¿ç”¨è„±æ•
@app.tool()
async def update_user_info(
    user_id: str,
    email: str,
    phone: str,
    ctx
):
    """æ›´æ–°ç”¨æˆ·ä¿¡æ¯"""
    logger = ctx.request_context.lifespan_context.logger
    
    # è®°å½•æ—¥å¿—æ—¶è„±æ•
    logger.info(
        "æ›´æ–°ç”¨æˆ·ä¿¡æ¯",
        extra={
            "user_id": user_id,
            "email": DataMasking.mask_email(email),  # è„±æ•
            "phone": DataMasking.mask_phone(phone)   # è„±æ•
        }
    )
    
    # å®é™…æ›´æ–°ï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼‰
    await update_database(user_id, email, phone)
    
    return {
        "success": True,
        "updated_email": DataMasking.mask_email(email),
        "updated_phone": DataMasking.mask_phone(phone)
    }
```

### 5.4 è¾“å…¥éªŒè¯ä¸é˜²æŠ¤

é˜²æ­¢æ³¨å…¥æ”»å‡»å’Œæ¶æ„è¾“å…¥ã€‚

#### è¾“å…¥éªŒè¯å™¨

```python
from pydantic import BaseModel, validator, Field
from typing import Optional
import re

class UserInput(BaseModel):
    """ç”¨æˆ·è¾“å…¥éªŒè¯æ¨¡å‹"""
    
    username: str = Field(..., min_length=3, max_length=50)
    email: str
    age: Optional[int] = Field(None, ge=0, le=150)
    
    @validator('username')
    def validate_username(cls, v):
        """éªŒè¯ç”¨æˆ·å"""
        # åªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
        if not re.match(r'^[a-zA-Z0-9_]+$', v):
            raise ValueError('ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿')
        return v
    
    @validator('email')
    def validate_email(cls, v):
        """éªŒè¯é‚®ç®±"""
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(email_pattern, v):
            raise ValueError('æ— æ•ˆçš„é‚®ç®±åœ°å€')
        return v


class SQLInjectionPrevention:
    """SQL æ³¨å…¥é˜²æŠ¤"""
    
    @staticmethod
    def is_safe_input(input_str: str) -> bool:
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦å®‰å…¨"""
        # å±é™©çš„ SQL å…³é”®å­—
        dangerous_patterns = [
            r'\bDROP\b', r'\bDELETE\b', r'\bUPDATE\b',
            r'\bINSERT\b', r'\bEXEC\b', r'\bUNION\b',
            r'--', r'/\*', r'\*/', r';'
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, input_str, re.IGNORECASE):
                return False
        
        return True
    
    @staticmethod
    def sanitize_input(input_str: str) -> str:
        """æ¸…ç†è¾“å…¥"""
        # ç§»é™¤å±é™©å­—ç¬¦
        sanitized = re.sub(r'[;\'"\\]', '', input_str)
        return sanitized.strip()


class CommandInjectionPrevention:
    """å‘½ä»¤æ³¨å…¥é˜²æŠ¤"""
    
    @staticmethod
    def is_safe_filename(filename: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å®‰å…¨"""
        # åªå…è®¸å­—æ¯ã€æ•°å­—ã€ç‚¹ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦
        if not re.match(r'^[a-zA-Z0-9._-]+$', filename):
            return False
        
        # ä¸å…è®¸è·¯å¾„éå†
        if '..' in filename or '/' in filename or '\\' in filename:
            return False
        
        return True


# ä½¿ç”¨è¾“å…¥éªŒè¯
@app.tool()
async def create_user(
    username: str,
    email: str,
    age: Optional[int],
    ctx
):
    """åˆ›å»ºç”¨æˆ·ï¼ˆå¸¦è¾“å…¥éªŒè¯ï¼‰"""
    
    try:
        # éªŒè¯è¾“å…¥
        user_input = UserInput(
            username=username,
            email=email,
            age=age
        )
        
        # æ‰§è¡Œåˆ›å»º
        user_id = await create_user_in_db(
            user_input.username,
            user_input.email,
            user_input.age
        )
        
        return {
            "success": True,
            "user_id": user_id
        }
        
    except ValueError as e:
        return {
            "success": False,
            "error": "è¾“å…¥éªŒè¯å¤±è´¥",
            "details": str(e)
        }


@app.tool()
async def search_users(query: str, ctx):
    """æœç´¢ç”¨æˆ·ï¼ˆé˜² SQL æ³¨å…¥ï¼‰"""
    
    # æ£€æŸ¥è¾“å…¥å®‰å…¨æ€§
    if not SQLInjectionPrevention.is_safe_input(query):
        return {
            "success": False,
            "error": "æ£€æµ‹åˆ°æ½œåœ¨çš„ SQL æ³¨å…¥æ”»å‡»"
        }
    
    # æ¸…ç†è¾“å…¥
    safe_query = SQLInjectionPrevention.sanitize_input(query)
    
    # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ï¼ˆæœ€ä½³å®è·µï¼‰
    results = await search_users_in_db(safe_query)
    
    return {
        "success": True,
        "results": results
    }
```

### 5.5 é€Ÿç‡é™åˆ¶

é˜²æ­¢æ»¥ç”¨å’Œ DoS æ”»å‡»ã€‚

```python
from collections import defaultdict
from datetime import datetime, timedelta

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    
    def __init__(
        self,
        max_requests: int = 100,
        time_window: int = 60
    ):
        self.max_requests = max_requests  # æœ€å¤§è¯·æ±‚æ•°
        self.time_window = time_window    # æ—¶é—´çª—å£ï¼ˆç§’ï¼‰
        self.requests = defaultdict(list)  # user_id -> [timestamps]
    
    def is_allowed(self, user_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚"""
        now = datetime.now()
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        cutoff = now - timedelta(seconds=self.time_window)
        self.requests[user_id] = [
            ts for ts in self.requests[user_id]
            if ts > cutoff
        ]
        
        # æ£€æŸ¥è¯·æ±‚æ•°
        if len(self.requests[user_id]) >= self.max_requests:
            return False
        
        # è®°å½•æœ¬æ¬¡è¯·æ±‚
        self.requests[user_id].append(now)
        return True
    
    def get_remaining(self, user_id: str) -> int:
        """è·å–å‰©ä½™è¯·æ±‚æ•°"""
        return self.max_requests - len(self.requests[user_id])


def rate_limit(max_requests: int = 100, time_window: int = 60):
    """é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            ctx = kwargs.get('ctx')
            user_info = kwargs.get('user_info', {})
            user_id = user_info.get('user_id', 'anonymous')
            
            # è·å–é€Ÿç‡é™åˆ¶å™¨
            rate_limiter = ctx.request_context.lifespan_context.rate_limiter
            
            # æ£€æŸ¥æ˜¯å¦å…è®¸
            if not rate_limiter.is_allowed(user_id):
                remaining = rate_limiter.get_remaining(user_id)
                return {
                    "error": "è¯·æ±‚è¿‡äºé¢‘ç¹",
                    "message": f"è¯·åœ¨ {time_window} ç§’åé‡è¯•",
                    "remaining": remaining
                }
            
            # æ‰§è¡Œå‡½æ•°
            return await func(*args, **kwargs)
        
        return wrapper
    return decorator


# ä½¿ç”¨é€Ÿç‡é™åˆ¶
@app.tool()
@require_auth()
@rate_limit(max_requests=10, time_window=60)  # æ¯åˆ†é’Ÿæœ€å¤š10æ¬¡
async def expensive_operation(data: str, ctx, token: str, user_info: dict):
    """è€—æ—¶æ“ä½œï¼ˆé™åˆ¶é¢‘ç‡ï¼‰"""
    result = await perform_expensive_task(data)
    return {"success": True, "result": result}
```

### 5.6 å®‰å…¨å®¡è®¡

è®°å½•æ‰€æœ‰æ•æ„Ÿæ“ä½œï¼Œä¾¿äºäº‹åå®¡æŸ¥ã€‚

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass
class AuditLog:
    """å®¡è®¡æ—¥å¿—"""
    
    timestamp: datetime
    user_id: str
    action: str
    resource: str
    result: str
    ip_address: Optional[str] = None
    details: Optional[dict] = None
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "user_id": self.user_id,
            "action": self.action,
            "resource": self.resource,
            "result": self.result,
            "ip_address": self.ip_address,
            "details": self.details
        }


class AuditLogger:
    """å®‰å…¨å®¡è®¡è®°å½•å™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    async def log_action(
        self,
        user_id: str,
        action: str,
        resource: str,
        result: str,
        ip_address: Optional[str] = None,
        details: Optional[dict] = None
    ):
        """è®°å½•æ“ä½œ"""
        audit_log = AuditLog(
            timestamp=datetime.now(),
            user_id=user_id,
            action=action,
            resource=resource,
            result=result,
            ip_address=ip_address,
            details=details
        )
        
        # è®°å½•åˆ°æ—¥å¿—
        self.logger.info(
            "å®‰å…¨å®¡è®¡",
            extra={"audit": audit_log.to_dict()}
        )
        
        # ä¹Ÿå¯ä»¥ä¿å­˜åˆ°ä¸“é—¨çš„å®¡è®¡æ•°æ®åº“
        await self.save_to_audit_db(audit_log)
    
    async def save_to_audit_db(self, audit_log: AuditLog):
        """ä¿å­˜åˆ°å®¡è®¡æ•°æ®åº“"""
        # å®ç°æ•°æ®åº“ä¿å­˜é€»è¾‘
        pass


# æ•æ„Ÿæ“ä½œå®¡è®¡
@app.tool()
@require_auth(roles=["admin"])
async def delete_sensitive_data(
    data_id: str,
    ctx,
    token: str,
    user_info: dict
):
    """åˆ é™¤æ•æ„Ÿæ•°æ®ï¼ˆå®¡è®¡ï¼‰"""
    
    audit_logger = ctx.request_context.lifespan_context.audit_logger
    user_id = user_info["user_id"]
    
    try:
        # æ‰§è¡Œåˆ é™¤
        await delete_from_database(data_id)
        
        # è®°å½•æˆåŠŸçš„å®¡è®¡æ—¥å¿—
        await audit_logger.log_action(
            user_id=user_id,
            action="delete_sensitive_data",
            resource=f"data:{data_id}",
            result="success",
            details={
                "data_id": data_id,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        return {"success": True}
        
    except Exception as e:
        # è®°å½•å¤±è´¥çš„å®¡è®¡æ—¥å¿—
        await audit_logger.log_action(
            user_id=user_id,
            action="delete_sensitive_data",
            resource=f"data:{data_id}",
            result="failure",
            details={
                "data_id": data_id,
                "error": str(e)
            }
        )
        
        return {"success": False, "error": str(e)}
```

---


## 6. æµ‹è¯•ä¸è°ƒè¯•

### 6.1 ä¸ºä»€ä¹ˆéœ€è¦æµ‹è¯•ï¼Ÿ

æµ‹è¯•æ˜¯ä¿è¯ä»£ç è´¨é‡çš„å…³é”®ã€‚æ²¡æœ‰æµ‹è¯•çš„ä»£ç å°±åƒèµ°é’¢ä¸æ²¡æœ‰å®‰å…¨ç½‘ã€‚

#### æµ‹è¯•çš„ä»·å€¼

```
åœºæ™¯å¯¹æ¯”ï¼šç”Ÿäº§ç¯å¢ƒå‘ç° bug

âŒ æ²¡æœ‰æµ‹è¯•ï¼š
1. ç”¨æˆ·å‘ç° bug â†’ æäº¤é—®é¢˜
2. å¼€å‘èŠ±2å°æ—¶å®šä½é—®é¢˜
3. ä¿®å¤ä»£ç 
4. æ‹…å¿ƒä¿®å¤ä¼šå¼•å…¥æ–°é—®é¢˜
5. å°å¿ƒç¿¼ç¿¼éƒ¨ç½²
6. ç¥ˆç¥·ä¸è¦å‡ºé—®é¢˜

âœ… æœ‰å®Œå–„æµ‹è¯•ï¼š
1. å†™ä»£ç æ—¶å°±å‘ç° bug
2. æµ‹è¯•å¤±è´¥æ˜ç¡®æŒ‡å‡ºé—®é¢˜
3. ä¿®å¤ä»£ç 
4. è¿è¡Œæµ‹è¯•ï¼Œç¡®ä¿ä¿®å¤æˆåŠŸ
5. è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼Œç¡®ä¿æ²¡æœ‰ç ´åå…¶ä»–åŠŸèƒ½
6. è‡ªä¿¡åœ°éƒ¨ç½²

å¥½å¤„ï¼š
- æå‰å‘ç° bugï¼ˆèŠ‚çœæ—¶é—´å’Œæˆæœ¬ï¼‰
- å¿«é€Ÿå®šä½é—®é¢˜
- é‡æ„æ—¶æœ‰ä¿éšœ
- æ–‡æ¡£åŒ–ä»£ç è¡Œä¸º
```

#### æµ‹è¯•é‡‘å­—å¡”

```
           /\
          /  \
         / UI \      å°‘é‡ E2E æµ‹è¯•
        /______\     (æ…¢ï¼Œè„†å¼±)
       /        \
      /  é›†æˆæµ‹è¯• \   é€‚é‡é›†æˆæµ‹è¯•
     /____________\  (ä¸­é€Ÿ)
    /              \
   /    å•å…ƒæµ‹è¯•     \ å¤§é‡å•å…ƒæµ‹è¯•
  /__________________\ (å¿«ï¼Œç¨³å®š)

åŸåˆ™ï¼š
- å•å…ƒæµ‹è¯•æœ€å¤šï¼ˆå¿«é€Ÿï¼Œéš”ç¦»ï¼‰
- é›†æˆæµ‹è¯•é€‚é‡ï¼ˆéªŒè¯ç»„ä»¶åä½œï¼‰
- E2E æµ‹è¯•æœ€å°‘ï¼ˆæ…¢ï¼Œç»´æŠ¤æˆæœ¬é«˜ï¼‰
```

### 6.2 å•å…ƒæµ‹è¯•

å•å…ƒæµ‹è¯•é’ˆå¯¹å•ä¸ªå‡½æ•°æˆ–æ–¹æ³•ï¼ŒéªŒè¯å…¶è¡Œä¸ºæ˜¯å¦æ­£ç¡®ã€‚

#### åŸºç¡€å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import Mock, patch, AsyncMock

# è¢«æµ‹è¯•çš„å‡½æ•°
async def calculate_total(items: list[dict]) -> float:
    """è®¡ç®—æ€»ä»·"""
    total = 0.0
    for item in items:
        total += item["price"] * item["quantity"]
    return total


# æµ‹è¯•ç”¨ä¾‹
class TestCalculateTotal:
    """æµ‹è¯• calculate_total å‡½æ•°"""
    
    @pytest.mark.asyncio
    async def test_empty_list(self):
        """æµ‹è¯•ç©ºåˆ—è¡¨"""
        result = await calculate_total([])
        assert result == 0.0
    
    @pytest.mark.asyncio
    async def test_single_item(self):
        """æµ‹è¯•å•ä¸ªå•†å“"""
        items = [{"price": 10.0, "quantity": 2}]
        result = await calculate_total(items)
        assert result == 20.0
    
    @pytest.mark.asyncio
    async def test_multiple_items(self):
        """æµ‹è¯•å¤šä¸ªå•†å“"""
        items = [
            {"price": 10.0, "quantity": 2},
            {"price": 5.0, "quantity": 3}
        ]
        result = await calculate_total(items)
        assert result == 35.0
    
    @pytest.mark.asyncio
    async def test_zero_quantity(self):
        """æµ‹è¯•æ•°é‡ä¸º0"""
        items = [{"price": 10.0, "quantity": 0}]
        result = await calculate_total(items)
        assert result == 0.0


# è¿è¡Œæµ‹è¯•
# pytest test_calculator.py -v
```

#### æµ‹è¯• MCP å·¥å…·

```python
import pytest
from unittest.mock import AsyncMock, MagicMock

# è¢«æµ‹è¯•çš„å·¥å…·
async def search_tool(query: str, ctx) -> dict:
    """æœç´¢å·¥å…·"""
    # ä»ä¸Šä¸‹æ–‡è·å–ç¼“å­˜
    cache = ctx.request_context.lifespan_context.cache
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"search:{query}"
    cached = cache.get(cache_key)
    if cached:
        return {"cached": True, "result": cached}
    
    # æ‰§è¡Œæœç´¢
    result = await perform_search(query)
    
    # ä¿å­˜åˆ°ç¼“å­˜
    cache.set(cache_key, result)
    
    return {"cached": False, "result": result}


# æµ‹è¯•ç±»
class TestSearchTool:
    """æµ‹è¯•æœç´¢å·¥å…·"""
    
    @pytest.fixture
    def mock_context(self):
        """åˆ›å»ºæ¨¡æ‹Ÿä¸Šä¸‹æ–‡"""
        ctx = MagicMock()
        
        # æ¨¡æ‹Ÿç¼“å­˜
        cache = MagicMock()
        cache.get = MagicMock(return_value=None)
        cache.set = MagicMock()
        
        ctx.request_context.lifespan_context.cache = cache
        
        return ctx
    
    @pytest.mark.asyncio
    async def test_cache_miss(self, mock_context):
        """æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­"""
        with patch('__main__.perform_search', new_callable=AsyncMock) as mock_search:
            mock_search.return_value = ["result1", "result2"]
            
            result = await search_tool("Python", mock_context)
            
            # éªŒè¯ç»“æœ
            assert result["cached"] is False
            assert result["result"] == ["result1", "result2"]
            
            # éªŒè¯è°ƒç”¨
            mock_search.assert_called_once_with("Python")
            mock_context.request_context.lifespan_context.cache.set.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_cache_hit(self, mock_context):
        """æµ‹è¯•ç¼“å­˜å‘½ä¸­"""
        # è®¾ç½®ç¼“å­˜è¿”å›å€¼
        mock_context.request_context.lifespan_context.cache.get.return_value = ["cached_result"]
        
        with patch('__main__.perform_search', new_callable=AsyncMock) as mock_search:
            result = await search_tool("Python", mock_context)
            
            # éªŒè¯ç»“æœ
            assert result["cached"] is True
            assert result["result"] == ["cached_result"]
            
            # éªŒè¯æ²¡æœ‰è°ƒç”¨æœç´¢
            mock_search.assert_not_called()


# å‚æ•°åŒ–æµ‹è¯•
@pytest.mark.parametrize("query,expected", [
    ("Python", ["Python tutorial"]),
    ("JavaScript", ["JS guide"]),
    ("", []),
])
@pytest.mark.asyncio
async def test_search_with_different_queries(query, expected, mock_context):
    """æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢"""
    with patch('__main__.perform_search', new_callable=AsyncMock) as mock_search:
        mock_search.return_value = expected
        
        result = await search_tool(query, mock_context)
        
        assert result["result"] == expected
```

### 6.3 é›†æˆæµ‹è¯•

é›†æˆæµ‹è¯•éªŒè¯å¤šä¸ªç»„ä»¶ååŒå·¥ä½œã€‚

#### MCP Server é›†æˆæµ‹è¯•

```python
import pytest
import asyncio
from mcp import ClientSession
from mcp.client.stdio import stdio_client, StdioServerParameters

@pytest.fixture
async def mcp_server():
    """å¯åŠ¨ MCP Server ç”¨äºæµ‹è¯•"""
    server_params = StdioServerParameters(
        command="python",
        args=["-m", "my_mcp_server"]
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            yield session


class TestMCPServerIntegration:
    """MCP Server é›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_server_initialization(self, mcp_server):
        """æµ‹è¯•æœåŠ¡å™¨åˆå§‹åŒ–"""
        # æœåŠ¡å™¨åº”è¯¥æ­£å¸¸åˆå§‹åŒ–
        assert mcp_server is not None
    
    @pytest.mark.asyncio
    async def test_list_tools(self, mcp_server):
        """æµ‹è¯•åˆ—å‡ºå·¥å…·"""
        tools = await mcp_server.list_tools()
        
        # éªŒè¯å·¥å…·åˆ—è¡¨
        assert len(tools.tools) > 0
        
        # éªŒè¯ç‰¹å®šå·¥å…·å­˜åœ¨
        tool_names = [t.name for t in tools.tools]
        assert "search" in tool_names
    
    @pytest.mark.asyncio
    async def test_call_tool(self, mcp_server):
        """æµ‹è¯•è°ƒç”¨å·¥å…·"""
        result = await mcp_server.call_tool(
            "search",
            arguments={"query": "Python"}
        )
        
        # éªŒè¯ç»“æœ
        assert result is not None
        assert len(result.content) > 0
    
    @pytest.mark.asyncio
    async def test_tool_error_handling(self, mcp_server):
        """æµ‹è¯•å·¥å…·é”™è¯¯å¤„ç†"""
        with pytest.raises(Exception):
            await mcp_server.call_tool(
                "nonexistent_tool",
                arguments={}
            )
    
    @pytest.mark.asyncio
    async def test_end_to_end_workflow(self, mcp_server):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        # 1. åˆ—å‡ºå·¥å…·
        tools = await mcp_server.list_tools()
        assert len(tools.tools) > 0
        
        # 2. è°ƒç”¨æœç´¢å·¥å…·
        search_result = await mcp_server.call_tool(
            "search",
            arguments={"query": "Python"}
        )
        assert search_result.content[0].text is not None
        
        # 3. åˆ—å‡ºèµ„æº
        resources = await mcp_server.list_resources()
        assert resources is not None
```

#### æ•°æ®åº“é›†æˆæµ‹è¯•

```python
import pytest
import asyncpg

@pytest.fixture
async def test_db():
    """åˆ›å»ºæµ‹è¯•æ•°æ®åº“"""
    # è¿æ¥æ•°æ®åº“
    conn = await asyncpg.connect(
        host="localhost",
        port=5432,
        user="test_user",
        password="test_password",
        database="test_db"
    )
    
    # åˆ›å»ºæµ‹è¯•è¡¨
    await conn.execute("""
        CREATE TABLE IF NOT EXISTS users (
            id SERIAL PRIMARY KEY,
            username VARCHAR(50),
            email VARCHAR(100)
        )
    """)
    
    yield conn
    
    # æ¸…ç†
    await conn.execute("DROP TABLE users")
    await conn.close()


class TestDatabaseIntegration:
    """æ•°æ®åº“é›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_insert_user(self, test_db):
        """æµ‹è¯•æ’å…¥ç”¨æˆ·"""
        await test_db.execute(
            "INSERT INTO users (username, email) VALUES ($1, $2)",
            "alice", "alice@example.com"
        )
        
        # éªŒè¯æ’å…¥
        row = await test_db.fetchrow("SELECT * FROM users WHERE username = $1", "alice")
        assert row["username"] == "alice"
        assert row["email"] == "alice@example.com"
    
    @pytest.mark.asyncio
    async def test_query_user(self, test_db):
        """æµ‹è¯•æŸ¥è¯¢ç”¨æˆ·"""
        # æ’å…¥æµ‹è¯•æ•°æ®
        await test_db.execute(
            "INSERT INTO users (username, email) VALUES ($1, $2)",
            "bob", "bob@example.com"
        )
        
        # æŸ¥è¯¢
        row = await test_db.fetchrow("SELECT * FROM users WHERE username = $1", "bob")
        assert row is not None
```

### 6.4 å‹åŠ›æµ‹è¯•

éªŒè¯ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„è¡¨ç°ã€‚

```python
import asyncio
import time
from typing import List

class LoadTester:
    """å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self, target_func, concurrent_users: int = 10):
        self.target_func = target_func
        self.concurrent_users = concurrent_users
        self.results = []
    
    async def run_single_user(self, user_id: int):
        """å•ä¸ªç”¨æˆ·çš„æµ‹è¯•"""
        start_time = time.time()
        
        try:
            result = await self.target_func(user_id)
            duration = time.time() - start_time
            
            self.results.append({
                "user_id": user_id,
                "success": True,
                "duration": duration,
                "result": result
            })
        except Exception as e:
            duration = time.time() - start_time
            
            self.results.append({
                "user_id": user_id,
                "success": False,
                "duration": duration,
                "error": str(e)
            })
    
    async def run(self, duration_seconds: int = 60):
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        print(f"ğŸš€ å¯åŠ¨å‹åŠ›æµ‹è¯•ï¼š{self.concurrent_users} å¹¶å‘ç”¨æˆ·")
        start_time = time.time()
        
        tasks = []
        user_id = 0
        
        while time.time() - start_time < duration_seconds:
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            for _ in range(self.concurrent_users):
                task = asyncio.create_task(self.run_single_user(user_id))
                tasks.append(task)
                user_id += 1
            
            # ç­‰å¾…ä¸€æ‰¹å®Œæˆ
            await asyncio.gather(*tasks)
            tasks = []
            
            # çŸ­æš‚ä¼‘æ¯
            await asyncio.sleep(0.1)
        
        self.print_report()
    
    def print_report(self):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        total = len(self.results)
        successful = sum(1 for r in self.results if r["success"])
        failed = total - successful
        
        durations = [r["duration"] for r in self.results if r["success"]]
        
        if durations:
            avg_duration = sum(durations) / len(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            
            # P95
            sorted_durations = sorted(durations)
            p95_index = int(len(sorted_durations) * 0.95)
            p95_duration = sorted_durations[p95_index]
        else:
            avg_duration = min_duration = max_duration = p95_duration = 0
        
        print("\n" + "=" * 60)
        print("ğŸ“Š å‹åŠ›æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»è¯·æ±‚æ•°ï¼š{total}")
        print(f"æˆåŠŸï¼š{successful} ({successful/total*100:.1f}%)")
        print(f"å¤±è´¥ï¼š{failed} ({failed/total*100:.1f}%)")
        print(f"\nå“åº”æ—¶é—´ç»Ÿè®¡ï¼ˆç§’ï¼‰ï¼š")
        print(f"  å¹³å‡ï¼š{avg_duration:.3f}")
        print(f"  æœ€å°ï¼š{min_duration:.3f}")
        print(f"  æœ€å¤§ï¼š{max_duration:.3f}")
        print(f"  P95ï¼š{p95_duration:.3f}")
        print("=" * 60)


# ä½¿ç”¨ç¤ºä¾‹
async def test_api_call(user_id: int):
    """è¢«æµ‹è¯•çš„ API è°ƒç”¨"""
    # æ¨¡æ‹Ÿ API è°ƒç”¨
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå»¶è¿Ÿ
    return f"Result for user {user_id}"


async def run_load_test():
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""
    tester = LoadTester(
        target_func=test_api_call,
        concurrent_users=50  # 50 ä¸ªå¹¶å‘ç”¨æˆ·
    )
    
    await tester.run(duration_seconds=30)  # è¿è¡Œ 30 ç§’


# è¿è¡Œ
# asyncio.run(run_load_test())
```

### 6.5 è°ƒè¯•æŠ€å·§

#### ä½¿ç”¨ Python è°ƒè¯•å™¨

```python
import pdb

@app.tool()
async def debug_tool(data: str, ctx):
    """å¸¦è°ƒè¯•çš„å·¥å…·"""
    
    # è®¾ç½®æ–­ç‚¹
    pdb.set_trace()  # ç¨‹åºä¼šåœ¨è¿™é‡Œæš‚åœ
    
    # å¯ä»¥åœ¨è°ƒè¯•å™¨ä¸­ï¼š
    # - æŸ¥çœ‹å˜é‡ï¼šprint(data)
    # - æ‰§è¡Œä»£ç ï¼šresult = data.upper()
    # - ç»§ç»­æ‰§è¡Œï¼šc (continue)
    # - å•æ­¥æ‰§è¡Œï¼šn (next)
    # - è¿›å…¥å‡½æ•°ï¼šs (step)
    
    result = process_data(data)
    
    return {"result": result}
```

#### æ¡ä»¶æ–­ç‚¹

```python
import pdb

@app.tool()
async def conditional_debug(items: list, ctx):
    """æ¡ä»¶è°ƒè¯•"""
    
    for i, item in enumerate(items):
        # åªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹è°ƒè¯•
        if item.get("error"):
            pdb.set_trace()  # åªæœ‰å‡ºé”™æ—¶æ‰æš‚åœ
        
        process_item(item)
    
    return {"processed": len(items)}
```

#### æ—¥å¿—è°ƒè¯•

```python
import logging

logger = logging.getLogger(__name__)

@app.tool()
async def debug_with_logging(data: str, ctx):
    """ä½¿ç”¨æ—¥å¿—è°ƒè¯•"""
    
    # è®°å½•å‡½æ•°å…¥å£
    logger.debug(f"è¿›å…¥å‡½æ•°ï¼Œå‚æ•°ï¼šdata={data}")
    
    # è®°å½•ä¸­é—´æ­¥éª¤
    step1 = data.upper()
    logger.debug(f"æ­¥éª¤1å®Œæˆï¼š{step1}")
    
    step2 = step1.replace(" ", "_")
    logger.debug(f"æ­¥éª¤2å®Œæˆï¼š{step2}")
    
    # è®°å½•å‡½æ•°å‡ºå£
    logger.debug(f"å‡½æ•°è¿”å›ï¼š{step2}")
    
    return {"result": step2}
```

#### æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats
from io import StringIO

def profile_function(func):
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        result = func(*args, **kwargs)
        
        profiler.disable()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        stream = StringIO()
        stats = pstats.Stats(profiler, stream=stream)
        stats.sort_stats('cumulative')
        stats.print_stats(10)  # æ˜¾ç¤ºå‰10ä¸ªæœ€æ…¢çš„å‡½æ•°
        
        print(stream.getvalue())
        
        return result
    
    return wrapper


@profile_function
def slow_function():
    """éœ€è¦æ€§èƒ½åˆ†æçš„å‡½æ•°"""
    total = 0
    for i in range(1000000):
        total += i
    return total
```

#### å†…å­˜åˆ†æ

```python
import tracemalloc

@app.tool()
async def memory_debug(ctx):
    """å†…å­˜è°ƒè¯•"""
    
    # å¼€å§‹è¿½è¸ªå†…å­˜
    tracemalloc.start()
    
    # è®°å½•èµ·å§‹å†…å­˜
    snapshot1 = tracemalloc.take_snapshot()
    
    # æ‰§è¡Œæ“ä½œ
    large_list = [i for i in range(1000000)]
    
    # è®°å½•ç»“æŸå†…å­˜
    snapshot2 = tracemalloc.take_snapshot()
    
    # æ¯”è¾ƒå·®å¼‚
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')
    
    print("[ Top 10 å†…å­˜å¢é•¿ ]")
    for stat in top_stats[:10]:
        print(stat)
    
    tracemalloc.stop()
    
    return {"memory_tracked": True}
```

### 6.6 æµ‹è¯•è¦†ç›–ç‡

è¡¡é‡æµ‹è¯•çš„å®Œæ•´æ€§ã€‚

```python
# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
# pytest --cov=my_mcp_server --cov-report=html tests/

# æŸ¥çœ‹è¦†ç›–ç‡
# open htmlcov/index.html
```

#### é…ç½® pytest.ini

```ini
[pytest]
# æµ‹è¯•æ–‡ä»¶æ¨¡å¼
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# å¼‚æ­¥æµ‹è¯•æ”¯æŒ
asyncio_mode = auto

# è¦†ç›–ç‡é…ç½®
addopts = 
    --cov=my_mcp_server
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
    -v

# å¿½ç•¥çš„æ–‡ä»¶
testpaths = tests
```

### 6.7 æŒç»­é›†æˆï¼ˆCIï¼‰

è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹ã€‚

#### GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov
    
    - name: Run tests
      run: |
        pytest --cov=my_mcp_server --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: true
```

---


## 7. æœ€ä½³å®è·µä¸æ€»ç»“

### 7.1 é¡¹ç›®ç»“æ„ç»„ç»‡

è‰¯å¥½çš„é¡¹ç›®ç»“æ„ä½¿ä»£ç æ˜“äºç†è§£å’Œç»´æŠ¤ã€‚

#### æ¨èçš„é¡¹ç›®ç»“æ„

```
my_mcp_server/
â”‚
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ requirements.txt          # Python ä¾èµ–
â”œâ”€â”€ .env.example             # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ .gitignore               # Git å¿½ç•¥æ–‡ä»¶
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py            # ä¸»æœåŠ¡å™¨æ–‡ä»¶
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/               # å·¥å…·ç›®å½•
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py        # æœç´¢å·¥å…·
â”‚   â”‚   â”œâ”€â”€ database.py      # æ•°æ®åº“å·¥å…·
â”‚   â”‚   â””â”€â”€ calculator.py    # è®¡ç®—å·¥å…·
â”‚   â”‚
â”‚   â”œâ”€â”€ resources/           # èµ„æºç›®å½•
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ documents.py     # æ–‡æ¡£èµ„æº
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py          # è®¤è¯
â”‚   â”‚   â”œâ”€â”€ cache.py         # ç¼“å­˜
â”‚   â”‚   â”œâ”€â”€ database.py      # æ•°æ®åº“
â”‚   â”‚   â””â”€â”€ logging.py       # æ—¥å¿—
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic æ¨¡å‹
â”‚   â”‚
â”‚   â””â”€â”€ utils/               # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ validators.py    # éªŒè¯å™¨
â”‚       â””â”€â”€ helpers.py       # è¾…åŠ©å‡½æ•°
â”‚
â”œâ”€â”€ tests/                   # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_tools.py        # å·¥å…·æµ‹è¯•
â”‚   â”œâ”€â”€ test_resources.py    # èµ„æºæµ‹è¯•
â”‚   â””â”€â”€ conftest.py          # pytest é…ç½®
â”‚
â”œâ”€â”€ config/                  # é…ç½®ç›®å½•
â”‚   â”œâ”€â”€ development.json     # å¼€å‘é…ç½®
â”‚   â”œâ”€â”€ production.json      # ç”Ÿäº§é…ç½®
â”‚   â””â”€â”€ test.json           # æµ‹è¯•é…ç½®
â”‚
â”œâ”€â”€ logs/                    # æ—¥å¿—ç›®å½•
â”‚
â””â”€â”€ docs/                    # æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ api.md              # API æ–‡æ¡£
    â””â”€â”€ deployment.md       # éƒ¨ç½²æ–‡æ¡£
```

#### æ¨¡å—åŒ–è®¾è®¡ç¤ºä¾‹

```python
# src/server.py - ä¸»æœåŠ¡å™¨æ–‡ä»¶
from mcp.server import Server
from .tools import register_tools
from .resources import register_resources
from .core import init_core_components

app = Server("production-mcp-server")

# æ³¨å†Œå·¥å…·
register_tools(app)

# æ³¨å†Œèµ„æº
register_resources(app)

# åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
@app.lifespan()
async def lifespan(ctx):
    await init_core_components(ctx)
    yield


# src/tools/__init__.py - å·¥å…·æ³¨å†Œ
from .search import register_search_tools
from .database import register_database_tools
from .calculator import register_calculator_tools

def register_tools(app):
    """æ³¨å†Œæ‰€æœ‰å·¥å…·"""
    register_search_tools(app)
    register_database_tools(app)
    register_calculator_tools(app)


# src/tools/search.py - æœç´¢å·¥å…·
def register_search_tools(app):
    """æ³¨å†Œæœç´¢ç›¸å…³å·¥å…·"""
    
    @app.tool()
    async def web_search(query: str, ctx):
        """Web æœç´¢å·¥å…·"""
        # å®ç°...
        pass
    
    @app.tool()
    async def local_search(query: str, ctx):
        """æœ¬åœ°æœç´¢å·¥å…·"""
        # å®ç°...
        pass
```

### 7.2 é…ç½®ç®¡ç†

#### ä½¿ç”¨é…ç½®æ–‡ä»¶

```python
# src/core/config.py
from pydantic import BaseSettings
from typing import Optional
import json
from pathlib import Path

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""
    
    # åŸºç¡€é…ç½®
    app_name: str = "MCP Server"
    version: str = "1.0.0"
    environment: str = "development"
    
    # æ•°æ®åº“é…ç½®
    db_host: str = "localhost"
    db_port: int = 5432
    db_user: str = "postgres"
    db_password: str = ""
    db_name: str = "mcp_db"
    
    # Redis é…ç½®
    redis_url: str = "redis://localhost:6379"
    
    # æ—¥å¿—é…ç½®
    log_level: str = "INFO"
    log_dir: str = "logs"
    
    # å®‰å…¨é…ç½®
    jwt_secret: str = ""
    jwt_expires_in: int = 3600
    
    # æ€§èƒ½é…ç½®
    cache_ttl: int = 300
    max_connections: int = 100
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
    
    @classmethod
    def load_from_file(cls, config_file: str):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        config_path = Path(config_file)
        if config_path.exists():
            with open(config_path) as f:
                config_data = json.load(f)
            return cls(**config_data)
        return cls()


# ä½¿ç”¨é…ç½®
import os

env = os.getenv("ENVIRONMENT", "development")
config = Settings.load_from_file(f"config/{env}.json")
```

#### ç¯å¢ƒå˜é‡ç®¡ç†

```bash
# .env.example
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥å®é™…å€¼

# åº”ç”¨é…ç½®
APP_NAME=MCP Server
ENVIRONMENT=production

# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=your_password_here
DB_NAME=mcp_db

# Redis é…ç½®
REDIS_URL=redis://localhost:6379

# å®‰å…¨é…ç½®
JWT_SECRET=your_secret_key_here

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
```

### 7.3 éƒ¨ç½²æœ€ä½³å®è·µ

#### Docker éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY src/ ./src/
COPY config/ ./config/

# åˆ›å»ºæ—¥å¿—ç›®å½•
RUN mkdir -p logs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV ENVIRONMENT=production

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦ï¼‰
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "src.server"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  mcp-server:
    build: .
    container_name: mcp-server
    environment:
      - ENVIRONMENT=production
      - DB_HOST=postgres
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./logs:/app/logs
      - ./config:/app/config
    restart: unless-stopped
  
  postgres:
    image: postgres:15
    container_name: mcp-postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=mcp_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
  
  redis:
    image: redis:7
    container_name: mcp-redis
    restart: unless-stopped

volumes:
  postgres_data:
```

#### è¿›ç¨‹ç®¡ç†

```ini
# supervisor.conf
[program:mcp-server]
command=python -m src.server
directory=/app
user=www-data
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/supervisor.log
environment=ENVIRONMENT="production"
```

### 7.4 å®Œæ•´ç”Ÿäº§çº§æ¡ˆä¾‹

#### å®Œæ•´çš„ç”Ÿäº§çº§ MCP Server

```python
# src/production_server.py
"""
å®Œæ•´çš„ç”Ÿäº§çº§ MCP Server ç¤ºä¾‹
åŒ…å«æ‰€æœ‰ç”Ÿäº§çº§ç‰¹æ€§
"""

import asyncio
import logging
from pathlib import Path
from mcp.server import Server
from typing import Optional

from .core.config import Settings
from .core.logging import ProductionLogger
from .core.auth import TokenAuth
from .core.cache import MultiLevelCache, TTLCache
from .core.database import DatabaseManager
from .core.metrics import Metrics
from .core.alerts import AlertManager

# åŠ è½½é…ç½®
config = Settings.load_from_file("config/production.json")

# åˆ›å»ºæœåŠ¡å™¨
app = Server(config.app_name)


@app.lifespan()
async def lifespan(ctx):
    """
    ç”Ÿå‘½å‘¨æœŸç®¡ç†
    åˆå§‹åŒ–æ‰€æœ‰ç”Ÿäº§çº§ç»„ä»¶
    """
    print("=" * 60)
    print(f"ğŸš€ {config.app_name} v{config.version} å¯åŠ¨ä¸­...")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger_system = ProductionLogger(
        name=config.app_name,
        log_dir=config.log_dir,
        level=getattr(logging, config.log_level)
    )
    logger = logger_system.get_logger()
    ctx.logger = logger
    logger.info("âœ… æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    # 2. åˆå§‹åŒ–æ•°æ®åº“
    try:
        db_manager = DatabaseManager(
            host=config.db_host,
            port=config.db_port,
            user=config.db_user,
            password=config.db_password,
            database=config.db_name
        )
        await db_manager.connect()
        ctx.db = db_manager
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼š{e}")
        raise
    
    # 3. åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
    try:
        l1_cache = TTLCache(default_ttl=config.cache_ttl)
        redis_client = await aioredis.create_redis_pool(config.redis_url)
        cache = MultiLevelCache(l1_cache, redis_client)
        ctx.cache = cache
        logger.info("âœ… ç¼“å­˜ç³»ç»Ÿå·²åˆå§‹åŒ–")
    except Exception as e:
        logger.warning(f"âš ï¸  Redis è¿æ¥å¤±è´¥ï¼Œä½¿ç”¨ä»…å†…å­˜ç¼“å­˜ï¼š{e}")
        ctx.cache = TTLCache(default_ttl=config.cache_ttl)
    
    # 4. åˆå§‹åŒ–è®¤è¯ç³»ç»Ÿ
    token_auth = TokenAuth(config.jwt_secret)
    ctx.token_auth = token_auth
    logger.info("âœ… è®¤è¯ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    # 5. åˆå§‹åŒ–ç›‘æ§æŒ‡æ ‡
    metrics = Metrics()
    ctx.metrics = metrics
    logger.info("âœ… ç›‘æ§ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    # 6. åˆå§‹åŒ–å‘Šè­¦ç³»ç»Ÿ
    alert_manager = AlertManager(logger)
    alert_manager.add_rule(AlertRule(
        name="é«˜é”™è¯¯ç‡",
        condition=lambda m: m.get_error_rate() > 0.1,
        level=AlertLevel.ERROR,
        message_template="é”™è¯¯ç‡ï¼š{error_rate:.2f}%"
    ))
    ctx.alert_manager = alert_manager
    logger.info("âœ… å‘Šè­¦ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    # 7. å¯åŠ¨åå°ä»»åŠ¡
    async def metrics_reporter():
        """å®šæœŸæŠ¥å‘ŠæŒ‡æ ‡"""
        while True:
            await asyncio.sleep(60)
            stats = metrics.get_summary()
            logger.info("ğŸ“Š æŒ‡æ ‡æŠ¥å‘Š", extra=stats)
    
    async def alert_checker():
        """å®šæœŸæ£€æŸ¥å‘Šè­¦"""
        while True:
            await asyncio.sleep(30)
            await alert_manager.check_all(metrics)
    
    metrics_task = asyncio.create_task(metrics_reporter())
    alert_task = asyncio.create_task(alert_checker())
    
    logger.info("=" * 60)
    logger.info(f"âœ… {config.app_name} å¯åŠ¨å®Œæˆ")
    logger.info(f"ğŸŒ ç¯å¢ƒï¼š{config.environment}")
    logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«ï¼š{config.log_level}")
    logger.info("=" * 60)
    
    # æœåŠ¡è¿è¡Œä¸­...
    yield
    
    # === å…³é—­é˜¶æ®µ ===
    logger.info("=" * 60)
    logger.info("ğŸ›‘ æœåŠ¡å…³é—­ä¸­...")
    
    # å–æ¶ˆåå°ä»»åŠ¡
    metrics_task.cancel()
    alert_task.cancel()
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    stats = metrics.get_summary()
    logger.info("ğŸ“Š æœ€ç»ˆç»Ÿè®¡", extra=stats)
    
    # å…³é—­è¿æ¥
    await db_manager.disconnect()
    if hasattr(ctx.cache, 'l2') and ctx.cache.l2:
        ctx.cache.l2.close()
        await ctx.cache.l2.wait_closed()
    
    logger.info("âœ… æœåŠ¡å·²å®‰å…¨å…³é—­")
    logger.info("=" * 60)


# æ³¨å†Œå·¥å…·ï¼ˆå¸¦å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—ï¼‰
@app.tool()
async def production_search(
    query: str,
    ctx,
    token: Optional[str] = None
):
    """
    ç”Ÿäº§çº§æœç´¢å·¥å…·
    åŒ…å«ï¼šè®¤è¯ã€ç¼“å­˜ã€æ—¥å¿—ã€ç›‘æ§ã€é”™è¯¯å¤„ç†
    """
    logger = ctx.request_context.lifespan_context.logger
    metrics = ctx.request_context.lifespan_context.metrics
    
    request_id = str(uuid.uuid4())
    start_time = time.time()
    
    try:
        # 1. è®¤è¯ï¼ˆå¦‚æœæä¾›äº† tokenï¼‰
        if token:
            token_auth = ctx.request_context.lifespan_context.token_auth
            user_info = token_auth.verify_token(token)
            if not user_info:
                metrics.record_request("production_search", 0, False)
                return {"error": "è®¤è¯å¤±è´¥"}
            user_id = user_info["user_id"]
        else:
            user_id = "anonymous"
        
        # 2. è¾“å…¥éªŒè¯
        if not query or len(query) > 1000:
            metrics.record_request("production_search", 0, False)
            return {"error": "æ— æ•ˆçš„æŸ¥è¯¢"}
        
        # 3. æ—¥å¿—è®°å½•
        logger.info(
            "æœç´¢è¯·æ±‚",
            extra={
                "request_id": request_id,
                "user_id": user_id,
                "query": query
            }
        )
        
        # 4. ç¼“å­˜æ£€æŸ¥
        cache = ctx.request_context.lifespan_context.cache
        cache_key = f"search:{query}"
        cached_result = await cache.get(cache_key)
        
        if cached_result:
            duration = time.time() - start_time
            metrics.record_request("production_search", duration, True)
            logger.info(
                "ç¼“å­˜å‘½ä¸­",
                extra={"request_id": request_id, "duration_ms": int(duration * 1000)}
            )
            return {
                "success": True,
                "cached": True,
                "result": cached_result,
                "request_id": request_id
            }
        
        # 5. æ‰§è¡Œæœç´¢
        result = await perform_search(query)
        
        # 6. ä¿å­˜åˆ°ç¼“å­˜
        await cache.set(cache_key, result)
        
        # 7. è®°å½•æˆåŠŸ
        duration = time.time() - start_time
        metrics.record_request("production_search", duration, True)
        logger.info(
            "æœç´¢å®Œæˆ",
            extra={
                "request_id": request_id,
                "result_count": len(result),
                "duration_ms": int(duration * 1000)
            }
        )
        
        return {
            "success": True,
            "cached": False,
            "result": result,
            "request_id": request_id
        }
        
    except Exception as e:
        # 8. é”™è¯¯å¤„ç†
        duration = time.time() - start_time
        metrics.record_request("production_search", duration, False)
        logger.error(
            "æœç´¢å¤±è´¥",
            exc_info=e,
            extra={"request_id": request_id, "query": query}
        )
        
        return {
            "success": False,
            "error": str(e),
            "request_id": request_id
        }


# å¥åº·æ£€æŸ¥å·¥å…·
@app.tool()
async def health_check(ctx):
    """å¥åº·æ£€æŸ¥"""
    metrics = ctx.request_context.lifespan_context.metrics
    
    return {
        "status": "healthy",
        "version": config.version,
        "environment": config.environment,
        "metrics": metrics.get_summary()
    }


if __name__ == "__main__":
    # è¿è¡ŒæœåŠ¡å™¨
    app.run(transport="stdio")
```

### 7.5 è¿ç»´æ£€æŸ¥æ¸…å•

#### éƒ¨ç½²å‰æ£€æŸ¥

```markdown
## éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

### ä»£ç è´¨é‡
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ï¼‰
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] ä»£ç å®¡æŸ¥å·²å®Œæˆ
- [ ] é™æ€ä»£ç åˆ†æé€šè¿‡ï¼ˆpylint, mypyï¼‰

### é…ç½®
- [ ] ç¯å¢ƒå˜é‡å·²æ­£ç¡®é…ç½®
- [ ] å¯†é’¥å·²æ›´æ–°ï¼ˆä¸ä½¿ç”¨é»˜è®¤å¯†é’¥ï¼‰
- [ ] æ•°æ®åº“è¿æ¥ä¿¡æ¯å·²éªŒè¯
- [ ] ç¬¬ä¸‰æ–¹ API å¯†é’¥å·²é…ç½®

### å®‰å…¨
- [ ] æ‰€æœ‰æ•æ„Ÿä¿¡æ¯å·²åŠ å¯†
- [ ] è®¤è¯ç³»ç»Ÿå·²å¯ç”¨
- [ ] é€Ÿç‡é™åˆ¶å·²é…ç½®
- [ ] è¾“å…¥éªŒè¯å·²å®æ–½
- [ ] HTTPS å·²å¯ç”¨ï¼ˆå¦‚é€‚ç”¨ï¼‰

### ç›‘æ§
- [ ] æ—¥å¿—ç³»ç»Ÿæ­£å¸¸å·¥ä½œ
- [ ] ç›‘æ§æŒ‡æ ‡æ­£åœ¨æ”¶é›†
- [ ] å‘Šè­¦è§„åˆ™å·²é…ç½®
- [ ] å‘Šè­¦é€šçŸ¥æ¸ é“å·²æµ‹è¯•

### æ€§èƒ½
- [ ] ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨
- [ ] æ•°æ®åº“è¿æ¥æ± å·²é…ç½®
- [ ] å‹åŠ›æµ‹è¯•å·²é€šè¿‡
- [ ] å“åº”æ—¶é—´ç¬¦åˆè¦æ±‚

### å¤‡ä»½
- [ ] æ•°æ®åº“å¤‡ä»½ç­–ç•¥å·²åˆ¶å®š
- [ ] é…ç½®æ–‡ä»¶å·²å¤‡ä»½
- [ ] å›æ»šæ–¹æ¡ˆå·²å‡†å¤‡

### æ–‡æ¡£
- [ ] README å·²æ›´æ–°
- [ ] API æ–‡æ¡£å·²å®Œå–„
- [ ] éƒ¨ç½²æ–‡æ¡£å·²ç¼–å†™
- [ ] æ•…éšœæ’é™¤æŒ‡å—å·²å‡†å¤‡
```

### 7.6 å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1ï¼šå†…å­˜æ³„æ¼

```python
# âŒ é—®é¢˜ä»£ç 
global_cache = {}  # æ— é™å¢é•¿

@app.tool()
async def cache_data(key: str, value: str, ctx):
    global_cache[key] = value  # æ°¸ä¸æ¸…ç†
    return {"success": True}

# âœ… è§£å†³æ–¹æ¡ˆ
from cachetools import TTLCache

cache = TTLCache(maxsize=1000, ttl=3600)  # æœ‰å¤§å°é™åˆ¶å’Œè¿‡æœŸæ—¶é—´

@app.tool()
async def cache_data(key: str, value: str, ctx):
    cache[key] = value
    return {"success": True}
```

#### é—®é¢˜2ï¼šæ•°æ®åº“è¿æ¥æ³„æ¼

```python
# âŒ é—®é¢˜ä»£ç 
@app.tool()
async def query_data(ctx):
    conn = await asyncpg.connect(...)  # æ¯æ¬¡åˆ›å»ºæ–°è¿æ¥
    result = await conn.fetchrow("SELECT ...")
    return result  # å¿˜è®°å…³é—­è¿æ¥

# âœ… è§£å†³æ–¹æ¡ˆ
@app.lifespan()
async def lifespan(ctx):
    # åˆ›å»ºè¿æ¥æ± 
    pool = await asyncpg.create_pool(...)
    ctx.db_pool = pool
    yield
    await pool.close()

@app.tool()
async def query_data(ctx):
    pool = ctx.request_context.lifespan_context.db_pool
    async with pool.acquire() as conn:
        result = await conn.fetchrow("SELECT ...")
        return result  # è¿æ¥è‡ªåŠ¨é‡Šæ”¾
```

### 7.7 å­¦ä¹ æ€»ç»“

#### æœ¬é˜¶æ®µçŸ¥è¯†åœ°å›¾

```
é˜¶æ®µ5ï¼šç”Ÿäº§çº§èƒ½åŠ›
â”‚
â”œâ”€ 1. ç”Ÿå‘½å‘¨æœŸç®¡ç† âœ…
â”‚  â”œâ”€ lifespan æœºåˆ¶
â”‚  â”œâ”€ èµ„æºåˆå§‹åŒ–
â”‚  â””â”€ ä¼˜é›…å…³é—­
â”‚
â”œâ”€ 2. çŠ¶æ€ç®¡ç† âœ…
â”‚  â”œâ”€ è¯·æ±‚çº§çŠ¶æ€
â”‚  â”œâ”€ ä¼šè¯çº§çŠ¶æ€
â”‚  â”œâ”€ åº”ç”¨çº§çŠ¶æ€
â”‚  â””â”€ æŒä¹…åŒ–çŠ¶æ€
â”‚
â”œâ”€ 3. ç¼“å­˜ä¸æ€§èƒ½ âœ…
â”‚  â”œâ”€ TTL/LRU ç¼“å­˜
â”‚  â”œâ”€ å¤šçº§ç¼“å­˜
â”‚  â”œâ”€ æ€§èƒ½ç›‘æ§
â”‚  â””â”€ ä¼˜åŒ–æŠ€å·§
â”‚
â”œâ”€ 4. æ—¥å¿—ä¸ç›‘æ§ âœ…
â”‚  â”œâ”€ ç»“æ„åŒ–æ—¥å¿—
â”‚  â”œâ”€ æ—¥å¿—çº§åˆ«
â”‚  â”œâ”€ ç›‘æ§æŒ‡æ ‡
â”‚  â””â”€ å‘Šè­¦ç³»ç»Ÿ
â”‚
â”œâ”€ 5. å®‰å…¨æ€§ âœ…
â”‚  â”œâ”€ è®¤è¯æˆæƒ
â”‚  â”œâ”€ æ•°æ®åŠ å¯†
â”‚  â”œâ”€ è¾“å…¥éªŒè¯
â”‚  â””â”€ å®‰å…¨å®¡è®¡
â”‚
â”œâ”€ 6. æµ‹è¯•è°ƒè¯• âœ…
â”‚  â”œâ”€ å•å…ƒæµ‹è¯•
â”‚  â”œâ”€ é›†æˆæµ‹è¯•
â”‚  â”œâ”€ å‹åŠ›æµ‹è¯•
â”‚  â””â”€ è°ƒè¯•æŠ€å·§
â”‚
â””â”€ 7. æœ€ä½³å®è·µ âœ…
   â”œâ”€ é¡¹ç›®ç»“æ„
   â”œâ”€ é…ç½®ç®¡ç†
   â”œâ”€ éƒ¨ç½²ç­–ç•¥
   â””â”€ è¿ç»´è§„èŒƒ
```

#### æ ¸å¿ƒè¦ç‚¹å›é¡¾

1. **ç”Ÿå‘½å‘¨æœŸæ˜¯åŸºç¡€**
   - ä½¿ç”¨ lifespan ç®¡ç†èµ„æº
   - é¿å…èµ„æºæ³„æ¼
   - ä¼˜é›…å¯åŠ¨å’Œå…³é—­

2. **çŠ¶æ€è¦åˆ†å±‚**
   - è¯·æ±‚çº§ï¼šä¸´æ—¶æ•°æ®
   - ä¼šè¯çº§ï¼šç”¨æˆ·ç›¸å…³
   - åº”ç”¨çº§ï¼šå…¨å±€å…±äº«
   - æŒä¹…åŒ–ï¼šé‡å¯ä¿ç•™

3. **ç¼“å­˜ææ€§èƒ½**
   - åˆç†è®¾ç½® TTL
   - å¤šçº§ç¼“å­˜æ¶æ„
   - æ™ºèƒ½å¤±æ•ˆç­–ç•¥

4. **æ—¥å¿—åŠ©æ’æŸ¥**
   - ç»“æ„åŒ–è¾“å‡º
   - åˆç†åˆ†çº§
   - å®šæœŸåˆ†æ

5. **å®‰å…¨æ˜¯åº•çº¿**
   - è®¤è¯å¿…é¡»æœ‰
   - æ•°æ®è¦åŠ å¯†
   - è¾“å…¥è¦éªŒè¯
   - æ“ä½œè¦å®¡è®¡

6. **æµ‹è¯•ä¿è´¨é‡**
   - å•å…ƒæµ‹è¯•ä¸ºä¸»
   - é›†æˆæµ‹è¯•ä¸ºè¾…
   - æŒç»­é›†æˆè‡ªåŠ¨åŒ–

7. **è¿ç»´è¦è§„èŒƒ**
   - æ–‡æ¡£è¦å®Œå–„
   - ç›‘æ§è¦åˆ°ä½
   - å‘Šè­¦è¦åŠæ—¶
   - å¤‡ä»½è¦åšå¥½

### 7.8 ä¸‹ä¸€æ­¥å»ºè®®

æ­å–œå®Œæˆé˜¶æ®µ5ï¼ä½ ç°åœ¨å·²ç»æŒæ¡äº†å¼€å‘ç”Ÿäº§çº§ MCP Server çš„æ‰€æœ‰æ ¸å¿ƒæŠ€èƒ½ã€‚

#### ğŸ¯ ç»§ç»­æ·±å…¥

1. **å®æˆ˜é¡¹ç›®**
   - å¼€å‘å®Œæ•´çš„ç”Ÿäº§çº§ MCP Server
   - é›†æˆåˆ°å®é™…ä¸šåŠ¡ç³»ç»Ÿ
   - ä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ

2. **è¿›é˜¶ä¸»é¢˜**
   - åˆ†å¸ƒå¼ MCP æ¶æ„
   - å¾®æœåŠ¡é›†æˆ
   - é«˜å¯ç”¨éƒ¨ç½²
   - è·¨è¯­è¨€å®ç°

3. **ç¤¾åŒºè´¡çŒ®**
   - åˆ†äº«ä½ çš„ç»éªŒ
   - è´¡çŒ®å¼€æºé¡¹ç›®
   - ç¼–å†™æŠ€æœ¯æ–‡ç« 
   - å¸®åŠ©ä»–äººå­¦ä¹ 

#### ğŸ“š æ¨èèµ„æº

**å®˜æ–¹æ–‡æ¡£**
- MCP è§„èŒƒï¼šhttps://modelcontextprotocol.io/specification
- Python SDKï¼šhttps://github.com/modelcontextprotocol/python-sdk
- TypeScript SDKï¼šhttps://github.com/modelcontextprotocol/typescript-sdk

**å­¦ä¹ èµ„æº**
- FastAPI æ–‡æ¡£ï¼šhttps://fastapi.tiangolo.com
- asyncio æ•™ç¨‹ï¼šhttps://docs.python.org/3/library/asyncio.html
- pytest æ–‡æ¡£ï¼šhttps://docs.pytest.org

**æœ€ä½³å®è·µ**
- 12-Factor Appï¼šhttps://12factor.net
- OWASP å®‰å…¨æŒ‡å—ï¼šhttps://owasp.org
- Google SRE ä¹¦ç±ï¼šhttps://sre.google

---

## ğŸ‰ é˜¶æ®µ5å®Œæˆï¼

ä½ å·²ç»å®Œæˆäº† MCP ç”Ÿäº§çº§èƒ½åŠ›çš„ç³»ç»Ÿå­¦ä¹ ã€‚ç°åœ¨ä½ å…·å¤‡äº†ï¼š

âœ… **è®¾è®¡èƒ½åŠ›**ï¼šç†è§£ç”Ÿäº§ç³»ç»Ÿæ¶æ„  
âœ… **å¼€å‘èƒ½åŠ›**ï¼šç¼–å†™é«˜è´¨é‡ä»£ç   
âœ… **è¿ç»´èƒ½åŠ›**ï¼šéƒ¨ç½²å’Œç»´æŠ¤æœåŠ¡  
âœ… **é—®é¢˜è§£å†³**ï¼šå¿«é€Ÿå®šä½å’Œä¿®å¤é—®é¢˜  
âœ… **æœ€ä½³å®è·µ**ï¼šéµå¾ªè¡Œä¸šæ ‡å‡†  

### ğŸš€ ä½ çš„ MCP ä¹‹æ—…

```
é˜¶æ®µ0: å‰ç½®çŸ¥è¯†å‡†å¤‡ âœ…
  â””â”€ Python/TypeScript åŸºç¡€
  
é˜¶æ®µ1: MCP æ ¸å¿ƒæ¦‚å¿µ âœ…
  â””â”€ åè®®ç†è§£
  
é˜¶æ®µ2: åè®®è§„èŒƒè¯¦è§£ âœ…
  â””â”€ JSON-RPC æ¶ˆæ¯
  
é˜¶æ®µ3: Server å¼€å‘å®æˆ˜ âœ…
  â””â”€ Tools/Resources/Prompts
  
é˜¶æ®µ4: Client/Host é›†æˆ âœ…
  â””â”€ å®¢æˆ·ç«¯å¼€å‘
  
é˜¶æ®µ5: ç”Ÿäº§çº§èƒ½åŠ› âœ… â† ä½ åœ¨è¿™é‡Œï¼
  â””â”€ ä¼ä¸šçº§å®è·µ
  
ä¸‹ä¸€æ­¥ï¼šå®æˆ˜é¡¹ç›® ğŸ¯
  â””â”€ å°†æ‰€å­¦åº”ç”¨åˆ°å®é™…é¡¹ç›®
```

### ğŸ’ª ç»§ç»­å‰è¿›

è®°ä½ï¼š**å­¦ä¹ æ°¸æ— æ­¢å¢ƒï¼Œå®è·µå‡ºçœŸçŸ¥**

- åŠ¨æ‰‹å®è·µæ¯”ç†è®ºå­¦ä¹ æ›´é‡è¦
- é‡åˆ°é—®é¢˜æ˜¯æˆé•¿çš„æœºä¼š
- åˆ†äº«çŸ¥è¯†èƒ½åŠ æ·±ç†è§£
- æŒç»­æ”¹è¿›æ˜¯ä¸“ä¸šæ€åº¦

**ç¥ä½ åœ¨ MCP å¼€å‘çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œï¼ğŸš€**

---

> æœ¬æ–‡æ¡£æœ€åæ›´æ–°ï¼š2025å¹´11æœˆ
> 
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆï¼
> 
> **æ„Ÿè°¢ä½ çš„å­¦ä¹ ï¼ŒæœŸå¾…çœ‹åˆ°ä½ å¼€å‘çš„ä¼˜ç§€ MCP Serverï¼**
