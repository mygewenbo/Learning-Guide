# LangChain å…¨é¢å­¦ä¹ è®¡åˆ’

> åŸºäº LangChain æœ€æ–°ç‰ˆæœ¬æ•´ç† | æ›´æ–°æ—¶é—´ï¼š2025å¹´1æœˆ

## ğŸ“š ç›®å½•
1. [LangChain æ¦‚è¿°](#1-langchain-æ¦‚è¿°)
2. [æ ¸å¿ƒæ¶æ„](#2-æ ¸å¿ƒæ¶æ„)
3. [æ¨¡å‹é›†æˆ (Models)](#3-æ¨¡å‹é›†æˆ-models)
4. [Agents ä»£ç†ç³»ç»Ÿ](#4-agents-ä»£ç†ç³»ç»Ÿ)
5. [LangGraph çŠ¶æ€å·¥ä½œæµ](#5-langgraph-çŠ¶æ€å·¥ä½œæµ)
6. [Memory è®°å¿†ç³»ç»Ÿ](#6-memory-è®°å¿†ç³»ç»Ÿ)
7. [Tools å·¥å…·ç³»ç»Ÿ](#7-tools-å·¥å…·ç³»ç»Ÿ)
8. [RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ](#8-rag-æ£€ç´¢å¢å¼ºç”Ÿæˆ)
9. [Streaming æµå¼å¤„ç†](#9-streaming-æµå¼å¤„ç†)
10. [Middleware ä¸­é—´ä»¶ç³»ç»Ÿ](#10-middleware-ä¸­é—´ä»¶ç³»ç»Ÿ)
11. [Structured Output ç»“æ„åŒ–è¾“å‡º](#11-structured-output-ç»“æ„åŒ–è¾“å‡º)
12. [Prompt Engineering æç¤ºå·¥ç¨‹](#12-prompt-engineering-æç¤ºå·¥ç¨‹)
13. [Observability å¯è§‚æµ‹æ€§](#13-observability-å¯è§‚æµ‹æ€§)
14. [éƒ¨ç½²ä¸ç”Ÿäº§](#14-éƒ¨ç½²ä¸ç”Ÿäº§)
15. [æœ€ä½³å®è·µ](#15-æœ€ä½³å®è·µ)

---

## 1. LangChain æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ
LangChain æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒç®€åŒ–äº† LLM åº”ç”¨ç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼Œæä¾›å¼€æºç»„ä»¶å’Œç¬¬ä¸‰æ–¹é›†æˆã€‚

### 1.2 æ ¸å¿ƒç‰¹æ€§
- **ç»„ä»¶åŒ–è®¾è®¡**ï¼šæ¨¡å—åŒ–çš„æ„å»ºå—ï¼Œå¯çµæ´»ç»„åˆ
- **é“¾å¼è°ƒç”¨**ï¼šå°†å¤šä¸ªç»„ä»¶ä¸²è”æˆå¤æ‚çš„å·¥ä½œæµ
- **Agent ç³»ç»Ÿ**ï¼šæ™ºèƒ½ä»£ç†å¯è‡ªä¸»å†³ç­–å’Œä½¿ç”¨å·¥å…·
- **è®°å¿†ç®¡ç†**ï¼šçŸ­æœŸå’Œé•¿æœŸè®°å¿†ç³»ç»Ÿ
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šç»Ÿä¸€æ¥å£æ”¯æŒå„ç§ LLM æä¾›å•†
- **å¯è§‚æµ‹æ€§**ï¼šå†…ç½®çš„è¿½è¸ªå’Œç›‘æ§èƒ½åŠ›

### 1.3 åº”ç”¨åœºæ™¯
- **é—®ç­”ç³»ç»Ÿ**ï¼šåŸºäºæ–‡æ¡£çš„æ™ºèƒ½é—®ç­”
- **èŠå¤©æœºå™¨äºº**ï¼šå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ç†è§£
- **æ–‡æ¡£åˆ†æ**ï¼šè‡ªåŠ¨æ‘˜è¦ã€åˆ†ç±»å’Œä¿¡æ¯æå–
- **ä»£ç åŠ©æ‰‹**ï¼šä»£ç ç”Ÿæˆã€è§£é‡Šå’Œè°ƒè¯•
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šè‡ªç„¶è¯­è¨€è½¬ SQL
- **å·¥ä½œæµè‡ªåŠ¨åŒ–**ï¼šå¤šæ­¥éª¤ä»»åŠ¡ç¼–æ’
- **çŸ¥è¯†ç®¡ç†**ï¼šRAG ç³»ç»Ÿå’ŒçŸ¥è¯†åº“

### 1.4 å®‰è£…

```bash
# æ ¸å¿ƒåº“
pip install langchain langchain-core

# ç¤¾åŒºé›†æˆ
pip install langchain-community

# ç‰¹å®šæ¨¡å‹æä¾›å•†
pip install langchain-openai      # OpenAI
pip install langchain-anthropic   # Anthropic
pip install langchain-google      # Google

# æ–‡æœ¬åˆ†å‰²å’Œå¤„ç†
pip install langchain-text-splitters

# LangGraphï¼ˆçŠ¶æ€å·¥ä½œæµï¼‰
pip install langgraph

# LangSmithï¼ˆç›‘æ§å’Œè¿½è¸ªï¼‰
pip install langsmith
```

---

## 2. æ ¸å¿ƒæ¶æ„

### 2.1 æ•´ä½“æ¶æ„å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         åº”ç”¨å±‚ (Applications)                â”‚
â”‚   èŠå¤©æœºå™¨äººã€é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨åŒ–å·¥å…·ç­‰            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LangGraph (çŠ¶æ€å·¥ä½œæµç¼–æ’)               â”‚
â”‚   StateGraphã€æ¡ä»¶è·¯ç”±ã€å¹¶è¡Œæ‰§è¡Œ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       LangChain Agents (ä»£ç†å±‚)              â”‚
â”‚   create_agentã€å·¥å…·è°ƒç”¨ã€å†³ç­–é€»è¾‘             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       æ ¸å¿ƒç»„ä»¶å±‚ (Core Components)            â”‚
â”‚  Models | Prompts | Tools | Memory           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      åŸºç¡€è®¾æ–½å±‚ (Infrastructure)              â”‚
â”‚  LangSmithç›‘æ§ | å‘é‡å­˜å‚¨ | æ£€æŸ¥ç‚¹             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒæ¦‚å¿µ

#### 2.2.1 Runnable æ¥å£
æ‰€æœ‰ LangChain ç»„ä»¶éƒ½å®ç° `Runnable` æ¥å£ï¼Œæä¾›ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼ï¼š

```python
# æ‰€æœ‰ç»„ä»¶éƒ½æ”¯æŒè¿™äº›æ–¹æ³•
result = component.invoke(input)           # å•æ¬¡åŒæ­¥è°ƒç”¨
results = component.batch([input1, input2]) # æ‰¹é‡å¤„ç†
for chunk in component.stream(input):      # æµå¼è¾“å‡º
    print(chunk)
```

**Runnable çš„æ ¸å¿ƒæ–¹æ³•**ï¼š
- `invoke()`: å•æ¬¡è°ƒç”¨ï¼Œè¿”å›å®Œæ•´ç»“æœ
- `batch()`: æ‰¹é‡å¤„ç†å¤šä¸ªè¾“å…¥
- `stream()`: æµå¼è¾“å‡ºï¼Œé€æ­¥è¿”å›ç»“æœ
- `batch_as_completed()`: å¼‚æ­¥æ‰¹å¤„ç†ï¼ŒæŒ‰å®Œæˆé¡ºåºè¿”å›

#### 2.2.2 LCEL (LangChain Expression Language)
ä½¿ç”¨ `|` æ“ä½œç¬¦é“¾æ¥ç»„ä»¶ï¼Œåˆ›å»ºå¤„ç†æµæ°´çº¿ï¼š

```python
chain = prompt | model | output_parser
result = chain.invoke({"input": "ç”¨æˆ·è¾“å…¥"})
```

### 2.3 ä¸»è¦ç»„ä»¶

| ç»„ä»¶ | åŠŸèƒ½ | ç¤ºä¾‹ |
|-----|------|------|
| **Models** | LLM å’Œ Chat æ¨¡å‹ | ChatOpenAI, ChatAnthropic |
| **Prompts** | æç¤ºæ¨¡æ¿ | PromptTemplate, ChatPromptTemplate |
| **Output Parsers** | è¾“å‡ºè§£æ | StrOutputParser, JsonOutputParser |
| **Retrievers** | æ–‡æ¡£æ£€ç´¢ | VectorStoreRetriever |
| **Tools** | å¤–éƒ¨å·¥å…· | @tool è£…é¥°å™¨ |
| **Agents** | æ™ºèƒ½ä»£ç† | create_agent() |
| **Memory** | è®°å¿†ç³»ç»Ÿ | Checkpointer, Store |

---

## 3. æ¨¡å‹é›†æˆ (Models)

### 3.1 åˆå§‹åŒ–æ¨¡å‹

#### æ–¹å¼ 1ï¼šå­—ç¬¦ä¸²æ ‡è¯†ç¬¦ï¼ˆè‡ªåŠ¨æ¨æ–­æä¾›å•†ï¼‰
```python
from langchain.agents import create_agent

agent = create_agent(
    "gpt-4o",  # è‡ªåŠ¨è¯†åˆ«ä¸º OpenAI æ¨¡å‹
    tools=tools
)
```

#### æ–¹å¼ 2ï¼šæ˜¾å¼å®ä¾‹åŒ–
```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    model="gpt-4o",
    temperature=0.7,
    max_tokens=2000,
    timeout=30
)
```

#### æ–¹å¼ 3ï¼šç»Ÿä¸€åˆå§‹åŒ–æ¥å£
```python
from langchain.chat_models import init_chat_model

model = init_chat_model(
    model="gpt-4o-mini",
    model_provider="openai",
    temperature=0.5
)
```

### 3.2 æ¨¡å‹è°ƒç”¨

#### åŸºæœ¬è°ƒç”¨
```python
# æ–‡æœ¬å­—ç¬¦ä¸²
response = model.invoke("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„ä¿³å¥")

# æ¶ˆæ¯åˆ—è¡¨
from langchain_core.messages import HumanMessage, SystemMessage

response = model.invoke([
    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    HumanMessage(content="è§£é‡Šé‡å­è®¡ç®—")
])
```

#### æ‰¹é‡å¤„ç†
```python
# åŒæ­¥æ‰¹å¤„ç†
responses = model.batch([
    "ä¸ºä»€ä¹ˆé¹¦é¹‰æœ‰å½©è‰²ç¾½æ¯›ï¼Ÿ",
    "é£æœºå¦‚ä½•é£è¡Œï¼Ÿ",
    "ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—ï¼Ÿ"
])

# å¼‚æ­¥æ‰¹å¤„ç†ï¼ˆæŒ‰å®Œæˆé¡ºåºï¼‰
for response in model.batch_as_completed([...]):
    print(response)
```

### 3.3 å·¥å…·ç»‘å®š

```python
from langchain.tools import tool

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯"""
    return f"{location}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œ22Â°C"

# å°†å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
model_with_tools = model.bind_tools([get_weather])

# æ¨¡å‹å¯ä»¥å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
response = model_with_tools.invoke("çº½çº¦çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
print(response.tool_calls)  # æŸ¥çœ‹å·¥å…·è°ƒç”¨
```

### 3.4 æµå¼è¾“å‡º

```python
# æµå¼è·å– token
for chunk in model.stream("è®²ä¸€ä¸ªé•¿æ•…äº‹"):
    print(chunk.content, end="", flush=True)

# æµå¼å·¥å…·è°ƒç”¨
for chunk in model_with_tools.stream("æ³¢å£«é¡¿å’Œä¸œäº¬çš„å¤©æ°”ï¼Ÿ"):
    for tool_chunk in chunk.tool_call_chunks:
        if name := tool_chunk.get("name"):
            print(f"å·¥å…·: {name}")
        if args := tool_chunk.get("args"):
            print(f"å‚æ•°: {args}")
```

### 3.5 Token ä½¿ç”¨è¿½è¸ª

```python
from langchain_core.callbacks import get_usage_metadata_callback

model_1 = init_chat_model("gpt-4o-mini")
model_2 = init_chat_model("claude-haiku-4-5-20251001")

with get_usage_metadata_callback() as cb:
    model_1.invoke("ä½ å¥½")
    model_2.invoke("ä½ å¥½")
    
    # æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹çš„ token ä½¿ç”¨æƒ…å†µ
    print(cb.usage_metadata)
    # {
    #   "gpt-4o-mini": {"input_tokens": 8, "output_tokens": 10, ...},
    #   "claude-haiku": {"input_tokens": 8, "output_tokens": 21, ...}
    # }
```

---

## 4. Agents ä»£ç†ç³»ç»Ÿ

### 4.1 ä»€ä¹ˆæ˜¯ Agentï¼Ÿ

Agent æ˜¯èƒ½å¤Ÿä½¿ç”¨å·¥å…·ã€åšå‡ºå†³ç­–å¹¶æ‰§è¡Œå¤šæ­¥éª¤ä»»åŠ¡çš„æ™ºèƒ½ç³»ç»Ÿã€‚

**Agent çš„æ ¸å¿ƒèƒ½åŠ›**ï¼š
- ğŸ¤” **æ¨ç†**ï¼šç†è§£ç”¨æˆ·æ„å›¾å’Œä»»åŠ¡éœ€æ±‚
- ğŸ”§ **å·¥å…·ä½¿ç”¨**ï¼šé€‰æ‹©å’Œè°ƒç”¨åˆé€‚çš„å·¥å…·
- ğŸ”„ **è¿­ä»£æ‰§è¡Œ**ï¼šæ ¹æ®ç»“æœè°ƒæ•´ç­–ç•¥
- ğŸ’¬ **å¯¹è¯ç®¡ç†**ï¼šç»´æŠ¤ä¸Šä¸‹æ–‡å’Œå¤šè½®äº¤äº’
- ğŸ“Š **ç»“æœç»¼åˆ**ï¼šæ•´åˆå¤šæ­¥éª¤ç»“æœ

### 4.2 åˆ›å»ºåŸºç¡€ Agent

```python
from langchain.agents import create_agent
from langchain.tools import tool

@tool
def search(query: str) -> str:
    """æœç´¢ä¿¡æ¯"""
    return f"æœç´¢ç»“æœï¼š{query}"

@tool
def get_weather(location: str) -> str:
    """è·å–å¤©æ°”ä¿¡æ¯"""
    return f"{location}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œ72Â°F"

# åˆ›å»º Agent
agent = create_agent(
    model="gpt-4o",
    tools=[search, get_weather],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œå¯ä»¥æœç´¢ä¿¡æ¯å’ŒæŸ¥è¯¢å¤©æ°”"
)

# è°ƒç”¨ Agent
result = agent.invoke({
    "messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”å¦‚ä½•ï¼Ÿ"}]
})

print(result["messages"][-1].content)
```

### 4.3 ReACT å·¥ä½œæ¨¡å¼

Agent éµå¾ª **Reasoningï¼ˆæ¨ç†ï¼‰â†’ Actionï¼ˆè¡ŒåŠ¨ï¼‰â†’ Observationï¼ˆè§‚å¯Ÿï¼‰** å¾ªç¯ï¼š

```
ç”¨æˆ·è¾“å…¥: "æœç´¢æ— çº¿è€³æœºå¹¶æ£€æŸ¥åº“å­˜"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨ç†: æˆ‘éœ€è¦å…ˆæœç´¢äº§å“              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¡ŒåŠ¨: search_products("æ— çº¿è€³æœº")   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è§‚å¯Ÿ: "æ‰¾åˆ° Sony WH-1000XM5"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨ç†: ç°åœ¨æ£€æŸ¥è¿™ä¸ªäº§å“çš„åº“å­˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¡ŒåŠ¨: check_inventory("WH-1000XM5") â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è§‚å¯Ÿ: "åº“å­˜ 10 ä»¶"                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æœ€ç»ˆå›ç­”: "æ‰¾åˆ° Sony WH-1000XM5ï¼Œ    â”‚
â”‚           å½“å‰åº“å­˜ 10 ä»¶"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.4 Context ä¸Šä¸‹æ–‡ç³»ç»Ÿ

ä½¿ç”¨ Context ä¼ é€’è¿è¡Œæ—¶ä¿¡æ¯ï¼š

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

@dataclass
class Context:
    user_id: str
    user_location: str

@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """è·å–ç”¨æˆ·ä½ç½®"""
    return runtime.context.user_location

agent = create_agent(
    model="gpt-4o",
    tools=[get_user_location],
    context_schema=Context
)

# è°ƒç”¨æ—¶ä¼ é€’ Context
result = agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘åœ¨å“ªé‡Œï¼Ÿ"}]},
    context=Context(user_id="user_123", user_location="æ—§é‡‘å±±")
)
```

---

## 5. LangGraph çŠ¶æ€å·¥ä½œæµ

### 5.1 ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ

**LangGraph** æ˜¯ä¸€ä¸ªä½çº§ç¼–æ’æ¡†æ¶ï¼Œç”¨äºæ„å»ºã€ç®¡ç†å’Œéƒ¨ç½²é•¿æœŸè¿è¡Œçš„æœ‰çŠ¶æ€ Agent å’Œå·¥ä½œæµã€‚

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- ğŸ”„ **æŒä¹…åŒ–æ‰§è¡Œ**ï¼šçŠ¶æ€ä¿å­˜å’Œæ¢å¤
- ğŸ‘¤ **äººæœºäº¤äº’**ï¼šäººå·¥å®¡æ ¸å’Œå¹²é¢„
- ğŸ§  **å…¨é¢è®°å¿†**ï¼šè·¨ä¼šè¯çš„çŠ¶æ€ç®¡ç†
- ğŸš€ **ç”Ÿäº§å°±ç»ª**ï¼šå¯æ‰©å±•çš„éƒ¨ç½²èƒ½åŠ›

### 5.2 æ ¸å¿ƒæ¦‚å¿µ

#### Stateï¼ˆçŠ¶æ€ï¼‰
```python
from typing_extensions import TypedDict
from typing import Annotated
import operator

class State(TypedDict):
    messages: Annotated[list, operator.add]  # ç´¯åŠ æ¶ˆæ¯
    topic: str
    output: str
```

#### Nodeï¼ˆèŠ‚ç‚¹ï¼‰
```python
def generate_joke(state: State):
    """ç”Ÿæˆç¬‘è¯"""
    msg = llm.invoke(f"å†™ä¸€ä¸ªå…³äº{state['topic']}çš„ç¬‘è¯")
    return {"joke": msg.content}
```

#### Edgeï¼ˆè¾¹ï¼‰
- **æ™®é€šè¾¹**ï¼šå›ºå®šçš„èŠ‚ç‚¹è½¬æ¢
- **æ¡ä»¶è¾¹**ï¼šåŸºäºçŠ¶æ€çš„åŠ¨æ€è·¯ç”±

### 5.3 ç®€å•é“¾å¼å·¥ä½œæµ

```python
from langgraph.graph import StateGraph, START, END

class State(TypedDict):
    topic: str
    joke: str
    improved_joke: str

# åˆ›å»º Graph
workflow = StateGraph(State)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("generate_joke", generate_joke)
workflow.add_node("improve_joke", improve_joke)
workflow.add_node("polish_joke", polish_joke)

# æ·»åŠ è¾¹
workflow.add_edge(START, "generate_joke")
workflow.add_edge("generate_joke", "improve_joke")
workflow.add_edge("improve_joke", "polish_joke")
workflow.add_edge("polish_joke", END)

# ç¼–è¯‘å¹¶æ‰§è¡Œ
chain = workflow.compile()
result = chain.invoke({"topic": "çŒ«"})
```

### 5.4 å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ

```python
# å¹¶è¡Œæ‰§è¡Œå¤šä¸ª LLM è°ƒç”¨
async def call_llm1(state: State):
    msg = await llm.invoke(f"å†™ä¸€ä¸ªå…³äº{state['topic']}çš„ç¬‘è¯")
    return {"joke": msg.content}

async def call_llm2(state: State):
    msg = await llm.invoke(f"å†™ä¸€ä¸ªå…³äº{state['topic']}çš„æ•…äº‹")
    return {"story": msg.content}

# æ„å»ºå¹¶è¡Œå·¥ä½œæµ
parallel_workflow = StateGraph(State)
parallel_workflow.add_node("llm1", call_llm1)
parallel_workflow.add_node("llm2", call_llm2)
parallel_workflow.add_node("aggregator", aggregator)

# å¹¶è¡Œå¯åŠ¨
parallel_workflow.add_edge(START, "llm1")
parallel_workflow.add_edge(START, "llm2")

# æ±‡èšåˆ°èšåˆå™¨
parallel_workflow.add_edge("llm1", "aggregator")
parallel_workflow.add_edge("llm2", "aggregator")
parallel_workflow.add_edge("aggregator", END)
```

---

## 6. Memory è®°å¿†ç³»ç»Ÿ

### 6.1 çŸ­æœŸè®°å¿†ï¼ˆå¯¹è¯å†å²ï¼‰

ä½¿ç”¨ **Checkpointer** ç®¡ç†ä¼šè¯çŠ¶æ€ï¼š

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

agent = create_agent(
    "gpt-4o",
    tools=[],
    checkpointer=InMemorySaver()
)

# ç¬¬ä¸€è½®å¯¹è¯
agent.invoke(
    {"messages": [{"role": "user", "content": "ä½ å¥½ï¼æˆ‘å« Bobã€‚"}]},
    {"configurable": {"thread_id": "1"}}
)

# ç¬¬äºŒè½®å¯¹è¯ï¼ˆè®°ä½ä¸Šä¸‹æ–‡ï¼‰
agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}]},
    {"configurable": {"thread_id": "1"}}
)
# è¾“å‡º: "ä½ çš„åå­—æ˜¯ Bob"
```

### 6.2 é•¿æœŸè®°å¿†ï¼ˆè·¨ä¼šè¯å­˜å‚¨ï¼‰

ä½¿ç”¨ **Store** æŒä¹…åŒ–æ•°æ®ï¼š

```python
from langgraph.store.memory import InMemoryStore
from langchain.tools import tool, ToolRuntime
from dataclasses import dataclass

@dataclass
class Context:
    user_id: str

store = InMemoryStore()

# å­˜å‚¨ç”¨æˆ·ä¿¡æ¯
store.put(
    ("users",),
    "user_123",
    {"name": "John Smith", "language": "English"}
)

@tool
def get_user_info(runtime: ToolRuntime[Context]) -> str:
    """æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯"""
    user_id = runtime.context.user_id
    user_info = runtime.store.get(("users",), user_id)
    return str(user_info.value) if user_info else "æœªçŸ¥ç”¨æˆ·"

agent = create_agent(
    model="gpt-4o",
    tools=[get_user_info],
    store=store,
    context_schema=Context
)
```

### 6.3 è®°å¿†ç³»ç»Ÿå¯¹æ¯”

| è®°å¿†ç±»å‹ | å®ç°æ–¹å¼ | ç”Ÿå‘½å‘¨æœŸ | ä½¿ç”¨åœºæ™¯ |
|---------|---------|---------|---------|
| **çŸ­æœŸè®°å¿†** | Checkpointer | å•ä¸ªä¼šè¯ | å¯¹è¯å†å²ã€ä¸Šä¸‹æ–‡è¿è´¯æ€§ |
| **é•¿æœŸè®°å¿†** | Store | è·¨ä¼šè¯æŒä¹…åŒ– | ç”¨æˆ·åå¥½ã€çŸ¥è¯†ç§¯ç´¯ |
| **å·¥ä½œè®°å¿†** | State | å•æ¬¡æ‰§è¡Œ | ä¸­é—´ç»“æœã€ä¸´æ—¶æ•°æ® |

---

## 7. Tools å·¥å…·ç³»ç»Ÿ

### 7.1 å®šä¹‰å·¥å…·

#### åŸºç¡€å·¥å…·
```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """æœç´¢å®¢æˆ·æ•°æ®åº“ä¸­åŒ¹é…æŸ¥è¯¢çš„è®°å½•ã€‚
    
    Args:
        query: è¦æŸ¥æ‰¾çš„æœç´¢è¯
        limit: è¿”å›çš„æœ€å¤§ç»“æœæ•°
    """
    return f"æ‰¾åˆ° {limit} æ¡å…³äº '{query}' çš„ç»“æœ"
```

#### å¤æ‚è¾“å…¥æ¨¡å¼ï¼ˆPydanticï¼‰
```python
from pydantic import BaseModel, Field
from typing import Literal

class WeatherInput(BaseModel):
    location: str = Field(description="åŸå¸‚åç§°æˆ–åæ ‡")
    units: Literal["celsius", "fahrenheit"] = Field(default="celsius")
    include_forecast: bool = Field(default=False)

@tool(args_schema=WeatherInput)
def get_weather(location: str, units: str = "celsius", 
                include_forecast: bool = False) -> str:
    """è·å–å¤©æ°”ä¿¡æ¯"""
    temp = 22 if units == "celsius" else 72
    result = f"{location}å½“å‰æ¸©åº¦ï¼š{temp}Â°{units[0].upper()}"
    if include_forecast:
        result += "\næœªæ¥5å¤©ï¼šæ™´å¤©"
    return result
```

### 7.2 å·¥å…·ä¸­çš„è¿è¡Œæ—¶ä¿¡æ¯

```python
@tool
def get_weather(city: str, runtime: ToolRuntime) -> str:
    """è·å–å¤©æ°”ä¿¡æ¯"""
    writer = runtime.stream_writer
    
    # æµå¼è¾“å‡ºè¿›åº¦
    writer(f"æ­£åœ¨æŸ¥è¯¢åŸå¸‚ï¼š{city}")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    
    return f"{city}æ°¸è¿œæ˜¯æ™´å¤©ï¼"
```

---

## 8. RAG æ£€ç´¢å¢å¼ºç”Ÿæˆ

### 8.1 ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

**RAG (Retrieval-Augmented Generation)** é€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼º LLM çš„å“åº”èƒ½åŠ›ã€‚

**æ ¸å¿ƒæµç¨‹**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ å‘é‡æ£€ç´¢ â†’ ç›¸å…³æ–‡æ¡£ â†’ æ³¨å…¥ä¸Šä¸‹æ–‡ â†’ LLM ç”Ÿæˆå›ç­”
```

### 8.2 åŸºç¡€ RAG å®ç°

```python
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 1. åŠ è½½æ–‡æ¡£
loader = WebBaseLoader("https://example.com/blog")
docs = loader.load()

# 2. åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
splits = text_splitter.split_documents(docs)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = InMemoryVectorStore.from_documents(
    documents=splits,
    embedding=embeddings
)

# 4. åˆ›å»ºæ£€ç´¢å™¨
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)
```

### 8.3 RAG Agent

```python
from langchain.tools import tool

@tool(response_format="content_and_artifact")
def retrieve_context(query: str):
    """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
    retrieved_docs = vector_store.similarity_search(query, k=2)
    serialized = "\n\n".join(
        f"æ¥æº: {doc.metadata}\nå†…å®¹: {doc.page_content}"
        for doc in retrieved_docs
    )
    return serialized, retrieved_docs

# åˆ›å»º RAG Agent
tools = [retrieve_context]
prompt = "ä½ å¯ä»¥ä½¿ç”¨æ£€ç´¢å·¥å…·æ¥æŸ¥æ‰¾åšå®¢å†…å®¹ï¼Œä»¥å¸®åŠ©å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"

agent = create_agent(model, tools, system_prompt=prompt)

# æŸ¥è¯¢
result = agent.invoke({
    "messages": [{"role": "user", "content": "ä»€ä¹ˆæ˜¯ä»»åŠ¡åˆ†è§£ï¼Ÿ"}]
})
```

---

## 9. Streaming æµå¼å¤„ç†

### 9.1 æµå¼æ¨¡å¼

#### 9.1.1 messages æ¨¡å¼ï¼ˆToken æµï¼‰
```python
agent = create_agent("gpt-4o", tools=[get_weather])

for token, metadata in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”ï¼Ÿ"}]},
    stream_mode="messages"
):
    print(f"èŠ‚ç‚¹: {metadata['langgraph_node']}")
    print(f"å†…å®¹: {token.content}")
```

#### 9.1.2 updates æ¨¡å¼ï¼ˆæ­¥éª¤æ›´æ–°ï¼‰
```python
for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”ï¼Ÿ"}]},
    stream_mode="updates"
):
    for step, data in chunk.items():
        print(f"æ­¥éª¤: {step}")
        print(f"æ¶ˆæ¯: {data['messages'][-1].content}")
```

#### 9.1.3 custom æ¨¡å¼ï¼ˆè‡ªå®šä¹‰æ›´æ–°ï¼‰
```python
from langgraph.config import get_stream_writer

@tool
def get_weather(city: str) -> str:
    """è·å–å¤©æ°”"""
    writer = get_stream_writer()
    writer(f"æ­£åœ¨æŸ¥è¯¢ {city}")
    writer(f"å·²è·å– {city} çš„æ•°æ®")
    return f"{city}æ°¸è¿œæ˜¯æ™´å¤©ï¼"

for chunk in agent.stream(
    {"messages": [{"role": "user", "content": "æ—§é‡‘å±±çš„å¤©æ°”ï¼Ÿ"}]},
    stream_mode="custom"
):
    print(chunk)
```

---

## 10. Middleware ä¸­é—´ä»¶ç³»ç»Ÿ

### 10.1 ä»€ä¹ˆæ˜¯ Middlewareï¼Ÿ

Middleware å…è®¸åœ¨ Agent æ‰§è¡Œçš„å„ä¸ªé˜¶æ®µæ’å…¥è‡ªå®šä¹‰é€»è¾‘ï¼š
- ğŸ”„ **before_model**: æ¨¡å‹è°ƒç”¨å‰
- ğŸ”„ **after_model**: æ¨¡å‹è°ƒç”¨å
- ğŸ”§ **wrap_tool_call**: å·¥å…·è°ƒç”¨åŒ…è£…
- ğŸ’¬ **dynamic_prompt**: åŠ¨æ€æç¤ºè¯

### 10.2 åŠ¨æ€æç¤ºè¯

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def user_role_prompt(request: ModelRequest) -> str:
    """åŸºäºç”¨æˆ·è§’è‰²ç”Ÿæˆæç¤ºè¯"""
    user_role = request.runtime.context.get("user_role", "user")
    base_prompt = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"
    
    if user_role == "expert":
        return f"{base_prompt} æä¾›è¯¦ç»†çš„æŠ€æœ¯å›ç­”ã€‚"
    elif user_role == "beginner":
        return f"{base_prompt} ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šï¼Œé¿å…æœ¯è¯­ã€‚"
    
    return base_prompt

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[user_role_prompt]
)
```

### 10.3 å·¥å…·é‡è¯•

```python
from langchain.agents.middleware import ToolRetryMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool, database_tool],
    middleware=[
        ToolRetryMiddleware(
            max_retries=3,
            backoff_factor=2.0,
            initial_delay=1.0
        )
    ]
)
```

### 10.4 å·¥å…·è°ƒç”¨é™åˆ¶

```python
from langchain.agents.middleware import ToolCallLimitMiddleware

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool],
    middleware=[
        # å…¨å±€é™åˆ¶
        ToolCallLimitMiddleware(thread_limit=20, run_limit=10),
        # å·¥å…·ç‰¹å®šé™åˆ¶
        ToolCallLimitMiddleware(
            tool_name="search",
            thread_limit=5,
            run_limit=3
        )
    ]
)
```

---

## 11. Structured Output ç»“æ„åŒ–è¾“å‡º

### 11.1 ä¸ºä»€ä¹ˆéœ€è¦ç»“æ„åŒ–è¾“å‡ºï¼Ÿ

è®© LLM è¾“å‡ºç¬¦åˆé¢„å®šä¹‰æ¨¡å¼çš„æ•°æ®ï¼Œä¾¿äºåç»­å¤„ç†å’Œé›†æˆã€‚

### 11.2 ä½¿ç”¨ Pydantic æ¨¡å‹

```python
from pydantic import BaseModel, Field

class Movie(BaseModel):
    """ç”µå½±ä¿¡æ¯"""
    title: str = Field(description="ç”µå½±æ ‡é¢˜")
    year: int = Field(description="ä¸Šæ˜ å¹´ä»½")
    director: str = Field(description="å¯¼æ¼”")
    rating: float = Field(description="è¯„åˆ†ï¼ˆæ»¡åˆ†10åˆ†ï¼‰")

# ç»‘å®šç»“æ„åŒ–è¾“å‡º
model_with_structure = model.with_structured_output(Movie)

response = model_with_structure.invoke("æä¾›ç”µå½±ã€Šç›—æ¢¦ç©ºé—´ã€‹çš„è¯¦ç»†ä¿¡æ¯")
print(response)
# Movie(title="ç›—æ¢¦ç©ºé—´", year=2010, director="å…‹é‡Œæ–¯æ‰˜å¼—Â·è¯ºå…°", rating=8.8)
```

### 11.3 åœ¨ Agent ä¸­ä½¿ç”¨

```python
from langchain.agents.structured_output import ToolStrategy

class ContactInfo(BaseModel):
    name: str
    email: str
    phone: str

agent = create_agent(
    model="gpt-4o",
    tools=[search_tool],
    response_format=ToolStrategy(ContactInfo)
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "æå–è”ç³»ä¿¡æ¯ï¼šJohn Doe, john@example.com, (555) 123-4567"}]
})

print(result["structured_response"])
# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')
```

---

## 12. Prompt Engineering æç¤ºå·¥ç¨‹

### 12.1 ç³»ç»Ÿæç¤ºè¯

```python
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ SQL æŸ¥è¯¢åŠ©æ‰‹ã€‚
ç»™å®šç”¨æˆ·é—®é¢˜ï¼Œåˆ›å»ºè¯­æ³•æ­£ç¡®çš„ {dialect} æŸ¥è¯¢ã€‚

è§„åˆ™ï¼š
1. å§‹ç»ˆé™åˆ¶ç»“æœä¸º {top_k} æ¡
2. å…ˆæŸ¥çœ‹æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨
3. æŸ¥è¯¢æœ€ç›¸å…³è¡¨çš„æ¨¡å¼
4. æ‰§è¡Œå‰ä»”ç»†æ£€æŸ¥æŸ¥è¯¢
5. ä¸è¦æ‰§è¡Œ DML è¯­å¥ï¼ˆINSERTã€UPDATEã€DELETEã€DROPï¼‰
"""

agent = create_agent(
    model="gpt-4o",
    tools=sql_tools,
    system_prompt=SYSTEM_PROMPT.format(dialect="PostgreSQL", top_k=5)
)
```

### 12.2 åŠ¨æ€ä¸Šä¸‹æ–‡æ³¨å…¥

```python
from langchain.agents.middleware import dynamic_prompt

@dynamic_prompt
def prompt_with_context(request: ModelRequest) -> str:
    """æ³¨å…¥æ£€ç´¢ä¸Šä¸‹æ–‡"""
    last_query = request.state["messages"][-1].text
    retrieved_docs = vector_store.similarity_search(last_query)
    
    docs_content = "\n\n".join(doc.page_content for doc in retrieved_docs)
    
    return (
        "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š"
        f"\n\n{docs_content}"
    )

agent = create_agent(model, tools=[], middleware=[prompt_with_context])
```

---

## 13. Observability å¯è§‚æµ‹æ€§

### 13.1 LangSmith é›†æˆ

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export LANGSMITH_API_KEY="your-api-key"
export LANGSMITH_TRACING="true"
export LANGSMITH_PROJECT="my-project"
```

### 13.2 æ·»åŠ è¿½è¸ªå…ƒæ•°æ®

```python
response = agent.invoke(
    {"messages": [{"role": "user", "content": "å‘é€æ¬¢è¿é‚®ä»¶"}]},
    config={
        "tags": ["production", "email-assistant", "v1.0"],
        "metadata": {
            "user_id": "user_123",
            "session_id": "session_456",
            "environment": "production"
        }
    }
)
```

### 13.3 é€‰æ‹©æ€§è¿½è¸ª

```python
import langsmith as ls

# åªè¿½è¸ªè¿™æ®µä»£ç 
with ls.tracing_context(enabled=True):
    agent.invoke({"messages": [{"role": "user", "content": "æµ‹è¯•"}]})

# è¿™æ®µä¸è¿½è¸ª
agent.invoke({"messages": [{"role": "user", "content": "å¦ä¸€ä¸ªæµ‹è¯•"}]})
```

---

## 14. éƒ¨ç½²ä¸ç”Ÿäº§

### 14.1 ç¯å¢ƒé…ç½®

```python
import os

# ç”Ÿäº§ç¯å¢ƒé…ç½®
os.environ["LANGCHAIN_ENV"] = "production"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"

# æ¨¡å‹é…ç½®
model = ChatOpenAI(
    model="gpt-4o",
    temperature=0.1,  # é™ä½éšæœºæ€§
    max_retries=3,
    timeout=30
)
```

### 14.2 æŒä¹…åŒ– Checkpointer

```python
from langgraph.checkpoint.postgres import PostgresSaver

# ä½¿ç”¨ PostgreSQL æŒä¹…åŒ–
checkpointer = PostgresSaver.from_conn_string(
    "postgresql://user:pass@localhost:5432/langchain_db"
)

agent = create_agent(
    model="gpt-4o",
    tools=tools,
    checkpointer=checkpointer
)
```

### 14.3 é”™è¯¯å¤„ç†

```python
from langchain_core.exceptions import LangChainException

try:
    result = agent.invoke({"messages": [...]})
except LangChainException as e:
    logger.error(f"Agent æ‰§è¡Œå¤±è´¥: {e}")
    # é™çº§ç­–ç•¥
    result = fallback_response()
```

---

## 15. æœ€ä½³å®è·µ

### 15.1 è®¾è®¡åŸåˆ™

âœ… **Doï¼ˆæ¨èï¼‰**ï¼š
- ä½¿ç”¨æ¸…æ™°çš„å·¥å…·æè¿°å’Œç±»å‹æç¤º
- ä¸º Agent æä¾›å…·ä½“çš„ç³»ç»Ÿæç¤ºè¯
- ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
- æ·»åŠ è¿½è¸ªå’Œç›‘æ§
- å®æ–½é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- é™åˆ¶å·¥å…·è°ƒç”¨æ¬¡æ•°é˜²æ­¢å¾ªç¯
- ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç¡®ä¿æ•°æ®ä¸€è‡´æ€§

âŒ **Don'tï¼ˆä¸æ¨èï¼‰**ï¼š
- æ¨¡ç³Šçš„å·¥å…·æè¿°
- è¿‡äºå¤æ‚çš„å•ä¸ªå·¥å…·
- åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å†…å­˜å­˜å‚¨
- å¿½ç•¥é”™è¯¯å¤„ç†
- æ— é™åˆ¶çš„å·¥å…·è°ƒç”¨
- ç¡¬ç¼–ç  API å¯†é’¥

### 15.2 æ€§èƒ½ä¼˜åŒ–

```python
# 1. ä½¿ç”¨æ‰¹å¤„ç†
responses = model.batch([query1, query2, query3])

# 2. å¹¶è¡Œæ‰§è¡Œ
from langgraph.graph import StateGraph
# ä½¿ç”¨ add_edge ä» START åˆ°å¤šä¸ªèŠ‚ç‚¹å®ç°å¹¶è¡Œ

# 3. ç¼“å­˜æç¤ºè¯
from langchain_anthropic.middleware import AnthropicPromptCachingMiddleware

agent = create_agent(
    model=ChatAnthropic(model="claude-sonnet-4-5-20250929"),
    system_prompt=LONG_PROMPT,
    middleware=[AnthropicPromptCachingMiddleware(ttl="5m")]
)
```

### 15.3 å®‰å…¨è€ƒè™‘

```python
# 1. ä¸è¦ç¡¬ç¼–ç å¯†é’¥
api_key = os.environ.get("OPENAI_API_KEY")

# 2. éªŒè¯å·¥å…·è¾“å…¥
@tool
def execute_query(query: str) -> str:
    """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢"""
    # éªŒè¯æŸ¥è¯¢ï¼Œé˜²æ­¢æ³¨å…¥
    if any(keyword in query.upper() for keyword in ["DROP", "DELETE", "UPDATE"]):
        return "ä¸å…è®¸çš„æ“ä½œ"
    return db.execute(query)

# 3. é™åˆ¶è¾“å‡ºé•¿åº¦
model = ChatOpenAI(
    model="gpt-4o",
    max_tokens=2000  # é™åˆ¶è¾“å‡º
)
```

### 15.4 æµ‹è¯•ç­–ç•¥

```python
# 1. å•å…ƒæµ‹è¯•å·¥å…·
def test_search_tool():
    result = search_database("test query", limit=5)
    assert "test query" in result

# 2. é›†æˆæµ‹è¯• Agent
def test_agent_response():
    result = agent.invoke({
        "messages": [{"role": "user", "content": "æµ‹è¯•æŸ¥è¯¢"}]
    })
    assert result["messages"][-1].content

# 3. ä½¿ç”¨ LLM æ¨¡æ‹Ÿå™¨æµ‹è¯•
from langchain.agents.middleware import LLMToolEmulator

test_agent = create_agent(
    model="gpt-4o",
    tools=[get_weather, search],
    middleware=[LLMToolEmulator()]  # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨
)
```

---

## ğŸ“– å­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain Python æ–‡æ¡£](https://python.langchain.com/)
- [LangChain JavaScript æ–‡æ¡£](https://js.langchain.com/)
- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)
- [LangSmith æ–‡æ¡£](https://docs.smith.langchain.com/)

### ç¤¾åŒºèµ„æº
- [GitHub ä»“åº“](https://github.com/langchain-ai/langchain)
- [Discord ç¤¾åŒº](https://discord.gg/langchain)
- [Twitter](https://twitter.com/LangChainAI)

### ç¤ºä¾‹é¡¹ç›®
- RAG é—®ç­”ç³»ç»Ÿ
- SQL æŸ¥è¯¢ Agent
- å¤š Agent åä½œç³»ç»Ÿ
- æ–‡æ¡£åˆ†æå·¥å…·
- ä»£ç åŠ©æ‰‹

---

## ğŸ¯ å­¦ä¹ è·¯çº¿å»ºè®®

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ï¼ˆ1-2å‘¨ï¼‰
1. ç†è§£ LangChain æ ¸å¿ƒæ¦‚å¿µ
2. å­¦ä¹ æ¨¡å‹åˆå§‹åŒ–å’Œè°ƒç”¨
3. æŒæ¡åŸºç¡€å·¥å…·å®šä¹‰
4. åˆ›å»ºç®€å•çš„ Agent

### ç¬¬äºŒé˜¶æ®µï¼šè¿›é˜¶ï¼ˆ2-3å‘¨ï¼‰
1. æ·±å…¥ LangGraph å·¥ä½œæµ
2. æŒæ¡è®°å¿†ç³»ç»Ÿï¼ˆçŸ­æœŸ+é•¿æœŸï¼‰
3. å®ç° RAG ç³»ç»Ÿ
4. å­¦ä¹  Middleware æœºåˆ¶

### ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§ï¼ˆ3-4å‘¨ï¼‰
1. å¤š Agent åä½œ
2. ç»“æ„åŒ–è¾“å‡ºå’Œæ•°æ®éªŒè¯
3. æµå¼å¤„ç†å’Œå®æ—¶äº¤äº’
4. å¯è§‚æµ‹æ€§å’Œç›‘æ§

### ç¬¬å››é˜¶æ®µï¼šç”Ÿäº§ï¼ˆæŒç»­ï¼‰
1. æ€§èƒ½ä¼˜åŒ–
2. é”™è¯¯å¤„ç†å’Œå®¹é”™
3. å®‰å…¨æ€§åŠ å›º
4. éƒ¨ç½²å’Œè¿ç»´

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```python
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.checkpoint.memory import InMemorySaver

# å®šä¹‰å·¥å…·
@tool
def get_weather(city: str) -> str:
    """è·å–åŸå¸‚å¤©æ°”"""
    return f"{city}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œ22Â°C"

# åˆ›å»º Agent
agent = create_agent(
    model="gpt-4o",
    tools=[get_weather],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å¤©æ°”åŠ©æ‰‹",
    checkpointer=InMemorySaver()
)

# è¿è¡Œ Agent
result = agent.invoke(
    {"messages": [{"role": "user", "content": "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}]},
    {"configurable": {"thread_id": "session_1"}}
)

print(result["messages"][-1].content)
```

---

**ğŸ‰ æ­å–œä½ å®Œæˆ LangChain å­¦ä¹ è®¡åˆ’ï¼ç°åœ¨å¼€å§‹æ„å»ºä½ çš„ AI åº”ç”¨å§ï¼**

