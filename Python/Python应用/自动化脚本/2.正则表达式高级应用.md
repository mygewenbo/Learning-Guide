# 正则表达式高级应用

## 一、概述

在Python自动化脚本开发中，正则表达式是一项强大的工具，能够帮助我们处理各种复杂的文本处理任务。在上一章中，我们已经学习了正则表达式的基础语法和re模块的基本使用。本章将深入探讨正则表达式的高级特性和应用，帮助你掌握更复杂的模式设计和优化技巧。

## 二、高级正则表达式语法

### 1. 断言（Assertions）

断言是一种特殊的正则表达式语法，用于匹配位置而不是实际字符。断言不会消耗字符，只会检查某个位置是否满足特定条件。

#### 1.1 正向先行断言（Positive Lookahead）

正向先行断言用于检查某个位置后面是否匹配指定的模式，语法为：`(?=pattern)`

```python
import re

# 匹配后面跟着"world"的"hello"
text = "hello world, hello python"
pattern = r"hello(?= world)"
result = re.findall(pattern, text)
print(result)  # 输出：['hello']

# 匹配后面跟着数字的单词
text = "apple123 banana cherry456"
pattern = r"\w+(?=\d+)"
result = re.findall(pattern, text)
print(result)  # 输出：['apple', 'cherry']
```

#### 1.2 负向先行断言（Negative Lookahead）

负向先行断言用于检查某个位置后面是否**不**匹配指定的模式，语法为：`(?!pattern)`

```python
import re

# 匹配后面不跟着"world"的"hello"
text = "hello world, hello python"
pattern = r"hello(?! world)"
result = re.findall(pattern, text)
print(result)  # 输出：['hello']

# 匹配后面不跟着数字的单词
text = "apple123 banana cherry456"
pattern = r"\w+(?!\d+)"
result = re.findall(pattern, text)
print(result)  # 输出：['banana']
```

#### 1.3 正向后行断言（Positive Lookbehind）

正向后行断言用于检查某个位置前面是否匹配指定的模式，语法为：`(?<=pattern)`

```python
import re

# 匹配前面是"hello "的"world"
text = "hello world, hello python"
pattern = r"(?<=hello )world"
result = re.findall(pattern, text)
print(result)  # 输出：['world']

# 匹配前面是数字的单词
text = "123apple 456banana cherry"
pattern = r"(?<=\d+)\w+"
result = re.findall(pattern, text)
print(result)  # 输出：['apple', 'banana']
```

#### 1.4 负向后行断言（Negative Lookbehind）

负向后行断言用于检查某个位置前面是否**不**匹配指定的模式，语法为：`(?<!pattern)`

```python
import re

# 匹配前面不是"hello "的"world"
text = "hi world, hello world"
pattern = r"(?<!hello )world"
result = re.findall(pattern, text)
print(result)  # 输出：['world']

# 匹配前面不是数字的单词
text = "123apple 456banana cherry"
pattern = r"(?<!\d+)\w+"
result = re.findall(pattern, text)
print(result)  # 输出：['cherry']
```

### 2. 命名捕获组的高级用法

#### 2.1 命名捕获组与反向引用

```python
import re

# 使用命名捕获组和反向引用匹配重复的单词
text = "hello hello world world python"
pattern = r"(?P<word>\w+)\s+(?P=word)"
result = re.findall(pattern, text)
print(result)  # 输出：['hello', 'world']

# 匹配HTML标签对
text = "<div>content</div><span>text</span>"
pattern = r"<(?P<tag>\w+)>(.*?)</(?P=tag)>"
result = re.findall(pattern, text)
print(result)  # 输出：[('div', 'content'), ('span', 'text')]
```

#### 2.2 命名捕获组在sub()中的应用

```python
import re

# 使用命名捕获组进行复杂替换
text = "John Doe, Jane Smith"
pattern = r"(?P<first>\w+)\s+(?P<last>\w+)"
# 将"First Last"替换为"Last, First"
result = re.sub(pattern, r"\g<last>, \g<first>", text)
print(result)  # 输出：Doe, John, Smith, Jane

# 使用函数进行更复杂的替换
text = "2023-12-01 2024-01-15"
def format_date(match):
    year = match.group('year')
    month = match.group('month')
    day = match.group('day')
    return f"{month}/{day}/{year}"

pattern = r"(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})"
result = re.sub(pattern, format_date, text)
print(result)  # 输出：12/01/2023 01/15/2024
```

### 3. 原子组（Atomic Groups）

原子组用于防止正则表达式引擎进行回溯，提高匹配效率，语法为：`(?>pattern)`

```python
import re
import time

# 测试原子组对性能的影响
text = "a" * 20 + "b"

# 没有原子组的模式（会导致大量回溯）
pattern1 = r"(a+)+b"
start_time = time.time()
result1 = re.search(pattern1, text)
end_time1 = time.time()

# 有原子组的模式（防止回溯）
pattern2 = r"(?>a+)+b"
start_time = time.time()
result2 = re.search(pattern2, text)
end_time2 = time.time()

print(f"无原子组耗时: {end_time1 - start_time:.6f}秒")
print(f"有原子组耗时: {end_time2 - start_time:.6f}秒")
```

### 4. 条件匹配

条件匹配允许根据前面的匹配结果来决定是否匹配后面的模式，语法为：`(?(group)yes-pattern|no-pattern)`

```python
import re

# 匹配带可选前缀的电话号码
text = "13812345678 +8613987654321"
pattern = r"(\+86)?(?(1)\d{11}|1\d{10})"
result = re.findall(pattern, text)
print(result)  # 输出：[('', '13812345678'), ('+86', '13987654321')]

# 匹配可选的引号包围的字符串
text = "hello 'world' \"python\""
pattern = r"(['"])?(.*?)(?(1)\1|$)"
result = re.findall(pattern, text)
print(result)  # 输出：[('', 'hello '), ("'", 'world'), ('"', 'python')]
```

### 5. Unicode属性匹配

Python 3.7+支持使用Unicode属性进行匹配，语法为：`\p{Property}`或`\P{Property}`（表示不匹配）

```python
import re

# 匹配中文汉字
text = "Hello 你好 World 世界"
pattern = r"\p{Han}+"
result = re.findall(pattern, text)
print(result)  # 输出：['你好', '世界']

# 匹配所有Unicode字母
text = "Hello 你好 123 世界 αβγ"
pattern = r"\p{L}+"
result = re.findall(pattern, text)
print(result)  # 输出：['Hello', '你好', '世界', 'αβγ']

# 匹配所有数字（包括罗马数字、中文数字等）
text = "123 四百五十六 ⅣⅤⅥ"
pattern = r"\p{N}+"
result = re.findall(pattern, text)
print(result)  # 输出：['123', '四百五十六', 'ⅣⅤⅥ']
```

## 三、复杂模式设计技巧

### 1. 分层设计模式

对于复杂的文本结构，我们可以采用分层设计的方式，将复杂模式分解为多个简单模式，逐步匹配和提取信息。

```python
import re

# 解析复杂的日志条目
log_entry = "2023-12-01 14:30:45 [INFO] User 'alice' logged in from 192.168.1.100"

# 第一层：匹配整体结构
pattern1 = r"(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<message>.+)"

# 第二层：解析消息内容
message_pattern = r"User '(?P<username>\w+)' logged in from (?P<ip>\d+\.\d+\.\d+\.\d+)"

match = re.match(pattern1, log_entry)
if match:
    timestamp = match.group('timestamp')
    level = match.group('level')
    message = match.group('message')
    
    message_match = re.match(message_pattern, message)
    if message_match:
        username = message_match.group('username')
        ip = message_match.group('ip')
        
        print(f"Timestamp: {timestamp}")
        print(f"Level: {level}")
        print(f"Username: {username}")
        print(f"IP: {ip}")
```

### 2. 模式组合与模块化

```python
import re

# 定义可复用的模式组件
ipv4_pattern = r"(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.(?:25[0-5]|2[0-4]\d|[01]?\d\d?)\.(?:25[0-5]|2[0-4]\d|[01]?\d\d?)"
port_pattern = r"\d{1,5}"
protocol_pattern = r"https?"

# 组合成完整的URL模式
url_pattern = rf"{protocol_pattern}://{ipv4_pattern}(?::{port_pattern})?/\S*"

# 测试匹配
text = "Visit http://192.168.1.1:8080/home or https://10.0.0.1/api/data"
result = re.findall(url_pattern, text)
print(result)  # 输出：['http://192.168.1.1:8080/home', 'https://10.0.0.1/api/data']
```

### 3. 处理嵌套结构

对于嵌套结构，正则表达式的处理能力有限，但我们可以使用一些技巧来处理简单的嵌套情况。

```python
import re

# 匹配简单的嵌套括号
text = "(a (b c) d) (e f)"

# 使用递归正则表达式（Python需要使用regex模块，标准re模块不支持）
# 这里使用替代方案
pattern = r"\((?:[^()]+|\((?:[^()]+|\([^()]*\))*\))*\)"
result = re.findall(pattern, text)
print(result)  # 输出：['(a (b c) d)', '(e f)']

# 更简单的方法：使用栈来处理嵌套结构
def extract_nested(text, start_char='(', end_char=')'):
    result = []
    stack = []
    current = []
    
    for char in text:
        if char == start_char:
            stack.append(char)
            if len(stack) == 1:  # 只记录最外层的开始
                current = []
            else:
                current.append(char)
        elif char == end_char:
            if stack:
                stack.pop()
                if not stack:  # 最外层结束
                    result.append(''.join(current))
                else:
                    current.append(char)
        elif stack:  # 只有在括号内才记录
            current.append(char)
    
    return result

result = extract_nested(text)
print(result)  # 输出：['a (b c) d', 'e f']
```

## 四、正则表达式性能优化

### 1. 避免过度回溯

回溯是正则表达式引擎在匹配失败时尝试其他可能路径的过程，过度回溯会导致性能问题。

```python
import re
import time

# 不好的模式：会导致大量回溯
bad_pattern = r"(a+)+b"

# 好的模式：避免回溯
# 1. 使用原子组
good_pattern1 = r"(?>a+)+b"
# 2. 简化模式
good_pattern2 = r"a+b"

text = "a" * 20 + "c"  # 不匹配的情况，会导致回溯

start_time = time.time()
re.search(bad_pattern, text)
end_time = time.time()
print(f"Bad pattern: {end_time - start_time:.6f}秒")

start_time = time.time()
re.search(good_pattern1, text)
end_time = time.time()
print(f"Good pattern 1: {end_time - start_time:.6f}秒")

start_time = time.time()
re.search(good_pattern2, text)
end_time = time.time()
print(f"Good pattern 2: {end_time - start_time:.6f}秒")
```

### 2. 优化量词使用

- 尽量使用具体的量词替代宽泛的量词
- 优先使用非贪婪匹配（*?、+?、??）避免过度匹配
- 合理使用锚点（^、$、\b）限制匹配范围

```python
import re

# 不好的模式：宽泛的量词和贪婪匹配
bad_pattern = r".*=.*"

# 好的模式：具体的量词和非贪婪匹配
good_pattern = r"[^=]*?=[^=]*"

text = "key1=value1;key2=value2;key3=value3"

result1 = re.findall(bad_pattern, text)
result2 = re.findall(good_pattern, text)

print(f"Bad pattern result: {result1}")  # 输出：['key1=value1;key2=value2;key3=value3']
print(f"Good pattern result: {result2}")  # 输出：['key1=value1', ';key2=value2', ';key3=value3']
```

### 3. 编译正则表达式

对于频繁使用的正则表达式，编译可以提高性能。

```python
import re
import time

# 未编译的正则表达式
text = "Hello world" * 100000
pattern = r"world"

start_time = time.time()
for _ in range(1000):
    re.findall(pattern, text)
end_time = time.time()
print(f"未编译: {end_time - start_time:.6f}秒")

# 编译的正则表达式
compiled_pattern = re.compile(pattern)
start_time = time.time()
for _ in range(1000):
    compiled_pattern.findall(text)
end_time = time.time()
print(f"已编译: {end_time - start_time:.6f}秒")
```

### 4. 优先使用字符串方法

对于简单的文本操作，字符串方法通常比正则表达式更快。

```python
import re
import time

text = "Hello world" * 100000

# 使用正则表达式
start_time = time.time()
result1 = re.findall(r"world", text)
end_time = time.time()
print(f"正则表达式: {end_time - start_time:.6f}秒")

# 使用字符串方法
start_time = time.time()
result2 = text.count("world")
end_time = time.time()
print(f"字符串方法: {end_time - start_time:.6f}秒")
```

## 五、高级应用场景

### 1. 解析复杂日志文件

```python
import re

# 解析Nginx访问日志
log_pattern = r"(?P<ip>\d+\.\d+\.\d+\.\d+) - - \[(?P<timestamp>[^\]]+)\] "
log_pattern += r'"(?P<method>\w+) (?P<path>[^\s]+) (?P<protocol>[^"]+)" '
log_pattern += r"(?P<status>\d+) (?P<size>\d+) "
log_pattern += r'"(?P<referer>[^"]*)" "(?P<user_agent>[^"]*)"'

log_entry = "192.168.1.1 - - [01/Dec/2023:14:30:45 +0800] \"GET /index.html HTTP/1.1\" 200 1024 \"-\" \"Mozilla/5.0\""

match = re.match(log_pattern, log_entry)
if match:
    print(f"IP: {match.group('ip')}")
    print(f"Timestamp: {match.group('timestamp')}")
    print(f"Method: {match.group('method')}")
    print(f"Path: {match.group('path')}")
    print(f"Status: {match.group('status')}")
    print(f"Size: {match.group('size')}")
    print(f"Referer: {match.group('referer')}")
    print(f"User-Agent: {match.group('user_agent')}")
```

### 2. 数据提取与转换

```python
import re

# 从HTML中提取结构化数据
html = """
<table>
    <tr><th>Name</th><th>Age</th><th>City</th></tr>
    <tr><td>John</td><td>30</td><td>New York</td></tr>
    <tr><td>Jane</td><td>25</td><td>London</td></tr>
    <tr><td>Bob</td><td>35</td><td>Paris</td></tr>
</table>
"""

# 提取表格数据
row_pattern = r"<tr>(.*?)</tr>"
cell_pattern = r"<td>(.*?)</td>"

rows = re.findall(row_pattern, html, re.DOTALL)
for i, row in enumerate(rows[1:]):  # 跳过表头
    cells = re.findall(cell_pattern, row)
    name, age, city = cells
    print(f"Person {i+1}: Name={name}, Age={age}, City={city}")

# 输出：
# Person 1: Name=John, Age=30, City=New York
# Person 2: Name=Jane, Age=25, City=London
# Person 3: Name=Bob, Age=35, City=Paris
```

### 3. 代码解析与重构

```python
import re

# 从Python代码中提取函数定义
def extract_functions(code):
    pattern = r"def\s+(?P<name>\w+)\s*\((?P<params>[^)]*)\)\s*:\s*(?P<docstring>\"\"\".*?\"\"\"|'''[^']*'''|)"
    return re.findall(pattern, code, re.DOTALL)

code = """
def add(a, b):
    """Add two numbers"""
    return a + b

def multiply(x, y=1):
    '''Multiply two numbers'''    
    return x * y

def greet(name):
    return f"Hello, {name}!"
"""

functions = extract_functions(code)
for func in functions:
    name, params, docstring = func
    print(f"Function: {name}")
    print(f"Params: {params}")
    print(f"Docstring: {docstring.strip()}")
    print()
```

### 4. 自然语言处理

```python
import re

# 提取文本中的实体
text = "Apple was founded by Steve Jobs in Cupertino, California in 1976."

# 提取组织名
org_pattern = r"\b[A-Z][a-zA-Z]+\b"
orgs = re.findall(org_pattern, text)
print(f"Organizations: {orgs}")

# 提取人名
person_pattern = r"\b[A-Z][a-z]+\s+[A-Z][a-z]+\b"
people = re.findall(person_pattern, text)
print(f"People: {people}")

# 提取地点
place_pattern = r"\b[A-Z][a-zA-Z]+(?:,\s+[A-Z][a-zA-Z]+)?\b"
places = re.findall(place_pattern, text)
# 过滤掉已识别的组织和人名
places = [place for place in places if place not in orgs and place not in people]
print(f"Places: {places}")

# 提取年份
year_pattern = r"\b\d{4}\b"
years = re.findall(year_pattern, text)
print(f"Years: {years}")
```

## 六、正则表达式调试技巧

### 1. 使用regex101.com

[regex101.com](https://regex101.com/)是一个强大的正则表达式在线测试工具，支持Python语法，可以帮助你：
- 测试正则表达式匹配
- 查看匹配过程和回溯情况
- 分析性能
- 获取详细的解释

### 2. 使用re.DEBUG标志

Python的re模块提供了DEBUG标志，可以输出正则表达式的编译过程，帮助你理解正则表达式的内部工作原理。

```python
import re

pattern = r"(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})"
# 输出正则表达式的编译过程
re.compile(pattern, re.DEBUG)
```

### 3. 分段测试

对于复杂的正则表达式，建议分段测试，逐步构建完整的模式。

```python
import re

# 完整模式
full_pattern = r"(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<message>.+)"

# 分段测试
# 1. 测试时间戳
 timestamp_pattern = r"(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})"
# 2. 测试日志级别
 level_pattern = r"\[(?P<level>\w+)\]"
# 3. 测试消息
 message_pattern = r"(?P<message>.+)"

# 逐步组合测试
```

### 4. 使用捕获组调试

在调试复杂正则表达式时，可以添加额外的捕获组来查看匹配过程中的中间结果。

```python
import re

text = "2023-12-01 14:30:45 [INFO] User logged in"

# 添加额外的捕获组用于调试
pattern = r"(\d{4}-\d{2}-\d{2})\s+(\d{2}:\d{2}:\d{2})\s+\[(\w+)\]\s+(.+)"
match = re.match(pattern, text)
if match:
    print(f"Full match: {match.group(0)}")
    print(f"Date: {match.group(1)}")
    print(f"Time: {match.group(2)}")
    print(f"Level: {match.group(3)}")
    print(f"Message: {match.group(4)}")
```

## 七、高级re模块功能

### 1. 使用regex模块扩展功能

Python的标准re模块功能有限，对于一些高级特性（如递归正则表达式、占有量词等），可以使用第三方的regex模块。

```python
# 需要先安装：pip install regex
import regex

# 使用递归正则表达式匹配嵌套括号
text = "(a (b (c) d) e)"
pattern = r"\((?>[^()]+|(?R))*\)"
result = regex.findall(pattern, text)
print(result)  # 输出：['(a (b (c) d) e)']

# 使用占有量词
text = "aaaaaab"
# 标准re模块不支持占有量词
# 使用regex模块的占有量词
pattern = r"a++b"
result = regex.findall(pattern, text)
print(result)  # 输出：['aaaaaab']
```

### 2. 使用re.Scanner进行词法分析

re.Scanner可以用于简单的词法分析，将文本分解为标记流。

```python
import re

# 定义标记类型
tokens = [
    (r"\d+", lambda scanner, token: ("NUMBER", int(token))),
    (r"[+\-*/]", lambda scanner, token: ("OPERATOR", token)),
    (r"\s+", lambda scanner, token: None),  # 忽略空白字符
]

# 创建扫描器
scanner = re.Scanner(tokens)

# 扫描文本
text = "123 + 456 - 789 * 321 / 100"
tokens, remainder = scanner.scan(text)

# 过滤掉None值
tokens = [token for token in tokens if token is not None]

print(f"Tokens: {tokens}")
print(f"Remainder: '{remainder}'")
```

### 3. 使用re.VERBOSE编写可读的正则表达式

re.VERBOSE标志允许在正则表达式中添加注释和空白字符，提高可读性。

```python
import re

# 使用VERBOSE编写复杂的正则表达式
pattern = re.compile(r"""
    ^                   # 字符串开头
    (?P<protocol>https?) # 协议部分
    ://                  # URL分隔符
    (?P<domain>          # 域名部分
        (?:[a-zA-Z0-9-]+\.)+  # 子域名
        [a-zA-Z]{2,}          # 顶级域名
    )
    (?::(?P<port>\d{1,5}))?  # 可选端口
    (?P<path>/[^?#]*)?        # 路径
    (?:\?(?P<query>[^#]*))?   # 可选查询字符串
    (?:#(?P<fragment>.*))?    # 可选片段
    $                   # 字符串结尾
""", re.VERBOSE)

url = "https://www.example.com:8080/path/to/resource?param1=value1&param2=value2#section1"
match = pattern.match(url)
if match:
    print(f"Protocol: {match.group('protocol')}")
    print(f"Domain: {match.group('domain')}")
    print(f"Port: {match.group('port')}")
    print(f"Path: {match.group('path')}")
    print(f"Query: {match.group('query')}")
    print(f"Fragment: {match.group('fragment')}")
```

## 八、最佳实践与注意事项

### 1. 选择合适的工具

- 对于简单的文本操作，优先使用字符串方法
- 对于复杂的模式匹配，使用正则表达式
- 对于非常复杂的文本结构，考虑使用专门的解析库（如lxml、BeautifulSoup等）

### 2. 编写可读的正则表达式

- 使用re.VERBOSE添加注释和空白
- 将复杂模式分解为多个简单模式
- 使用有意义的命名捕获组
- 添加适当的文档说明正则表达式的用途和匹配规则

### 3. 测试边界情况

- 测试空字符串
- 测试最小匹配
- 测试最大匹配
- 测试特殊字符
- 测试不匹配的情况

### 4. 考虑国际化

- 使用Unicode属性匹配而非ASCII范围
- 考虑不同语言的字符集
- 避免硬编码字符范围

### 5. 安全性考虑

- 避免使用正则表达式处理不可信的输入，可能导致ReDoS（正则表达式拒绝服务）攻击
- 限制正则表达式的匹配时间和复杂度
- 对用户提供的正则表达式进行验证和限制

## 九、综合示例

### 1. 解析CSV文件

```python
import re

# 解析CSV文件，处理引号和逗号
csv_text = '''Name,Age,City
John Doe,30,New York
"Smith, Jane",25,"London, UK"
Bob,35,Paris
"Doe, Jr., John",40,"Los Angeles, CA"
'''

# 正则表达式模式：匹配CSV字段
# 1. 匹配带引号的字段："(?:[^"\\]|\\.)*" 
# 2. 匹配不带引号的字段：[^,\r\n]*
field_pattern = r'"(?:[^"\\]|\\.)*"|[^,\r\n]*'

# 拆分CSV行
lines = csv_text.strip().split('\n')

# 解析每一行
for line in lines:
    # 提取字段
    fields = re.findall(field_pattern, line)
    # 清理字段：去除引号和首尾空白
    cleaned_fields = []
    for field in fields:
        if field.startswith('"') and field.endswith('"'):
            # 去除引号并处理转义字符
            field = field[1:-1].replace('\\"', '"')
        cleaned_fields.append(field.strip())
    
    print(cleaned_fields)
```

### 2. 日志分析工具

```python
import re
import collections

# 简单的日志分析工具
class LogAnalyzer:
    def __init__(self, log_pattern):
        self.pattern = re.compile(log_pattern)
        self.stats = {
            'levels': collections.Counter(),
            'ips': collections.Counter(),
            'paths': collections.Counter()
        }
    
    def analyze_line(self, line):
        match = self.pattern.match(line)
        if match:
            level = match.group('level')
            ip = match.group('ip')
            path = match.group('path')
            
            self.stats['levels'][level] += 1
            self.stats['ips'][ip] += 1
            self.stats['paths'][path] += 1
    
    def analyze_file(self, file_path):
        with open(file_path, 'r') as f:
            for line in f:
                self.analyze_line(line.strip())
    
    def print_stats(self):
        print("=== Log Analysis Results ===")
        print("\nLog Levels:")
        for level, count in self.stats['levels'].most_common():
            print(f"  {level}: {count}")
        
        print("\nTop IPs:")
        for ip, count in self.stats['ips'].most_common(5):
            print(f"  {ip}: {count}")
        
        print("\nTop Paths:")
        for path, count in self.stats['paths'].most_common(5):
            print(f"  {path}: {count}")

# 使用示例
if __name__ == "__main__":
    # Nginx访问日志模式
    log_pattern = r"(?P<ip>\d+\.\d+\.\d+\.\d+) - - \[(?P<timestamp>[^\]]+)\] "
    log_pattern += r'"(?P<method>\w+) (?P<path>[^\s]+) (?P<protocol>[^"]+)" '
    log_pattern += r"(?P<status>\d+) (?P<size>\d+) "
    log_pattern += r'"(?P<referer>[^"]*)" "(?P<user_agent>[^"]*)"'
    
    analyzer = LogAnalyzer(log_pattern)
    
    # 模拟日志数据
    sample_logs = [
        "192.168.1.1 - - [01/Dec/2023:14:30:45 +0800] \"GET /index.html HTTP/1.1\" 200 1024 \"-\" \"Mozilla/5.0\"",
        "192.168.1.2 - - [01/Dec/2023:14:31:00 +0800] \"POST /api/data HTTP/1.1\" 201 512 \"-\" \"Python/3.10\"",
        "192.168.1.1 - - [01/Dec/2023:14:31:30 +0800] \"GET /styles.css HTTP/1.1\" 200 2048 \"-\" \"Mozilla/5.0\"",
        "192.168.1.3 - - [01/Dec/2023:14:32:00 +0800] \"GET /script.js HTTP/1.1\" 404 0 \"-\" \"Chrome/108.0\"",
        "192.168.1.1 - - [01/Dec/2023:14:32:30 +0800] \"GET /images/logo.png HTTP/1.1\" 200 4096 \"-\" \"Mozilla/5.0\"",
    ]
    
    for log in sample_logs:
        analyzer.analyze_line(log)
    
    analyzer.print_stats()
```

## 十、总结

正则表达式是一项强大的文本处理工具，掌握其高级特性和应用技巧能够帮助你处理各种复杂的文本处理任务。本章我们学习了：

1. **高级正则表达式语法**：包括断言、命名捕获组的高级用法、原子组、条件匹配和Unicode属性匹配
2. **复杂模式设计技巧**：分层设计、模式组合与模块化、处理嵌套结构
3. **正则表达式性能优化**：避免过度回溯、优化量词使用、编译正则表达式、优先使用字符串方法
4. **高级应用场景**：解析复杂日志文件、数据提取与转换、代码解析与重构、自然语言处理
5. **正则表达式调试技巧**：使用regex101.com、re.DEBUG标志、分段测试、使用捕获组调试
6. **高级re模块功能**：使用regex模块扩展功能、re.Scanner进行词法分析、re.VERBOSE编写可读的正则表达式
7. **最佳实践与注意事项**：选择合适的工具、编写可读的正则表达式、测试边界情况、考虑国际化、安全性考虑

通过不断练习和实践，你将能够熟练运用正则表达式解决各种复杂的文本处理问题，提高自动化脚本开发的效率和质量。

## 十一、练习题

1. 编写一个正则表达式，匹配所有有效的IPv6地址
2. 使用正则表达式解析JSON字符串，提取所有键值对
3. 编写一个正则表达式，匹配HTML中的所有链接（`<a href="...">...</a>`）
4. 使用正则表达式实现一个简单的模板引擎，支持`{{variable}}`语法
5. 编写一个正则表达式，匹配所有的邮箱地址，包括复杂的情况（如带引号的用户名）
6. 使用正则表达式分析Python代码，提取所有类定义和继承关系
7. 编写一个正则表达式，匹配自然语言文本中的日期和时间
8. 使用正则表达式实现一个简单的Markdown解析器，提取标题、列表和链接
9. 编写一个正则表达式，匹配所有的CSS选择器
10. 使用正则表达式优化一个存在性能问题的模式

## 十二、参考资料

1. Python官方文档：https://docs.python.org/zh-cn/3/library/re.html
2. regex101.com：https://regex101.com/（正则表达式在线测试工具）
3. 《Mastering Regular Expressions》（Jeffrey E.F. Friedl）
4. 《Regular Expressions Cookbook》（Jan Goyvaerts, Steven Levithan）
5. regex模块文档：https://pypi.org/project/regex/（第三方正则表达式库）
6. Unicode属性数据库：https://unicode.org/Public/UNIDATA/PropertyValueAliases.txt